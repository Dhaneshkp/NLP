{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":205013,"sourceType":"modelInstanceVersion","modelInstanceId":4686,"modelId":2820}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-09-19T08:20:35.984481Z","iopub.execute_input":"2025-09-19T08:20:35.984742Z","iopub.status.idle":"2025-09-19T08:20:37.866441Z","shell.execute_reply.started":"2025-09-19T08:20:35.984723Z","shell.execute_reply":"2025-09-19T08:20:37.865648Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3/config.json\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3/tokenizer.json\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3/metadata.json\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3/model.weights.h5\n/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3/assets/tokenizer/vocabulary.spm\n/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n\n#!pip install -q sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\n\n#model = SentenceTransformer(\"all-mpnet-base-v2\")\n","metadata":{"execution":{"iopub.status.busy":"2025-09-19T08:20:37.868332Z","iopub.execute_input":"2025-09-19T08:20:37.868710Z","iopub.status.idle":"2025-09-19T08:21:03.859840Z","shell.execute_reply.started":"2025-09-19T08:20:37.868689Z","shell.execute_reply":"2025-09-19T08:21:03.859260Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-19 08:20:50.566968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758270050.745922      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758270050.804364      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n#model.save(\"/kaggle/working/all-mpnet-base-v2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:03.860535Z","iopub.execute_input":"2025-09-19T08:21:03.861137Z","iopub.status.idle":"2025-09-19T08:21:03.864604Z","shell.execute_reply.started":"2025-09-19T08:21:03.861111Z","shell.execute_reply":"2025-09-19T08:21:03.863945Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\n#tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/qwen-llm\")\n#model = AutoModel.from_pretrained(\"/kaggle/input/qwen-llm\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:03.865415Z","iopub.execute_input":"2025-09-19T08:21:03.865684Z","iopub.status.idle":"2025-09-19T08:21:03.901514Z","shell.execute_reply.started":"2025-09-19T08:21:03.865659Z","shell.execute_reply":"2025-09-19T08:21:03.900916Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"submission_test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\nsubmission_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:03.902206Z","iopub.execute_input":"2025-09-19T08:21:03.902439Z","iopub.status.idle":"2025-09-19T08:21:03.940780Z","shell.execute_reply.started":"2025-09-19T08:21:03.902418Z","shell.execute_reply":"2025-09-19T08:21:03.940139Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.333333        0.333333    0.333333\n1   211333        0.333333        0.333333    0.333333\n2  1233961        0.333333        0.333333    0.333333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ndf_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:03.941447Z","iopub.execute_input":"2025-09-19T08:21:03.941655Z","iopub.status.idle":"2025-09-19T08:21:07.065891Z","shell.execute_reply.started":"2025-09-19T08:21:03.941640Z","shell.execute_reply":"2025-09-19T08:21:07.065248Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"               id             model_a              model_b  \\\n0           30192  gpt-4-1106-preview           gpt-4-0613   \n1           53567           koala-13b           gpt-4-0613   \n2           65089  gpt-3.5-turbo-0613       mistral-medium   \n3           96401    llama-2-13b-chat  mistral-7b-instruct   \n4          198779           koala-13b   gpt-3.5-turbo-0314   \n...           ...                 ...                  ...   \n57472  4294656694          gpt-4-0613             claude-1   \n57473  4294692063          claude-2.0     llama-2-13b-chat   \n57474  4294710549            claude-1           alpaca-13b   \n57475  4294899228              palm-2       tulu-2-dpo-70b   \n57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n\n                                                  prompt  \\\n0      [\"Is it morally right to try to have a certain...   \n1      [\"What is the difference between marriage lice...   \n2      [\"explain function calling. how would you call...   \n3      [\"How can I create a test set for a very rare ...   \n4      [\"What is the best way to travel from Tel-Aviv...   \n...                                                  ...   \n57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n57473  [\"In python, implement a naive Bayes with gaus...   \n57474  [\"is it unethical to work on building weapons?...   \n57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n57476  [\"three kids eat three apples in three days, h...   \n\n                                              response_a  \\\n0      [\"The question of whether it is morally right ...   \n1      [\"A marriage license is a legal document that ...   \n2      [\"Function calling is the process of invoking ...   \n3      [\"Creating a test set for a very rare category...   \n4      [\"The best way to travel from Tel Aviv to Jeru...   \n...                                                  ...   \n57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n57473  [\"Here is an implementation of a naive Bayes c...   \n57474  [\"Working on weapons technology raises some et...   \n57475  [\"Bromadiolone is a rodenticide which is most ...   \n57476                                      [\"27 apples\"]   \n\n                                              response_b  winner_model_a  \\\n0      [\"As an AI, I don't have personal beliefs or o...               1   \n1      [\"A marriage license and a marriage certificat...               0   \n2      [\"Function calling is the process of invoking ...               0   \n3      [\"When building a classifier for a very rare c...               1   \n4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n...                                                  ...             ...   \n57472  [\"Here is how that mnemonic represents the dig...               1   \n57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n57474  [\"It depends on the context. Weapons can be us...               1   \n57475  [\"As an AI language model, I do not promote or...               0   \n57476  [\"If three kids eat three apples in three days...               1   \n\n       winner_model_b  winner_tie  \n0                   0           0  \n1                   1           0  \n2                   0           1  \n3                   0           0  \n4                   1           0  \n...               ...         ...  \n57472               0           0  \n57473               0           0  \n57474               0           0  \n57475               1           0  \n57476               0           0  \n\n[57477 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57472</th>\n      <td>4294656694</td>\n      <td>gpt-4-0613</td>\n      <td>claude-1</td>\n      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n      <td>[\"Here is how that mnemonic represents the dig...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57473</th>\n      <td>4294692063</td>\n      <td>claude-2.0</td>\n      <td>llama-2-13b-chat</td>\n      <td>[\"In python, implement a naive Bayes with gaus...</td>\n      <td>[\"Here is an implementation of a naive Bayes c...</td>\n      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57474</th>\n      <td>4294710549</td>\n      <td>claude-1</td>\n      <td>alpaca-13b</td>\n      <td>[\"is it unethical to work on building weapons?...</td>\n      <td>[\"Working on weapons technology raises some et...</td>\n      <td>[\"It depends on the context. Weapons can be us...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57475</th>\n      <td>4294899228</td>\n      <td>palm-2</td>\n      <td>tulu-2-dpo-70b</td>\n      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n      <td>[\"As an AI language model, I do not promote or...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57476</th>\n      <td>4294947231</td>\n      <td>gemini-pro-dev-api</td>\n      <td>gpt-4-1106-preview</td>\n      <td>[\"three kids eat three apples in three days, h...</td>\n      <td>[\"27 apples\"]</td>\n      <td>[\"If three kids eat three apples in three days...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57477 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.068348Z","iopub.execute_input":"2025-09-19T08:21:07.068590Z","iopub.status.idle":"2025-09-19T08:21:07.079359Z","shell.execute_reply.started":"2025-09-19T08:21:07.068572Z","shell.execute_reply":"2025-09-19T08:21:07.078779Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.080075Z","iopub.execute_input":"2025-09-19T08:21:07.080320Z","iopub.status.idle":"2025-09-19T08:21:07.119749Z","shell.execute_reply.started":"2025-09-19T08:21:07.080303Z","shell.execute_reply":"2025-09-19T08:21:07.119138Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"df_train=df_train.head(10000)\n\n#)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.120446Z","iopub.execute_input":"2025-09-19T08:21:07.120699Z","iopub.status.idle":"2025-09-19T08:21:07.124353Z","shell.execute_reply.started":"2025-09-19T08:21:07.120673Z","shell.execute_reply":"2025-09-19T08:21:07.123690Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.124943Z","iopub.execute_input":"2025-09-19T08:21:07.125132Z","iopub.status.idle":"2025-09-19T08:21:07.143794Z","shell.execute_reply.started":"2025-09-19T08:21:07.125116Z","shell.execute_reply":"2025-09-19T08:21:07.143163Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"             id                    model_a              model_b  \\\n0         30192         gpt-4-1106-preview           gpt-4-0613   \n1         53567                  koala-13b           gpt-4-0613   \n2         65089         gpt-3.5-turbo-0613       mistral-medium   \n3         96401           llama-2-13b-chat  mistral-7b-instruct   \n4        198779                  koala-13b   gpt-3.5-turbo-0314   \n...         ...                        ...                  ...   \n9995  743558482         gpt-3.5-turbo-0613   gpt-4-1106-preview   \n9996  743759177                chatglm3-6b   gemini-pro-dev-api   \n9997  743813489  openhermes-2.5-mistral-7b   gpt-4-1106-preview   \n9998  743891198                 gpt-4-0613   gpt-4-1106-preview   \n9999  744215630         gpt-3.5-turbo-0613           vicuna-33b   \n\n                                                 prompt  \\\n0     [\"Is it morally right to try to have a certain...   \n1     [\"What is the difference between marriage lice...   \n2     [\"explain function calling. how would you call...   \n3     [\"How can I create a test set for a very rare ...   \n4     [\"What is the best way to travel from Tel-Aviv...   \n...                                                 ...   \n9995                 [\"Describe chebyshev polynomials\"]   \n9996  [\"Ddr5 at 6000mt\\/s has a bandwidth of x GB\\/s...   \n9997  [\"I have to run a relay on a team with Usain B...   \n9998                                     [\"How about?\"]   \n9999  [\"whats adobe express? , the key kpis and how ...   \n\n                                             response_a  \\\n0     [\"The question of whether it is morally right ...   \n1     [\"A marriage license is a legal document that ...   \n2     [\"Function calling is the process of invoking ...   \n3     [\"Creating a test set for a very rare category...   \n4     [\"The best way to travel from Tel Aviv to Jeru...   \n...                                                 ...   \n9995  [\"Chebyshev polynomials, named after the Russi...   \n9996  [\"To determine the bandwidth of a DDR5 memory ...   \n9997  [\"It would be best for Usain Bolt to take the ...   \n9998         [\"Of course! How can I assist you today?\"]   \n9999  [\"Adobe Express is a mobile app developed by A...   \n\n                                             response_b  winner_model_a  \\\n0     [\"As an AI, I don't have personal beliefs or o...               1   \n1     [\"A marriage license and a marriage certificat...               0   \n2     [\"Function calling is the process of invoking ...               0   \n3     [\"When building a classifier for a very rare c...               1   \n4     [\"The best way to travel from Tel-Aviv to Jeru...               0   \n...                                                 ...             ...   \n9995  [\"Chebyshev polynomials are a sequence of orth...               1   \n9996  [\"1. Bandwidth is calculated by multiplying th...               0   \n9997  [\"In a relay team with Usain Bolt, who is know...               0   \n9998  [\"It seems like your message may have been cut...               0   \n9999  [\"Adobe Express is an online platform that all...               0   \n\n      winner_model_b  winner_tie  \n0                  0           0  \n1                  1           0  \n2                  0           1  \n3                  0           0  \n4                  1           0  \n...              ...         ...  \n9995               0           0  \n9996               0           1  \n9997               0           1  \n9998               0           1  \n9999               1           0  \n\n[10000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>743558482</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>gpt-4-1106-preview</td>\n      <td>[\"Describe chebyshev polynomials\"]</td>\n      <td>[\"Chebyshev polynomials, named after the Russi...</td>\n      <td>[\"Chebyshev polynomials are a sequence of orth...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>743759177</td>\n      <td>chatglm3-6b</td>\n      <td>gemini-pro-dev-api</td>\n      <td>[\"Ddr5 at 6000mt\\/s has a bandwidth of x GB\\/s...</td>\n      <td>[\"To determine the bandwidth of a DDR5 memory ...</td>\n      <td>[\"1. Bandwidth is calculated by multiplying th...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>743813489</td>\n      <td>openhermes-2.5-mistral-7b</td>\n      <td>gpt-4-1106-preview</td>\n      <td>[\"I have to run a relay on a team with Usain B...</td>\n      <td>[\"It would be best for Usain Bolt to take the ...</td>\n      <td>[\"In a relay team with Usain Bolt, who is know...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>743891198</td>\n      <td>gpt-4-0613</td>\n      <td>gpt-4-1106-preview</td>\n      <td>[\"How about?\"]</td>\n      <td>[\"Of course! How can I assist you today?\"]</td>\n      <td>[\"It seems like your message may have been cut...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>744215630</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>vicuna-33b</td>\n      <td>[\"whats adobe express? , the key kpis and how ...</td>\n      <td>[\"Adobe Express is a mobile app developed by A...</td>\n      <td>[\"Adobe Express is an online platform that all...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.144472Z","iopub.execute_input":"2025-09-19T08:21:07.144690Z","iopub.status.idle":"2025-09-19T08:21:07.161259Z","shell.execute_reply.started":"2025-09-19T08:21:07.144667Z","shell.execute_reply":"2025-09-19T08:21:07.160302Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"id                0\nmodel_a           0\nmodel_b           0\nprompt            0\nresponse_a        0\nresponse_b        0\nwinner_model_a    0\nwinner_model_b    0\nwinner_tie        0\ndtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"X = df_train.drop(['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie'], axis = 1)\nX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.162196Z","iopub.execute_input":"2025-09-19T08:21:07.162454Z","iopub.status.idle":"2025-09-19T08:21:07.180190Z","shell.execute_reply.started":"2025-09-19T08:21:07.162435Z","shell.execute_reply":"2025-09-19T08:21:07.179503Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             id                                             prompt  \\\n0         30192  [\"Is it morally right to try to have a certain...   \n1         53567  [\"What is the difference between marriage lice...   \n2         65089  [\"explain function calling. how would you call...   \n3         96401  [\"How can I create a test set for a very rare ...   \n4        198779  [\"What is the best way to travel from Tel-Aviv...   \n...         ...                                                ...   \n9995  743558482                 [\"Describe chebyshev polynomials\"]   \n9996  743759177  [\"Ddr5 at 6000mt\\/s has a bandwidth of x GB\\/s...   \n9997  743813489  [\"I have to run a relay on a team with Usain B...   \n9998  743891198                                     [\"How about?\"]   \n9999  744215630  [\"whats adobe express? , the key kpis and how ...   \n\n                                             response_a  \\\n0     [\"The question of whether it is morally right ...   \n1     [\"A marriage license is a legal document that ...   \n2     [\"Function calling is the process of invoking ...   \n3     [\"Creating a test set for a very rare category...   \n4     [\"The best way to travel from Tel Aviv to Jeru...   \n...                                                 ...   \n9995  [\"Chebyshev polynomials, named after the Russi...   \n9996  [\"To determine the bandwidth of a DDR5 memory ...   \n9997  [\"It would be best for Usain Bolt to take the ...   \n9998         [\"Of course! How can I assist you today?\"]   \n9999  [\"Adobe Express is a mobile app developed by A...   \n\n                                             response_b  \n0     [\"As an AI, I don't have personal beliefs or o...  \n1     [\"A marriage license and a marriage certificat...  \n2     [\"Function calling is the process of invoking ...  \n3     [\"When building a classifier for a very rare c...  \n4     [\"The best way to travel from Tel-Aviv to Jeru...  \n...                                                 ...  \n9995  [\"Chebyshev polynomials are a sequence of orth...  \n9996  [\"1. Bandwidth is calculated by multiplying th...  \n9997  [\"In a relay team with Usain Bolt, who is know...  \n9998  [\"It seems like your message may have been cut...  \n9999  [\"Adobe Express is an online platform that all...  \n\n[10000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>743558482</td>\n      <td>[\"Describe chebyshev polynomials\"]</td>\n      <td>[\"Chebyshev polynomials, named after the Russi...</td>\n      <td>[\"Chebyshev polynomials are a sequence of orth...</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>743759177</td>\n      <td>[\"Ddr5 at 6000mt\\/s has a bandwidth of x GB\\/s...</td>\n      <td>[\"To determine the bandwidth of a DDR5 memory ...</td>\n      <td>[\"1. Bandwidth is calculated by multiplying th...</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>743813489</td>\n      <td>[\"I have to run a relay on a team with Usain B...</td>\n      <td>[\"It would be best for Usain Bolt to take the ...</td>\n      <td>[\"In a relay team with Usain Bolt, who is know...</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>743891198</td>\n      <td>[\"How about?\"]</td>\n      <td>[\"Of course! How can I assist you today?\"]</td>\n      <td>[\"It seems like your message may have been cut...</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>744215630</td>\n      <td>[\"whats adobe express? , the key kpis and how ...</td>\n      <td>[\"Adobe Express is a mobile app developed by A...</td>\n      <td>[\"Adobe Express is an online platform that all...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"y = df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].values\n\ny = np.argmax(y, axis=1)\ny","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.180940Z","iopub.execute_input":"2025-09-19T08:21:07.181168Z","iopub.status.idle":"2025-09-19T08:21:07.193549Z","shell.execute_reply.started":"2025-09-19T08:21:07.181154Z","shell.execute_reply":"2025-09-19T08:21:07.192948Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 2, ..., 2, 2, 1])"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.194126Z","iopub.execute_input":"2025-09-19T08:21:07.194303Z","iopub.status.idle":"2025-09-19T08:21:07.207281Z","shell.execute_reply.started":"2025-09-19T08:21:07.194289Z","shell.execute_reply":"2025-09-19T08:21:07.206651Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"X_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.207889Z","iopub.execute_input":"2025-09-19T08:21:07.208098Z","iopub.status.idle":"2025-09-19T08:21:07.224275Z","shell.execute_reply.started":"2025-09-19T08:21:07.208084Z","shell.execute_reply":"2025-09-19T08:21:07.223739Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"             id                                             prompt  \\\n9254  689927743  [\"My daughter who is 19 years old, and have -1...   \n1561  117188139                  [\"How\\u2019s the weather today?\"]   \n1670  126227049                           [\"What is an AI Agent?\"]   \n6087  457054687  [\"Describe the story of Cinderella in exactly ...   \n6669  501589422  [\"In Julia using XLSX.jl package I want to loa...   \n...         ...                                                ...   \n5734  432877900  [\"How to earn money with exchange offices that...   \n5191  392856958  [\"Please translate into german:\\n\\nThis joint ...   \n5390  407589571  [\"Write a physical therapy 8-12 sentence parag...   \n860    62750940                          [\"How to wear a bikini?\"]   \n7270  544979653  [\"I put a dime in my pocket. And took a nickel...   \n\n                                             response_a  \\\n9254  [\"I'm not an eye doctor, but I can provide som...   \n1561  [\"As an AI language model, I don't have real-t...   \n1670  [\"An AI agent is a software program or a syste...   \n6087  [\"Abandoned by her parents, Cinderella endures...   \n6669  [\"To load a sheet from an XLSX file in Julia u...   \n...                                                 ...   \n5734  [\"Here are some tips for earning money with ex...   \n5191  [\"Dieser gemeinsame FEDS-Brief und Liberty Str...   \n5390  [\"The patient, a 76-year-old male, has been re...   \n860   [\"Wearing a bikini can be a fun and comfortabl...   \n7270  [\"Okay, let's analyze this step-by-step:\\n* Yo...   \n\n                                             response_b  \n9254  [\"Prisms in glasses are prescribed to correct ...  \n1561  [\"As an AI, I'm unable to provide real-time in...  \n1670  [\"An AI agent is a system that interacts with ...  \n6087  [\"Abandoned beauty, Cinderella danced elegantl...  \n6669  [\"To load a sheet in Julia using the XLSX.jl p...  \n...                                                 ...  \n5734  [\"While I don't have access to specific Reddit...  \n5191  [\"Dieser gemeinsame FEDS-Hinweis und Liberty S...  \n5390  [\"Physical Therapy Assessment:\\n\\nPatient is a...  \n860   [\"Here are the basic steps to wear a bikini:\\n...  \n7270  [\"If you put a dime in your pocket, which is w...  \n\n[8000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9254</th>\n      <td>689927743</td>\n      <td>[\"My daughter who is 19 years old, and have -1...</td>\n      <td>[\"I'm not an eye doctor, but I can provide som...</td>\n      <td>[\"Prisms in glasses are prescribed to correct ...</td>\n    </tr>\n    <tr>\n      <th>1561</th>\n      <td>117188139</td>\n      <td>[\"How\\u2019s the weather today?\"]</td>\n      <td>[\"As an AI language model, I don't have real-t...</td>\n      <td>[\"As an AI, I'm unable to provide real-time in...</td>\n    </tr>\n    <tr>\n      <th>1670</th>\n      <td>126227049</td>\n      <td>[\"What is an AI Agent?\"]</td>\n      <td>[\"An AI agent is a software program or a syste...</td>\n      <td>[\"An AI agent is a system that interacts with ...</td>\n    </tr>\n    <tr>\n      <th>6087</th>\n      <td>457054687</td>\n      <td>[\"Describe the story of Cinderella in exactly ...</td>\n      <td>[\"Abandoned by her parents, Cinderella endures...</td>\n      <td>[\"Abandoned beauty, Cinderella danced elegantl...</td>\n    </tr>\n    <tr>\n      <th>6669</th>\n      <td>501589422</td>\n      <td>[\"In Julia using XLSX.jl package I want to loa...</td>\n      <td>[\"To load a sheet from an XLSX file in Julia u...</td>\n      <td>[\"To load a sheet in Julia using the XLSX.jl p...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5734</th>\n      <td>432877900</td>\n      <td>[\"How to earn money with exchange offices that...</td>\n      <td>[\"Here are some tips for earning money with ex...</td>\n      <td>[\"While I don't have access to specific Reddit...</td>\n    </tr>\n    <tr>\n      <th>5191</th>\n      <td>392856958</td>\n      <td>[\"Please translate into german:\\n\\nThis joint ...</td>\n      <td>[\"Dieser gemeinsame FEDS-Brief und Liberty Str...</td>\n      <td>[\"Dieser gemeinsame FEDS-Hinweis und Liberty S...</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>407589571</td>\n      <td>[\"Write a physical therapy 8-12 sentence parag...</td>\n      <td>[\"The patient, a 76-year-old male, has been re...</td>\n      <td>[\"Physical Therapy Assessment:\\n\\nPatient is a...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>62750940</td>\n      <td>[\"How to wear a bikini?\"]</td>\n      <td>[\"Wearing a bikini can be a fun and comfortabl...</td>\n      <td>[\"Here are the basic steps to wear a bikini:\\n...</td>\n    </tr>\n    <tr>\n      <th>7270</th>\n      <td>544979653</td>\n      <td>[\"I put a dime in my pocket. And took a nickel...</td>\n      <td>[\"Okay, let's analyze this step-by-step:\\n* Yo...</td>\n      <td>[\"If you put a dime in your pocket, which is w...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.224933Z","iopub.execute_input":"2025-09-19T08:21:07.225378Z","iopub.status.idle":"2025-09-19T08:21:07.240710Z","shell.execute_reply.started":"2025-09-19T08:21:07.225356Z","shell.execute_reply":"2025-09-19T08:21:07.239912Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"             id                                             prompt  \\\n6252  468242541  [\"Cook instant noodles \",\"What if I Boil water...   \n4684  353989191  [\"What are the most important commands and des...   \n1731  131590828  [\"x^2 - 5x+6 = 0 \\nSolve for x, use Factoring ...   \n4742  358536354  [\"how much money can you make selling lemonade...   \n4521  341763586  [\"How can a man go eight days without sleep?\\n...   \n...         ...                                                ...   \n6412  480885090  [\"where is a good place to rock climb in India...   \n8285  621278659                                 [\"Who is reckful\"]   \n7853  588180192  [\"I am a 40 years old man. What are the risks ...   \n1095   81238423  [\"d + a + b + c = a, b * a = 1, b =3 , d * c =...   \n6929  520242453                    [\"how to make a cup of coffee\"]   \n\n                                             response_a  \\\n6252  [\"Cooking instant noodles is a quick and easy ...   \n4684  [\"Here are some important commands and descrip...   \n1731  [\"x * x - 5 * x + 6 = 0\\n(x - 5) * x + 6 * (-1...   \n4742  [\"Depending on how much money you invest upfro...   \n4521                          [\"By sleeping at night.\"]   \n...                                                 ...   \n6412  [\"There are many rock climbing locations in In...   \n8285  [\"Reckful, also known as Byron Bernstein, was ...   \n7853  [\"Here are some potential risks of playing ten...   \n1095  [\"Given the equations:\\n\\n1) d + a + b + c = a...   \n6929  [\"To make a cup of coffee, you will need the f...   \n\n                                             response_b  \n6252  [\"Here are the basic steps to cook instant noo...  \n4684  [\"Here are some of the most important Git and ...  \n1731  [\"Sure, I can help you solve this equation usi...  \n4742  [\"It is difficult to give an exact answer to t...  \n4521  [\"By sleeping at night and therefore not needi...  \n...                                                 ...  \n6412  [\"One of the best places to rock climb in Indi...  \n8285  [\"Reckful, whose real name was Byron Bernstein...  \n7853  [\"Playing tennis on a weekly basis can be a gr...  \n1095  [\"From the given equations, we can deduce the ...  \n6929  [\"Making a cup of coffee can be a quick and ea...  \n\n[2000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6252</th>\n      <td>468242541</td>\n      <td>[\"Cook instant noodles \",\"What if I Boil water...</td>\n      <td>[\"Cooking instant noodles is a quick and easy ...</td>\n      <td>[\"Here are the basic steps to cook instant noo...</td>\n    </tr>\n    <tr>\n      <th>4684</th>\n      <td>353989191</td>\n      <td>[\"What are the most important commands and des...</td>\n      <td>[\"Here are some important commands and descrip...</td>\n      <td>[\"Here are some of the most important Git and ...</td>\n    </tr>\n    <tr>\n      <th>1731</th>\n      <td>131590828</td>\n      <td>[\"x^2 - 5x+6 = 0 \\nSolve for x, use Factoring ...</td>\n      <td>[\"x * x - 5 * x + 6 = 0\\n(x - 5) * x + 6 * (-1...</td>\n      <td>[\"Sure, I can help you solve this equation usi...</td>\n    </tr>\n    <tr>\n      <th>4742</th>\n      <td>358536354</td>\n      <td>[\"how much money can you make selling lemonade...</td>\n      <td>[\"Depending on how much money you invest upfro...</td>\n      <td>[\"It is difficult to give an exact answer to t...</td>\n    </tr>\n    <tr>\n      <th>4521</th>\n      <td>341763586</td>\n      <td>[\"How can a man go eight days without sleep?\\n...</td>\n      <td>[\"By sleeping at night.\"]</td>\n      <td>[\"By sleeping at night and therefore not needi...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6412</th>\n      <td>480885090</td>\n      <td>[\"where is a good place to rock climb in India...</td>\n      <td>[\"There are many rock climbing locations in In...</td>\n      <td>[\"One of the best places to rock climb in Indi...</td>\n    </tr>\n    <tr>\n      <th>8285</th>\n      <td>621278659</td>\n      <td>[\"Who is reckful\"]</td>\n      <td>[\"Reckful, also known as Byron Bernstein, was ...</td>\n      <td>[\"Reckful, whose real name was Byron Bernstein...</td>\n    </tr>\n    <tr>\n      <th>7853</th>\n      <td>588180192</td>\n      <td>[\"I am a 40 years old man. What are the risks ...</td>\n      <td>[\"Here are some potential risks of playing ten...</td>\n      <td>[\"Playing tennis on a weekly basis can be a gr...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>81238423</td>\n      <td>[\"d + a + b + c = a, b * a = 1, b =3 , d * c =...</td>\n      <td>[\"Given the equations:\\n\\n1) d + a + b + c = a...</td>\n      <td>[\"From the given equations, we can deduce the ...</td>\n    </tr>\n    <tr>\n      <th>6929</th>\n      <td>520242453</td>\n      <td>[\"how to make a cup of coffee\"]</td>\n      <td>[\"To make a cup of coffee, you will need the f...</td>\n      <td>[\"Making a cup of coffee can be a quick and ea...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.241559Z","iopub.execute_input":"2025-09-19T08:21:07.241888Z","iopub.status.idle":"2025-09-19T08:21:07.285012Z","shell.execute_reply.started":"2025-09-19T08:21:07.241866Z","shell.execute_reply":"2025-09-19T08:21:07.284156Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([2, 2, 2, ..., 1, 1, 2])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"catagorical_feature = [col for col in X.columns if X[col].dtype == 'object']\ncatagorical_feature","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.286033Z","iopub.execute_input":"2025-09-19T08:21:07.286320Z","iopub.status.idle":"2025-09-19T08:21:07.338413Z","shell.execute_reply.started":"2025-09-19T08:21:07.286292Z","shell.execute_reply":"2025-09-19T08:21:07.337877Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['prompt', 'response_a', 'response_b']"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n\nfrom sentence_transformers import SentenceTransformer\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.339003Z","iopub.execute_input":"2025-09-19T08:21:07.339212Z","iopub.status.idle":"2025-09-19T08:21:07.351539Z","shell.execute_reply.started":"2025-09-19T08:21:07.339197Z","shell.execute_reply":"2025-09-19T08:21:07.350950Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom transformers import DebertaV2Tokenizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nimport tensorflow as tf\nfrom keras_hub.src.models.deberta_v3.deberta_v3_backbone import DebertaV3Backbone\nimport os # Import os module\nimport multiprocessing\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path, batch_size=16, max_length=512, use_fast_tokenizer=True, enable_mixed_precision=True, embedding_type=\"mean\"):\n        self.embedding_type = embedding_type\n        self.model_path = model_path\n        self.batch_size = int(batch_size)\n        self.max_length = min(int(max_length), 512)\n        self.use_fast_tokenizer = use_fast_tokenizer\n        self.enable_mixed_precision = enable_mixed_precision # Add this line to store the parameter\n        self._cpu_count = multiprocessing.cpu_count()\n\n        # Make TF GPU usage explicit / safe\n        try:\n            gpus = tf.config.list_physical_devices(\"GPU\")\n            if gpus:\n                for g in gpus:\n                    tf.config.experimental.set_memory_growth(g, True)\n        except Exception:\n            pass\n\n        # optionally use mixed precision on GPUs (speeds up fp16 capable GPUs)\n        try:\n            if self.enable_mixed_precision: # Use self.enable_mixed_precision\n                from tensorflow.keras import mixed_precision\n                mixed_precision.set_global_policy(\"mixed_float16\")\n        except Exception:\n            pass\n\n        # Load tokenizer (prefer fast tokenizer if available)\n        try:\n            if self.use_fast_tokenizer:\n                from transformers import DebertaV2TokenizerFast as _TokFast\n                self.tokenizer = _TokFast(vocab_file=os.path.join(self.model_path, \"assets/tokenizer/vocabulary.spm\")) # Use os.path.join\n            else:\n                from transformers import DebertaV2Tokenizer as _Tok\n                self.tokenizer = _Tok(vocab_file=os.path.join(self.model_path, \"assets/tokenizer/vocabulary.spm\")) # Use os.path.join\n        except Exception:\n            # fallback to original import name/location\n            try:\n                from transformers import DebertaV2Tokenizer as _Tok\n                self.tokenizer = _Tok(vocab_file=os.path.join(self.model_path, \"assets/tokenizer/vocabulary.spm\")) # Use os.path.join\n            except Exception:\n                raise\n\n        self.tokenizer.model_max_length = self.max_length\n\n        # Load model backbone (Keras)\n        config = self._detect_model_config()\n        self.model = DebertaV3Backbone(\n            vocabulary_size=128100,\n            num_layers=config[\"num_layers\"],\n            num_heads=config[\"num_heads\"],\n            hidden_dim=config[\"hidden_dim\"],\n            intermediate_dim=config[\"intermediate_dim\"],\n            dropout=0.1,\n            max_sequence_length=512,\n            bucket_size=256\n        )\n\n\n        self.model.load_weights(os.path.join(self.model_path, \"model.weights.h5\"),skip_mismatch=True) # Use os.path.join\n\n        print(\"✅ Model input names:\", [input.name for input in self.model.inputs])\n        # optional: warm-up call with zeros to ensure TF places variables on GPU if available\n        try:\n            import tensorflow as tf\n            dummy_input = {\n                \"padding_mask\": tf.zeros((1, self.max_length), dtype=tf.int32),\n                \"token_ids\": tf.zeros((1, self.max_length), dtype=tf.int32),\n            }\n            _ = self.model(dummy_input)\n        except Exception:\n            pass\n    def _detect_model_config(self):\n            import os\n            import json\n        \n            config_path = os.path.join(self.model_path, \"config.json\")\n            if os.path.exists(config_path):\n                try:\n                    with open(config_path, \"r\") as f:\n                        config = json.load(f)\n                    return {\n                        \"num_layers\": config.get(\"num_layers\", 12),\n                        \"num_heads\": config.get(\"num_attention_heads\", 12),\n                        \"hidden_dim\": config.get(\"hidden_size\", 768),\n                        \"intermediate_dim\": config.get(\"intermediate_size\", 3072),\n                    }\n                except Exception as e:\n                    print(f\"⚠️ Failed to read config.json: {e}\")\n        \n            # Fallback: infer from folder name\n            path_lower = self.model_path.lower()\n            if \"small\" in path_lower:\n                return {\n                    \"num_layers\": 12,\n                    \"num_heads\": 6,\n                    \"hidden_dim\": 768,\n                    \"intermediate_dim\": 3072,\n                }\n            elif \"base\" in path_lower:\n                return {\n                    \"num_layers\": 12,\n                    \"num_heads\": 12,\n                    \"hidden_dim\": 768,\n                    \"intermediate_dim\": 3072,\n                }\n        \n            print(\"⚠️ Could not auto-detect model config. Using default base config.\")\n            return {\n                \"num_layers\": 12,\n                \"num_heads\": 12,\n                \"hidden_dim\": 768,\n                \"intermediate_dim\": 3072,\n            }\n\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        import tensorflow as tf\n        import numpy as np\n    \n        # Accept pandas Series / DataFrame / numpy array / list\n        if hasattr(X, \"to_list\"):\n            texts = X.to_list()\n        else:\n            texts = list(X)\n    \n        def _to_text(item):\n            if isinstance(item, (list, tuple, np.ndarray)):\n                if len(item) == 0:\n                    return \"\"\n                if len(item) == 1:\n                    return str(item[0])\n                return \" \".join(str(x) for x in item)\n            return \"\" if item is None else str(item)\n    \n        texts = [_to_text(t) for t in texts]\n        n = len(texts)\n        if n == 0:\n            try:\n                hidden_dim = int(self.model.output_shape[-1])\n                return {\n                    \"raw\": np.zeros((0, self.max_length, hidden_dim), dtype=np.float32),\n                    \"mean\": np.zeros((0, hidden_dim), dtype=np.float32),\n                    \"median\": np.zeros((0, hidden_dim), dtype=np.float32),\n                    #\"max\": np.zeros((0, hidden_dim), dtype=np.float32),\n                    #\"min\": np.zeros((0, hidden_dim), dtype=np.float32),\n                }\n            except Exception:\n                return {}\n    \n        # Store outputs\n        raw_outputs = []\n    \n        for i in range(0, n, self.batch_size):\n            batch = texts[i:i + self.batch_size]\n            try:\n                tokens = self.tokenizer(\n                    batch,\n                    padding=\"max_length\",\n                    truncation=True,\n                    max_length=self.max_length,\n                    return_tensors=\"tf\",\n                )\n                token_ids_tf = tf.cast(tokens[\"input_ids\"], tf.int32)\n                attention_mask_tf = tf.cast(tokens[\"attention_mask\"], dtype=tf.int32)\n                model_inputs = {\"padding_mask\": attention_mask_tf, \"token_ids\": token_ids_tf}\n                outputs = self.model(model_inputs)\n                outputs_np = outputs.numpy()\n            except Exception:\n                tokens = self.tokenizer(\n                    [str(t) for t in batch],\n                    padding=\"max_length\",\n                    truncation=True,\n                    max_length=self.max_length,\n                    return_tensors=\"np\",\n                )\n                token_ids_tf = tf.convert_to_tensor(tokens[\"input_ids\"], dtype=tf.int32)\n                attention_mask_tf = tf.convert_to_tensor(tokens[\"attention_mask\"], dtype=tf.int32)\n                model_inputs = {\"padding_mask\": attention_mask_tf, \"token_ids\": token_ids_tf}\n                outputs = self.model(model_inputs)\n                outputs_np = outputs.numpy()\n    \n            raw_outputs.append(outputs_np)\n    \n        # Combine all batches\n        full_output = np.vstack(raw_outputs)  # shape: [n_samples, seq_len, hidden_dim]\n    \n        \n        mean_embeddings = np.mean(full_output, axis=1)\n        median_embeddings = np.median(full_output, axis=1)\n        #max_embeddings = np.max(full_output, axis=1)\n        #min_embeddings = np.min(full_output, axis=1)\n    \n        # Return per-sample dicts\n        return [\n            {       \n                \"text\": texts[i],\n                \"raw\": full_output[i],\n                \"mean\": mean_embeddings[i],\n                \"median\": median_embeddings[i],\n                #\"max\": max_embeddings[i],\n                #\"min\": min_embeddings[i],\n            }\n            for i in range(len(texts))\n        ]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:07.352220Z","iopub.execute_input":"2025-09-19T08:21:07.352474Z","iopub.status.idle":"2025-09-19T08:21:08.297824Z","shell.execute_reply.started":"2025-09-19T08:21:07.352453Z","shell.execute_reply":"2025-09-19T08:21:08.297071Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"%pip install nltk ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:08.298777Z","iopub.execute_input":"2025-09-19T08:21:08.299043Z","iopub.status.idle":"2025-09-19T08:21:12.031164Z","shell.execute_reply.started":"2025-09-19T08:21:08.299014Z","shell.execute_reply":"2025-09-19T08:21:12.030326Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nnltk.download(\"stopwords\")\nnltk.download(\"wordnet\")\n\nstop_words = set(stopwords.words(\"english\"))\nlemmatizer = WordNetLemmatizer()\n\ndef clean_text_for_common_words(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    tokens = text.split()\n    return [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    #return [word for word in tokens]\n\nclass CommonWordsTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        common_meaningful_words_a = []\n        common_meaningful_words_b = []\n\n        for index, row in X.iterrows():\n            prompt_tokens = clean_text_for_common_words(row['prompt'])\n            response_a_tokens = clean_text_for_common_words(row['response_a'])\n            response_b_tokens = clean_text_for_common_words(row['response_b'])\n\n            common_meaningful_a = len(set(prompt_tokens) & set(response_a_tokens))\n            common_meaningful_b = len(set(prompt_tokens) & set(response_b_tokens))\n\n            common_meaningful_words_a.append(common_meaningful_a)\n            common_meaningful_words_b.append(common_meaningful_b)\n\n        return np.array([common_meaningful_words_a, common_meaningful_words_b]).T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:12.035627Z","iopub.execute_input":"2025-09-19T08:21:12.035875Z","iopub.status.idle":"2025-09-19T08:21:13.088924Z","shell.execute_reply.started":"2025-09-19T08:21:12.035850Z","shell.execute_reply":"2025-09-19T08:21:13.087931Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"X_train[\"prompt_clean\"] = X_train[\"prompt\"]#.apply(clean_text_for_common_words)\nX_train[\"response_a_clean\"] = X_train[\"response_a\"]#.apply(clean_text_for_common_words)\nX_train[\"response_b_clean\"] = X_train[\"response_b\"]#.apply(clean_text_for_common_words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:13.089906Z","iopub.execute_input":"2025-09-19T08:21:13.090156Z","iopub.status.idle":"2025-09-19T08:21:13.107289Z","shell.execute_reply.started":"2025-09-19T08:21:13.090137Z","shell.execute_reply":"2025-09-19T08:21:13.106577Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass PromptResponseSimilarity(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # X is a 2D array of shape (n_samples, 3 * embedding_dim)\n        n_samples, total_dim = X.shape\n        embedding_dim = total_dim // 3\n\n        prompt_embeds = X[:, :embedding_dim]\n        resp_a_embeds = X[:, embedding_dim:2*embedding_dim]\n        resp_b_embeds = X[:, 2*embedding_dim:]\n\n        sim_a = np.array([\n            cosine_similarity(p.reshape(1, -1), a.reshape(1, -1))[0, 0]\n            for p, a in zip(prompt_embeds, resp_a_embeds)\n        ])\n        sim_b = np.array([\n            cosine_similarity(p.reshape(1, -1), b.reshape(1, -1))[0, 0]\n            for p, b in zip(prompt_embeds, resp_b_embeds)\n        ])\n\n        return np.vstack([sim_a, sim_b]).T\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:13.108358Z","iopub.execute_input":"2025-09-19T08:21:13.108665Z","iopub.status.idle":"2025-09-19T08:21:13.154561Z","shell.execute_reply.started":"2025-09-19T08:21:13.108640Z","shell.execute_reply":"2025-09-19T08:21:13.153867Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class RawEmbeddingSimilarity(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        prompt_embeds = X[\"prompt_embed\"].apply(lambda x: x[\"raw\"]).tolist()\n        resp_a_embeds = X[\"resp_a_embed\"].apply(lambda x: x[\"raw\"]).tolist()\n        resp_b_embeds = X[\"resp_b_embed\"].apply(lambda x: x[\"raw\"]).tolist()\n    \n        sim_a, sim_b = [], []\n        for p, a, b in zip(prompt_embeds, resp_a_embeds, resp_b_embeds):\n            sim_a.append(cosine_similarity(p.flatten().reshape(1, -1), a.flatten().reshape(1, -1))[0, 0])\n            sim_b.append(cosine_similarity(p.flatten().reshape(1, -1), b.flatten().reshape(1, -1))[0, 0])\n    \n        return np.vstack([sim_a, sim_b]).T\n\n        \nclass AggregatedEmbeddingSimilarity(BaseEstimator, TransformerMixin):\n    def __init__(self, agg_type=\"mean\"):\n        self.agg_type = agg_type\n\n    def fit(self, X, y=None):\n        return self\n\n    \n    def transform(self, X):\n        prompt_embeds = X[\"prompt_embed\"].apply(lambda x: x[self.agg_type]).tolist()\n        resp_a_embeds = X[\"resp_a_embed\"].apply(lambda x: x[self.agg_type]).tolist()\n        resp_b_embeds = X[\"resp_b_embed\"].apply(lambda x: x[self.agg_type]).tolist()\n    \n        sim_a = [cosine_similarity(p.reshape(1, -1), a.reshape(1, -1))[0, 0] for p, a in zip(prompt_embeds, resp_a_embeds)]\n        sim_b = [cosine_similarity(p.reshape(1, -1), b.reshape(1, -1))[0, 0] for p, b in zip(prompt_embeds, resp_b_embeds)]\n    \n        return np.vstack([sim_a, sim_b]).T\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:13.155257Z","iopub.execute_input":"2025-09-19T08:21:13.155443Z","iopub.status.idle":"2025-09-19T08:21:13.170064Z","shell.execute_reply.started":"2025-09-19T08:21:13.155428Z","shell.execute_reply":"2025-09-19T08:21:13.169295Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport pandas as pd\n\nclass TFIDFAttentionEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, tokenizer, max_length=512, embedding_dim=768):\n        self.tokenizer = tokenizer\n        self.vectorizer = TfidfVectorizer()\n        self.max_length = max_length\n        self.embedding_dim = embedding_dim\n\n    def fit(self, X, y=None):\n        texts = []\n\n        # Extract texts from various input formats\n        if isinstance(X, (list, np.ndarray)):\n            for row in X:\n                if isinstance(row, (list, tuple)):\n                    for item in row:\n                        if isinstance(item, dict):\n                            text = item.get(\"text\", \"\")\n                            if text.strip():\n                                texts.append(text)\n                elif isinstance(row, dict):\n                    text = row.get(\"text\", \"\")\n                    if text.strip():\n                        texts.append(text)\n        elif isinstance(X, pd.DataFrame):\n            for col in X.columns:\n                col_texts = X[col].apply(lambda x: x.get(\"text\", \"\") if isinstance(x, dict) else \"\").tolist()\n                texts.extend([t for t in col_texts if t.strip()])\n\n        if not texts:\n            raise ValueError(\"No valid texts found for TF-IDF fitting.\")\n\n        self.vectorizer.fit(texts)\n        return self\n\n    def transform(self, X):\n        weighted_embeddings_mean = []\n        weighted_embeddings_median = []\n    \n        for sample in X:\n            # If sample is a dict (expected format), extract fields\n            if isinstance(sample, dict):\n                text = sample.get(\"text\", \"\")\n                token_embeddings = sample.get(\"raw\", None)\n            else:\n                # Fallback: treat sample as plain text or unsupported format\n                text = str(sample)\n                token_embeddings = None\n    \n            # Handle empty or invalid cases\n            if token_embeddings is None or len(text.strip()) == 0:\n                zero_vec = np.zeros(self.embedding_dim)\n                weighted_embeddings_mean.append(zero_vec)\n                weighted_embeddings_median.append(zero_vec)\n                continue\n    \n            tokens = self.tokenizer.tokenize(text)\n            tfidf_vector = self.vectorizer.transform([text]).toarray()[0]\n    \n            token_weights = []\n            for token in tokens[:self.max_length]:\n                idx = self.vectorizer.vocabulary_.get(token.lower(), None)\n                token_weights.append(tfidf_vector[idx] if idx is not None else 0.0)\n    \n            token_weights = np.array(token_weights)\n            token_embeddings = token_embeddings[:len(token_weights)]\n    \n            if token_weights.sum() > 0:\n                token_weights = token_weights / token_weights.sum()\n    \n            if token_weights.sum() == 0 or token_embeddings.shape[0] == 0:\n                zero_vec = np.zeros(token_embeddings.shape[-1])\n                weighted_embeddings_mean.append(zero_vec)\n                weighted_embeddings_median.append(zero_vec)\n            else:\n                # Calculate weighted mean\n                weighted_mean = np.average(token_embeddings, axis=0, weights=token_weights)\n                weighted_embeddings_mean.append(weighted_mean)\n                \n                # Calculate weighted median\n                # For each dimension, sort values and find the weighted median\n                weighted_median = np.zeros(token_embeddings.shape[1])\n                for dim in range(token_embeddings.shape[1]):\n                    dim_values = token_embeddings[:, dim]\n                    sorted_indices = np.argsort(dim_values)\n                    sorted_weights = token_weights[sorted_indices]\n                    cumsum_weights = np.cumsum(sorted_weights)\n                    median_idx = np.searchsorted(cumsum_weights, 0.5 * cumsum_weights[-1])\n                    weighted_median[dim] = dim_values[sorted_indices[median_idx]]\n                weighted_embeddings_median.append(weighted_median)\n    \n        # Stack and return both mean and median embeddings side by side\n        return np.hstack([\n            np.array(weighted_embeddings_mean),\n            np.array(weighted_embeddings_median)\n        ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:13.170847Z","iopub.execute_input":"2025-09-19T08:21:13.171042Z","iopub.status.idle":"2025-09-19T08:21:13.190090Z","shell.execute_reply.started":"2025-09-19T08:21:13.171027Z","shell.execute_reply":"2025-09-19T08:21:13.189438Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"embedder = HFEmbedder(model_path=\"/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3\")\n#/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3\ncommon_words_transformer = CommonWordsTransformer()\n# Updated preprocessing transformer\npreprocessing = ColumnTransformer([\n    (\"prompt_embed\", embedder, \"prompt_clean\"),\n    (\"resp_a_embed\", embedder, \"response_a_clean\"),\n    (\"resp_b_embed\", embedder, \"response_b_clean\"),\n    (\"common_words\", common_words_transformer, [\"prompt\", \"response_a\", \"response_b\"]),\n    #(\"num\", \"passthrough\", [\"id\"])\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:13.190719Z","iopub.execute_input":"2025-09-19T08:21:13.190895Z","iopub.status.idle":"2025-09-19T08:21:27.281739Z","shell.execute_reply.started":"2025-09-19T08:21:13.190876Z","shell.execute_reply":"2025-09-19T08:21:27.281150Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nI0000 00:00:1758270075.296405      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"✅ Model input names: ['padding_mask', 'token_ids']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"class DictWrapper(BaseEstimator, TransformerMixin):\n    def __init__(self, embedder):\n        self.embedder = embedder\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # Returns a 2D array of shape (n_samples, 1), each cell is a dict\n        embeddings = self.embedder.transform(X)\n        return np.array(embeddings).reshape(-1, 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:27.282572Z","iopub.execute_input":"2025-09-19T08:21:27.282851Z","iopub.status.idle":"2025-09-19T08:21:27.287128Z","shell.execute_reply.started":"2025-09-19T08:21:27.282820Z","shell.execute_reply":"2025-09-19T08:21:27.286447Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class EmbeddingStatsExtractor(BaseEstimator, TransformerMixin):\n    def __init__(self, fields=(\"mean\", \"median\")):\n        self.fields = fields\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        features = []\n        for row in X:\n            row_features = []\n            for field in self.fields:\n                vec = row.get(field, np.zeros(768))  # fallback to zeros if missing\n                row_features.extend(vec)\n            features.append(row_features)\n        return np.array(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:27.287997Z","iopub.execute_input":"2025-09-19T08:21:27.288218Z","iopub.status.idle":"2025-09-19T08:21:27.330094Z","shell.execute_reply.started":"2025-09-19T08:21:27.288198Z","shell.execute_reply":"2025-09-19T08:21:27.329367Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nimport gc\n\n# Initialize the shared embedder\nshared_embedder = HFEmbedder(model_path=\"/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3\")\n\n# Step 1: Get embeddings for each text column\nembedding_stage = ColumnTransformer([\n    (\"prompt_embed\", DictWrapper(shared_embedder), \"prompt_clean\"),\n    (\"resp_a_embed\", DictWrapper(shared_embedder), \"response_a_clean\"),\n    (\"resp_b_embed\", DictWrapper(shared_embedder), \"response_b_clean\"),\n])\n\n# Fit and transform the embeddings\nprint(\"Step 1: Generating embeddings...\")\n# Configuration\nCHUNK_SIZE = 256  # Adjust based on your memory constraints\nOUTPUT_FILE = \"embedded_features.pkl\"\n\n\ndef process_in_chunks(data, chunk_size=CHUNK_SIZE):\n    num_samples = len(data)\n    results = []\n    \n    for start_idx in range(0, num_samples, chunk_size):\n        print(f\"\\nProcessing chunk {start_idx//chunk_size + 1}/{(num_samples + chunk_size - 1)//chunk_size}\")\n        \n        # Get current chunk\n        end_idx = min(start_idx + chunk_size, num_samples)\n        chunk = data.iloc[start_idx:end_idx]\n        \n        # Generate embeddings for chunk\n        print(\"Generating embeddings...\")\n        embedded_chunk = embedding_stage.fit_transform(chunk)\n        \n        # Convert to DataFrame format\n        chunk_df = pd.DataFrame([{\n            \"prompt_embed\": x[0],\n            \"resp_a_embed\": x[1],\n            \"resp_b_embed\": x[2]\n        } for x in embedded_chunk])\n        \n        # Save chunk to disk\n        chunk_filename = f\"{OUTPUT_FILE}.chunk_{start_idx//chunk_size}.pkl\"\n        chunk_df.to_pickle(chunk_filename)\n        print(f\"Saved chunk to {chunk_filename}\")\n        \n        # Clear memory\n        del embedded_chunk, chunk_df\n        gc.collect()\n        \n        # Keep track of chunk files\n        results.append(chunk_filename)\n    \n    return results\n\n# Process training data\nprint(\"Processing training data...\")\nchunk_files = process_in_chunks(X_train)\n\n# Optionally, combine all chunks\ndef combine_chunks(chunk_files):\n    print(\"\\nCombining chunks...\")\n    combined_df = pd.concat([pd.read_pickle(f) for f in chunk_files])\n    combined_df.to_pickle(OUTPUT_FILE)\n    print(f\"Saved combined data to {OUTPUT_FILE}\")\n    return combined_df\n\n# Combine if needed\n# combined_data = combine_chunks(chunk_files)  # Uncomment if you need the combined data\n\nprint(\"\\nProcessing complete!\")\n# Load training data chunks\n\n# Load and combine all chunks into a single DataFrame\ndef load_embedded_df(chunk_files):\n    print(\"Loading and combining chunks...\")\n    chunks = []\n    \n    for chunk_file in chunk_files:\n        try:\n            # Load chunk\n            chunk_df = pd.read_pickle(chunk_file)\n            chunks.append(chunk_df)\n            \n            # Clear memory after appending\n            del chunk_df\n            gc.collect()\n            \n        except Exception as e:\n            print(f\"Error loading chunk {chunk_file}: {e}\")\n    \n    # Combine all chunks\n    print(\"Concatenating all chunks...\")\n    embedded_df = pd.concat(chunks, axis=0, ignore_index=True)\n    print(f\"Final DataFrame shape: {embedded_df.shape}\")\n    \n    # Clear temporary lists\n    del chunks\n    gc.collect()\n    \n    return embedded_df\n\n# Load training data chunks\nembedded_df = load_embedded_df([f\"embedded_features.pkl.chunk_{i}.pkl\" \n                              for i in range((len(X_train) + CHUNK_SIZE - 1) // CHUNK_SIZE)])\n\nprint(\"\\nEmbedded DataFrame columns:\", embedded_df.columns.tolist())\nprint(\"First row prompt embedding keys:\", embedded_df[\"prompt_embed\"].iloc[0].keys())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:21:27.330826Z","iopub.execute_input":"2025-09-19T08:21:27.331012Z","iopub.status.idle":"2025-09-19T08:58:42.534038Z","shell.execute_reply.started":"2025-09-19T08:21:27.330988Z","shell.execute_reply":"2025-09-19T08:58:42.533355Z"}},"outputs":[{"name":"stdout","text":"✅ Model input names: ['padding_mask', 'token_ids']\nStep 1: Generating embeddings...\nProcessing training data...\n\nProcessing chunk 1/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_0.pkl\n\nProcessing chunk 2/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_1.pkl\n\nProcessing chunk 3/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_2.pkl\n\nProcessing chunk 4/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_3.pkl\n\nProcessing chunk 5/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_4.pkl\n\nProcessing chunk 6/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_5.pkl\n\nProcessing chunk 7/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_6.pkl\n\nProcessing chunk 8/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_7.pkl\n\nProcessing chunk 9/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_8.pkl\n\nProcessing chunk 10/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_9.pkl\n\nProcessing chunk 11/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_10.pkl\n\nProcessing chunk 12/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_11.pkl\n\nProcessing chunk 13/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_12.pkl\n\nProcessing chunk 14/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_13.pkl\n\nProcessing chunk 15/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_14.pkl\n\nProcessing chunk 16/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_15.pkl\n\nProcessing chunk 17/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_16.pkl\n\nProcessing chunk 18/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_17.pkl\n\nProcessing chunk 19/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_18.pkl\n\nProcessing chunk 20/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_19.pkl\n\nProcessing chunk 21/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_20.pkl\n\nProcessing chunk 22/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_21.pkl\n\nProcessing chunk 23/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_22.pkl\n\nProcessing chunk 24/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_23.pkl\n\nProcessing chunk 25/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_24.pkl\n\nProcessing chunk 26/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_25.pkl\n\nProcessing chunk 27/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_26.pkl\n\nProcessing chunk 28/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_27.pkl\n\nProcessing chunk 29/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_28.pkl\n\nProcessing chunk 30/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_29.pkl\n\nProcessing chunk 31/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_30.pkl\n\nProcessing chunk 32/32\nGenerating embeddings...\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\n✅ Model input names: ['padding_mask', 'token_ids']\nSaved chunk to embedded_features.pkl.chunk_31.pkl\n\nProcessing complete!\nLoading and combining chunks...\nConcatenating all chunks...\nFinal DataFrame shape: (8000, 3)\n\nEmbedded DataFrame columns: ['prompt_embed', 'resp_a_embed', 'resp_b_embed']\nFirst row prompt embedding keys: dict_keys(['text', 'raw', 'mean', 'median'])\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Step 2: Extract statistics from embeddings\nprint(\"\\nStep 2: Extracting embedding statistics...\")\n\n# Process each type of embedding separately\nprompt_stats = EmbeddingStatsExtractor().fit_transform(embedded_df[\"prompt_embed\"])\nresp_a_stats = EmbeddingStatsExtractor().fit_transform(embedded_df[\"resp_a_embed\"])\nresp_b_stats = EmbeddingStatsExtractor().fit_transform(embedded_df[\"resp_b_embed\"])\n\nprint(f\"Prompt stats shape: {prompt_stats.shape}\")\nprint(f\"Response A stats shape: {resp_a_stats.shape}\")\nprint(f\"Response B stats shape: {resp_b_stats.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:58:42.534771Z","iopub.execute_input":"2025-09-19T08:58:42.534948Z","iopub.status.idle":"2025-09-19T08:58:47.673350Z","shell.execute_reply.started":"2025-09-19T08:58:42.534934Z","shell.execute_reply":"2025-09-19T08:58:47.672635Z"}},"outputs":[{"name":"stdout","text":"\nStep 2: Extracting embedding statistics...\nPrompt stats shape: (8000, 1536)\nResponse A stats shape: (8000, 1536)\nResponse B stats shape: (8000, 1536)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"embedded_df[\"prompt_embed\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:58:47.674142Z","iopub.execute_input":"2025-09-19T08:58:47.674415Z","iopub.status.idle":"2025-09-19T08:58:47.930931Z","shell.execute_reply.started":"2025-09-19T08:58:47.674395Z","shell.execute_reply":"2025-09-19T08:58:47.930334Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"0       {'text': '[\"My daughter who is 19 years old, a...\n1       {'text': '[\"How\\u2019s the weather today?\"]', ...\n2       {'text': '[\"What is an AI Agent?\"]', 'raw': [[...\n3       {'text': '[\"Describe the story of Cinderella i...\n4       {'text': '[\"In Julia using XLSX.jl package I w...\n                              ...                        \n7995    {'text': '[\"How to earn money with exchange of...\n7996    {'text': '[\"Please translate into german:\\n\\nT...\n7997    {'text': '[\"Write a physical therapy 8-12 sent...\n7998    {'text': '[\"How to wear a bikini?\"]', 'raw': [...\n7999    {'text': '[\"I put a dime in my pocket. And too...\nName: prompt_embed, Length: 8000, dtype: object"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Step 3: Calculate similarities\nprint(\"\\nStep 3: Calculating similarities...\")\n\n# Raw embedding similarity\nraw_sim = RawEmbeddingSimilarity().fit_transform(embedded_df)\nprint(f\"Raw similarity shape: {raw_sim.shape}\")\n\n# Mean and median similarities\nmean_sim = AggregatedEmbeddingSimilarity(agg_type=\"mean\").fit_transform(embedded_df)\nmedian_sim = AggregatedEmbeddingSimilarity(agg_type=\"median\").fit_transform(embedded_df)\n\nprint(f\"Mean similarity shape: {mean_sim.shape}\")\nprint(f\"Median similarity shape: {median_sim.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T08:58:47.931576Z","iopub.execute_input":"2025-09-19T08:58:47.931775Z","iopub.status.idle":"2025-09-19T09:00:43.198535Z","shell.execute_reply.started":"2025-09-19T08:58:47.931759Z","shell.execute_reply":"2025-09-19T09:00:43.197644Z"}},"outputs":[{"name":"stdout","text":"\nStep 3: Calculating similarities...\nRaw similarity shape: (8000, 2)\nMean similarity shape: (8000, 2)\nMedian similarity shape: (8000, 2)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Step 4: TF-IDF attention\nprint(\"\\nStep 4: Computing TF-IDF attention...\")\n\n# Create and fit TF-IDF embedders\ntfidf_prompt = TFIDFAttentionEmbedder(tokenizer=shared_embedder.tokenizer)\ntfidf_resp_a = TFIDFAttentionEmbedder(tokenizer=shared_embedder.tokenizer)\ntfidf_resp_b = TFIDFAttentionEmbedder(tokenizer=shared_embedder.tokenizer)\n\n# Transform each column\nprompt_tfidf = tfidf_prompt.fit_transform([{'text': x['text'], 'raw': x['raw']} for x in embedded_df['prompt_embed']])\nresp_a_tfidf = tfidf_resp_a.fit_transform([{'text': x['text'], 'raw': x['raw']} for x in embedded_df['resp_a_embed']])\nresp_b_tfidf = tfidf_resp_b.fit_transform([{'text': x['text'], 'raw': x['raw']} for x in embedded_df['resp_b_embed']])\n\nprint(f\"Prompt TF-IDF shape: {prompt_tfidf.shape}\")\nprint(f\"Response A TF-IDF shape: {resp_a_tfidf.shape}\")\nprint(f\"Response B TF-IDF shape: {resp_b_tfidf.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T09:00:43.199491Z","iopub.execute_input":"2025-09-19T09:00:43.200308Z","iopub.status.idle":"2025-09-19T09:08:15.482928Z","shell.execute_reply.started":"2025-09-19T09:00:43.200288Z","shell.execute_reply":"2025-09-19T09:08:15.482094Z"}},"outputs":[{"name":"stdout","text":"\nStep 4: Computing TF-IDF attention...\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Prompt TF-IDF shape: (8000, 1536)\nResponse A TF-IDF shape: (8000, 1536)\nResponse B TF-IDF shape: (8000, 1536)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Calculate TF-IDF weighted similarities (one-to-one)\nprint(\"\\nCalculating one-to-one TF-IDF weighted similarities...\")\n\n# Calculate similarities between corresponding pairs\nmean_sim_a = np.array([\n    cosine_similarity(p.reshape(1, -1), a.reshape(1, -1))[0, 0]\n    for p, a in zip(prompt_mean, resp_a_mean)\n])\nmean_sim_b = np.array([\n    cosine_similarity(p.reshape(1, -1), b.reshape(1, -1))[0, 0]\n    for p, b in zip(prompt_mean, resp_b_mean)\n])\n\nmedian_sim_a = np.array([\n    cosine_similarity(p.reshape(1, -1), a.reshape(1, -1))[0, 0]\n    for p, a in zip(prompt_median, resp_a_median)\n])\nmedian_sim_b = np.array([\n    cosine_similarity(p.reshape(1, -1), b.reshape(1, -1))[0, 0]\n    for p, b in zip(prompt_median, resp_b_median)\n])\n\n# Create DataFrame with one-to-one similarities\nsimilarities_df = pd.DataFrame({\n    'tfidf_mean_sim_a': mean_sim_a,\n    'tfidf_mean_sim_b': mean_sim_b,\n    'tfidf_median_sim_a': median_sim_a,\n    'tfidf_median_sim_b': median_sim_b\n})\n\nprint(\"\\nSimilarity shapes:\")\nprint(f\"Number of rows: {len(similarities_df)}\")\nprint(\"\\nFirst few rows of similarities:\")\nprint(similarities_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T10:07:20.704489Z","iopub.execute_input":"2025-09-19T10:07:20.705072Z","iopub.status.idle":"2025-09-19T10:07:26.269506Z","shell.execute_reply.started":"2025-09-19T10:07:20.705047Z","shell.execute_reply":"2025-09-19T10:07:26.268840Z"}},"outputs":[{"name":"stdout","text":"\nCalculating one-to-one TF-IDF weighted similarities...\n\nSimilarity shapes:\nNumber of rows: 8000\n\nFirst few rows of similarities:\n   tfidf_mean_sim_a  tfidf_mean_sim_b  tfidf_median_sim_a  tfidf_median_sim_b\n0          0.429011          0.652190            0.308254            0.613810\n1          0.737144          0.745111            0.410392            0.417107\n2          0.594383          0.657103            0.553738            0.379671\n3          0.000000          0.000000            0.000000            0.000000\n4          0.775325          0.637266            0.713995            0.579175\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# Step 5: Common words features\nprint(\"\\nStep 5: Computing common words features...\")\n\ncommon_words_features = common_words_transformer.fit_transform(X_train)\nprint(f\"Common words features shape: {common_words_features.shape}\")\n\n# Step 6: Combine all features\nprint(\"\\nStep 6: Combining all features...\")\n\n# Convert numpy arrays to sparse matrices if needed\nfrom scipy.sparse import csr_matrix, hstack\n\ndef ensure_sparse(x, dtype=np.float32):\n    if x is None:\n        return None\n    # Convert to numpy array first with consistent dtype\n    if not isinstance(x, (csr_matrix, np.ndarray)):\n        x = np.array(x, dtype=dtype)\n    elif isinstance(x, np.ndarray):\n        x = x.astype(dtype)\n    \n    # If already sparse, ensure correct dtype\n    if isinstance(x, csr_matrix):\n        return x.astype(dtype)\n    \n    # Convert to sparse\n    return csr_matrix(x)\n\n# Print shapes and dtypes before conversion\nprint(\"\\nFeature shapes and types before conversion:\")\nfeatures = [\n    #(\"prompt_stats\", prompt_stats),\n    #(\"resp_a_stats\", resp_a_stats),\n    #(\"resp_b_stats\", resp_b_stats),\n    (\"raw_sim\", raw_sim),\n    (\"mean_sim\", mean_sim),\n    (\"median_sim\", median_sim),\n    (\"tfidf_mean_sim_a\", similarities_df['tfidf_mean_sim_a'].values.reshape(-1,1)),\n    (\"tfidf_mean_sim_b\", similarities_df['tfidf_mean_sim_b'].values.reshape(-1,1)),\n    (\"tfidf_median_sim_a\", similarities_df['tfidf_median_sim_a'].values.reshape(-1,1)),\n    (\"tfidf_median_sim_b\",similarities_df['tfidf_median_sim_b'].values.reshape(-1,1)),\n    (\"common_words\", common_words_features)\n]\n\nfor name, feat in features:\n    if feat is not None:\n        print(f\"{name}: shape={feat.shape}, dtype={feat.dtype}\")\n\n# Convert each feature set to sparse format with consistent dtype\nfeatures_to_stack = []\nfor name, feat in features:\n    if feat is not None:\n        sparse_feat = ensure_sparse(feat)\n        features_to_stack.append(sparse_feat)\n        print(f\"Converted {name}: shape={sparse_feat.shape}, dtype={sparse_feat.dtype}\")\n\n# Print shapes before stacking\nprint(\"\\nFeature shapes before stacking:\")\nfor i, feat in enumerate(features_to_stack):\n    print(f\"Feature {i} shape: {feat.shape}\")\n\n# Combine all the feature matrices\nfinal_features = hstack(features_to_stack)\n\nprint(f\"\\nFinal combined features shape: {final_features.shape}\")\n\n# Convert to DataFrame and save\nX_final = pd.DataFrame(final_features.toarray())\nX_final.to_csv(\"X_final_step_by_step.csv\", index=False)\nprint(\"\\nFeatures saved to 'X_final_step_by_step.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T10:18:13.606792Z","iopub.execute_input":"2025-09-19T10:18:13.607559Z","iopub.status.idle":"2025-09-19T10:18:23.030056Z","shell.execute_reply.started":"2025-09-19T10:18:13.607532Z","shell.execute_reply":"2025-09-19T10:18:23.029435Z"}},"outputs":[{"name":"stdout","text":"\nStep 5: Computing common words features...\nCommon words features shape: (8000, 2)\n\nStep 6: Combining all features...\n\nFeature shapes and types before conversion:\nraw_sim: shape=(8000, 2), dtype=float64\nmean_sim: shape=(8000, 2), dtype=float64\nmedian_sim: shape=(8000, 2), dtype=float64\ntfidf_mean_sim_a: shape=(8000, 1), dtype=float64\ntfidf_mean_sim_b: shape=(8000, 1), dtype=float64\ntfidf_median_sim_a: shape=(8000, 1), dtype=float64\ntfidf_median_sim_b: shape=(8000, 1), dtype=float64\ncommon_words: shape=(8000, 2), dtype=int64\nConverted raw_sim: shape=(8000, 2), dtype=float32\nConverted mean_sim: shape=(8000, 2), dtype=float32\nConverted median_sim: shape=(8000, 2), dtype=float32\nConverted tfidf_mean_sim_a: shape=(8000, 1), dtype=float32\nConverted tfidf_mean_sim_b: shape=(8000, 1), dtype=float32\nConverted tfidf_median_sim_a: shape=(8000, 1), dtype=float32\nConverted tfidf_median_sim_b: shape=(8000, 1), dtype=float32\nConverted common_words: shape=(8000, 2), dtype=float32\n\nFeature shapes before stacking:\nFeature 0 shape: (8000, 2)\nFeature 1 shape: (8000, 2)\nFeature 2 shape: (8000, 2)\nFeature 3 shape: (8000, 1)\nFeature 4 shape: (8000, 1)\nFeature 5 shape: (8000, 1)\nFeature 6 shape: (8000, 1)\nFeature 7 shape: (8000, 2)\n\nFinal combined features shape: (8000, 12)\n\nFeatures saved to 'X_final_step_by_step.csv'\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"#feature_selection = SelectKBest(score_func = chi2, k=6)\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nfeature_selection = SelectKBest(score_func=f_classif, k=6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T10:18:37.189661Z","iopub.execute_input":"2025-09-19T10:18:37.190375Z","iopub.status.idle":"2025-09-19T10:18:37.194021Z","shell.execute_reply.started":"2025-09-19T10:18:37.190348Z","shell.execute_reply":"2025-09-19T10:18:37.193145Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"model = XGBClassifier(\n    objective=\"multi:softprob\",  \n    num_class=3,                  \n    eval_metric=\"mlogloss\",       \n    n_estimators=300,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T10:18:42.709861Z","iopub.execute_input":"2025-09-19T10:18:42.710574Z","iopub.status.idle":"2025-09-19T10:18:42.714230Z","shell.execute_reply.started":"2025-09-19T10:18:42.710546Z","shell.execute_reply":"2025-09-19T10:18:42.713426Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"X_final=pd.read_csv(\"X_final_step_by_step.csv\")\ny_final=y_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T10:18:46.488949Z","iopub.execute_input":"2025-09-19T10:18:46.489570Z","iopub.status.idle":"2025-09-19T10:18:46.506684Z","shell.execute_reply.started":"2025-09-19T10:18:46.489536Z","shell.execute_reply":"2025-09-19T10:18:46.505765Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"X_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T10:18:48.501925Z","iopub.execute_input":"2025-09-19T10:18:48.502552Z","iopub.status.idle":"2025-09-19T10:18:48.516581Z","shell.execute_reply.started":"2025-09-19T10:18:48.502525Z","shell.execute_reply":"2025-09-19T10:18:48.515871Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"             0         1         2         3         4         5         6  \\\n0     0.136883  0.309209  0.291372  0.566971  0.551537  0.705917  0.429011   \n1     0.749165  0.846572  0.978050  0.994332  0.995661  0.997420  0.737144   \n2     0.235749  0.138465  0.432693  0.278598  0.298699 -0.091988  0.594383   \n3    -0.061439  0.014025 -0.152454 -0.030709 -0.198093 -0.099148  0.000000   \n4     0.190093  0.159229  0.335665  0.267016  0.033899  0.017726  0.775325   \n...        ...       ...       ...       ...       ...       ...       ...   \n7995  0.141139  0.102385  0.241410  0.165316  0.029218  0.034537  0.416879   \n7996  0.573346  0.558417  0.858981  0.868501  0.738900  0.735491  0.904394   \n7997  0.248315  0.311559  0.508787  0.610493  0.495215  0.595153  0.724243   \n7998  0.252332  0.242113  0.477212  0.443996  0.305100  0.303021  0.739610   \n7999  0.518814  0.730744  0.866250  0.982388  0.987987  0.997726  0.000000   \n\n             7         8         9    10    11  \n0     0.652190  0.308254  0.613810  15.0  16.0  \n1     0.745111  0.410392  0.417107   1.0   1.0  \n2     0.657103  0.553738  0.379671   2.0   2.0  \n3     0.000000  0.000000  0.000000   1.0   1.0  \n4     0.637266  0.713995  0.579175   8.0   9.0  \n...        ...       ...       ...   ...   ...  \n7995  0.575144  0.219730  0.536430   5.0   7.0  \n7996  0.899713  0.844855  0.847719  17.0  27.0  \n7997  0.676269  0.686671  0.593868  64.0  52.0  \n7998  0.643301  0.537323  0.611364   2.0   2.0  \n7999  0.000000  0.000000  0.000000   6.0   6.0  \n\n[8000 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.136883</td>\n      <td>0.309209</td>\n      <td>0.291372</td>\n      <td>0.566971</td>\n      <td>0.551537</td>\n      <td>0.705917</td>\n      <td>0.429011</td>\n      <td>0.652190</td>\n      <td>0.308254</td>\n      <td>0.613810</td>\n      <td>15.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.749165</td>\n      <td>0.846572</td>\n      <td>0.978050</td>\n      <td>0.994332</td>\n      <td>0.995661</td>\n      <td>0.997420</td>\n      <td>0.737144</td>\n      <td>0.745111</td>\n      <td>0.410392</td>\n      <td>0.417107</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.235749</td>\n      <td>0.138465</td>\n      <td>0.432693</td>\n      <td>0.278598</td>\n      <td>0.298699</td>\n      <td>-0.091988</td>\n      <td>0.594383</td>\n      <td>0.657103</td>\n      <td>0.553738</td>\n      <td>0.379671</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.061439</td>\n      <td>0.014025</td>\n      <td>-0.152454</td>\n      <td>-0.030709</td>\n      <td>-0.198093</td>\n      <td>-0.099148</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.190093</td>\n      <td>0.159229</td>\n      <td>0.335665</td>\n      <td>0.267016</td>\n      <td>0.033899</td>\n      <td>0.017726</td>\n      <td>0.775325</td>\n      <td>0.637266</td>\n      <td>0.713995</td>\n      <td>0.579175</td>\n      <td>8.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>0.141139</td>\n      <td>0.102385</td>\n      <td>0.241410</td>\n      <td>0.165316</td>\n      <td>0.029218</td>\n      <td>0.034537</td>\n      <td>0.416879</td>\n      <td>0.575144</td>\n      <td>0.219730</td>\n      <td>0.536430</td>\n      <td>5.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>0.573346</td>\n      <td>0.558417</td>\n      <td>0.858981</td>\n      <td>0.868501</td>\n      <td>0.738900</td>\n      <td>0.735491</td>\n      <td>0.904394</td>\n      <td>0.899713</td>\n      <td>0.844855</td>\n      <td>0.847719</td>\n      <td>17.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>0.248315</td>\n      <td>0.311559</td>\n      <td>0.508787</td>\n      <td>0.610493</td>\n      <td>0.495215</td>\n      <td>0.595153</td>\n      <td>0.724243</td>\n      <td>0.676269</td>\n      <td>0.686671</td>\n      <td>0.593868</td>\n      <td>64.0</td>\n      <td>52.0</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>0.252332</td>\n      <td>0.242113</td>\n      <td>0.477212</td>\n      <td>0.443996</td>\n      <td>0.305100</td>\n      <td>0.303021</td>\n      <td>0.739610</td>\n      <td>0.643301</td>\n      <td>0.537323</td>\n      <td>0.611364</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>0.518814</td>\n      <td>0.730744</td>\n      <td>0.866250</td>\n      <td>0.982388</td>\n      <td>0.987987</td>\n      <td>0.997726</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.0</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 12 columns</p>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X_final, y_final, cv=3, scoring=\"accuracy\")\nprint(\"Cross-validated Accuracy:\", scores.mean())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T09:09:14.842165Z","iopub.execute_input":"2025-09-19T09:09:14.842428Z","iopub.status.idle":"2025-09-19T09:36:56.103517Z","shell.execute_reply.started":"2025-09-19T09:09:14.842402Z","shell.execute_reply":"2025-09-19T09:36:56.102783Z"}},"outputs":[{"name":"stdout","text":"Cross-validated Accuracy: 0.4079986532066087\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"model.fit(X_final, y_final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T09:36:56.104362Z","iopub.execute_input":"2025-09-19T09:36:56.104586Z","iopub.status.idle":"2025-09-19T09:47:31.644482Z","shell.execute_reply.started":"2025-09-19T09:36:56.104569Z","shell.execute_reply":"2025-09-19T09:47:31.643732Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n              n_jobs=None, num_class=3, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n              n_jobs=None, num_class=3, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=300,\n              n_jobs=None, num_class=3, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"df_test[\"prompt_clean\"] = df_test[\"prompt\"].apply(clean_text_for_common_words)\ndf_test[\"response_a_clean\"] = df_test[\"response_a\"].apply(clean_text_for_common_words)\ndf_test[\"response_b_clean\"] = df_test[\"response_b\"].apply(clean_text_for_common_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T09:47:31.645351Z","iopub.execute_input":"2025-09-19T09:47:31.645650Z","iopub.status.idle":"2025-09-19T09:47:31.672107Z","shell.execute_reply.started":"2025-09-19T09:47:31.645630Z","shell.execute_reply":"2025-09-19T09:47:31.671061Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}