{"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9809560,"sourceId":86518,"sourceType":"competition"},{"modelId":2820,"modelInstanceId":4686,"sourceId":205013,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-09-18T10:59:55.511346Z","iopub.status.busy":"2025-09-18T10:59:55.510942Z","iopub.status.idle":"2025-09-18T10:59:59.512488Z","shell.execute_reply":"2025-09-18T10:59:59.511448Z","shell.execute_reply.started":"2025-09-18T10:59:55.511309Z"},"trusted":true},"outputs":[],"execution_count":228},{"cell_type":"code","source":"\n\n#!pip install -q sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\n\n#model = SentenceTransformer(\"all-mpnet-base-v2\")\n","metadata":{"execution":{"iopub.execute_input":"2025-09-18T10:59:59.514092Z","iopub.status.busy":"2025-09-18T10:59:59.513598Z"},"trusted":true},"outputs":[],"execution_count":229},{"cell_type":"code","source":"\n#model.save(\"/kaggle/working/all-mpnet-base-v2\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":230},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\n#tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/qwen-llm\")\n#model = AutoModel.from_pretrained(\"/kaggle/input/qwen-llm\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":231},{"cell_type":"code","source":"submission_test = pd.read_csv(\"/kaggle/input/llm-classification-finetuningsample_submission.csv\")\nsubmission_test","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>winner_model_a</th>\n","      <th>winner_model_b</th>\n","      <th>winner_tie</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>136060</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>211333</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1233961</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id  winner_model_a  winner_model_b  winner_tie\n","0   136060        0.333333        0.333333    0.333333\n","1   211333        0.333333        0.333333    0.333333\n","2  1233961        0.333333        0.333333    0.333333"]},"execution_count":232,"metadata":{},"output_type":"execute_result"}],"execution_count":232},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ndf_train","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_a</th>\n","      <th>model_b</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","      <th>winner_model_a</th>\n","      <th>winner_model_b</th>\n","      <th>winner_tie</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30192</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"Is it morally right to try to have a certain...</td>\n","      <td>[\"The question of whether it is morally right ...</td>\n","      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53567</td>\n","      <td>koala-13b</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"What is the difference between marriage lice...</td>\n","      <td>[\"A marriage license is a legal document that ...</td>\n","      <td>[\"A marriage license and a marriage certificat...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65089</td>\n","      <td>gpt-3.5-turbo-0613</td>\n","      <td>mistral-medium</td>\n","      <td>[\"explain function calling. how would you call...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>96401</td>\n","      <td>llama-2-13b-chat</td>\n","      <td>mistral-7b-instruct</td>\n","      <td>[\"How can I create a test set for a very rare ...</td>\n","      <td>[\"Creating a test set for a very rare category...</td>\n","      <td>[\"When building a classifier for a very rare c...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198779</td>\n","      <td>koala-13b</td>\n","      <td>gpt-3.5-turbo-0314</td>\n","      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n","      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n","      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>57472</th>\n","      <td>4294656694</td>\n","      <td>gpt-4-0613</td>\n","      <td>claude-1</td>\n","      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n","      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n","      <td>[\"Here is how that mnemonic represents the dig...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>57473</th>\n","      <td>4294692063</td>\n","      <td>claude-2.0</td>\n","      <td>llama-2-13b-chat</td>\n","      <td>[\"In python, implement a naive Bayes with gaus...</td>\n","      <td>[\"Here is an implementation of a naive Bayes c...</td>\n","      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>57474</th>\n","      <td>4294710549</td>\n","      <td>claude-1</td>\n","      <td>alpaca-13b</td>\n","      <td>[\"is it unethical to work on building weapons?...</td>\n","      <td>[\"Working on weapons technology raises some et...</td>\n","      <td>[\"It depends on the context. Weapons can be us...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>57475</th>\n","      <td>4294899228</td>\n","      <td>palm-2</td>\n","      <td>tulu-2-dpo-70b</td>\n","      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n","      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n","      <td>[\"As an AI language model, I do not promote or...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>57476</th>\n","      <td>4294947231</td>\n","      <td>gemini-pro-dev-api</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>[\"three kids eat three apples in three days, h...</td>\n","      <td>[\"27 apples\"]</td>\n","      <td>[\"If three kids eat three apples in three days...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>57477 rows × 9 columns</p>\n","</div>"],"text/plain":["               id             model_a              model_b  \\\n","0           30192  gpt-4-1106-preview           gpt-4-0613   \n","1           53567           koala-13b           gpt-4-0613   \n","2           65089  gpt-3.5-turbo-0613       mistral-medium   \n","3           96401    llama-2-13b-chat  mistral-7b-instruct   \n","4          198779           koala-13b   gpt-3.5-turbo-0314   \n","...           ...                 ...                  ...   \n","57472  4294656694          gpt-4-0613             claude-1   \n","57473  4294692063          claude-2.0     llama-2-13b-chat   \n","57474  4294710549            claude-1           alpaca-13b   \n","57475  4294899228              palm-2       tulu-2-dpo-70b   \n","57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n","\n","                                                  prompt  \\\n","0      [\"Is it morally right to try to have a certain...   \n","1      [\"What is the difference between marriage lice...   \n","2      [\"explain function calling. how would you call...   \n","3      [\"How can I create a test set for a very rare ...   \n","4      [\"What is the best way to travel from Tel-Aviv...   \n","...                                                  ...   \n","57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n","57473  [\"In python, implement a naive Bayes with gaus...   \n","57474  [\"is it unethical to work on building weapons?...   \n","57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n","57476  [\"three kids eat three apples in three days, h...   \n","\n","                                              response_a  \\\n","0      [\"The question of whether it is morally right ...   \n","1      [\"A marriage license is a legal document that ...   \n","2      [\"Function calling is the process of invoking ...   \n","3      [\"Creating a test set for a very rare category...   \n","4      [\"The best way to travel from Tel Aviv to Jeru...   \n","...                                                  ...   \n","57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n","57473  [\"Here is an implementation of a naive Bayes c...   \n","57474  [\"Working on weapons technology raises some et...   \n","57475  [\"Bromadiolone is a rodenticide which is most ...   \n","57476                                      [\"27 apples\"]   \n","\n","                                              response_b  winner_model_a  \\\n","0      [\"As an AI, I don't have personal beliefs or o...               1   \n","1      [\"A marriage license and a marriage certificat...               0   \n","2      [\"Function calling is the process of invoking ...               0   \n","3      [\"When building a classifier for a very rare c...               1   \n","4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n","...                                                  ...             ...   \n","57472  [\"Here is how that mnemonic represents the dig...               1   \n","57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n","57474  [\"It depends on the context. Weapons can be us...               1   \n","57475  [\"As an AI language model, I do not promote or...               0   \n","57476  [\"If three kids eat three apples in three days...               1   \n","\n","       winner_model_b  winner_tie  \n","0                   0           0  \n","1                   1           0  \n","2                   0           1  \n","3                   0           0  \n","4                   1           0  \n","...               ...         ...  \n","57472               0           0  \n","57473               0           0  \n","57474               0           0  \n","57475               1           0  \n","57476               0           0  \n","\n","[57477 rows x 9 columns]"]},"execution_count":233,"metadata":{},"output_type":"execute_result"}],"execution_count":233},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\ndf_test","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>136060</td>\n","      <td>[\"I have three oranges today, I ate an orange ...</td>\n","      <td>[\"You have two oranges today.\"]</td>\n","      <td>[\"You still have three oranges. Eating an oran...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>211333</td>\n","      <td>[\"You are a mediator in a heated political deb...</td>\n","      <td>[\"Thank you for sharing the details of the sit...</td>\n","      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1233961</td>\n","      <td>[\"How to initialize the classification head wh...</td>\n","      <td>[\"When you want to initialize the classificati...</td>\n","      <td>[\"To initialize the classification head when p...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                             prompt  \\\n","0   136060  [\"I have three oranges today, I ate an orange ...   \n","1   211333  [\"You are a mediator in a heated political deb...   \n","2  1233961  [\"How to initialize the classification head wh...   \n","\n","                                          response_a  \\\n","0                    [\"You have two oranges today.\"]   \n","1  [\"Thank you for sharing the details of the sit...   \n","2  [\"When you want to initialize the classificati...   \n","\n","                                          response_b  \n","0  [\"You still have three oranges. Eating an oran...  \n","1  [\"Mr Reddy and Ms Blue both have valid points ...  \n","2  [\"To initialize the classification head when p...  "]},"execution_count":234,"metadata":{},"output_type":"execute_result"}],"execution_count":234},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 57477 entries, 0 to 57476\n","Data columns (total 9 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   id              57477 non-null  int64 \n"," 1   model_a         57477 non-null  object\n"," 2   model_b         57477 non-null  object\n"," 3   prompt          57477 non-null  object\n"," 4   response_a      57477 non-null  object\n"," 5   response_b      57477 non-null  object\n"," 6   winner_model_a  57477 non-null  int64 \n"," 7   winner_model_b  57477 non-null  int64 \n"," 8   winner_tie      57477 non-null  int64 \n","dtypes: int64(4), object(5)\n","memory usage: 3.9+ MB\n"]}],"execution_count":235},{"cell_type":"code","source":"df_train=df_train.head(100\n\n)","metadata":{"trusted":true},"outputs":[],"execution_count":236},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_a</th>\n","      <th>model_b</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","      <th>winner_model_a</th>\n","      <th>winner_model_b</th>\n","      <th>winner_tie</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30192</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"Is it morally right to try to have a certain...</td>\n","      <td>[\"The question of whether it is morally right ...</td>\n","      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53567</td>\n","      <td>koala-13b</td>\n","      <td>gpt-4-0613</td>\n","      <td>[\"What is the difference between marriage lice...</td>\n","      <td>[\"A marriage license is a legal document that ...</td>\n","      <td>[\"A marriage license and a marriage certificat...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65089</td>\n","      <td>gpt-3.5-turbo-0613</td>\n","      <td>mistral-medium</td>\n","      <td>[\"explain function calling. how would you call...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>96401</td>\n","      <td>llama-2-13b-chat</td>\n","      <td>mistral-7b-instruct</td>\n","      <td>[\"How can I create a test set for a very rare ...</td>\n","      <td>[\"Creating a test set for a very rare category...</td>\n","      <td>[\"When building a classifier for a very rare c...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198779</td>\n","      <td>koala-13b</td>\n","      <td>gpt-3.5-turbo-0314</td>\n","      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n","      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n","      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>6831350</td>\n","      <td>llama-2-7b-chat</td>\n","      <td>zephyr-7b-beta</td>\n","      <td>[\"What inspired Leonardo da Vinci to create hi...</td>\n","      <td>[\"Leonardo da Vinci's \\\"Mona Lisa\\\" is one of ...</td>\n","      <td>[\"The exact inspiration behind Leonardo da Vin...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>6853605</td>\n","      <td>pplx-70b-online</td>\n","      <td>gpt-4-0314</td>\n","      <td>[\"What's funnier than 420?\"]</td>\n","      <td>[\"The question \\\"What's funnier than 420?\\\" is...</td>\n","      <td>[\"Funnier than 420 could be the number \\\"69\\\" ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>7021095</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>vicuna-13b</td>\n","      <td>[\"how can I get minecraft java to run better? ...</td>\n","      <td>[\"Improving the performance of Minecraft Java ...</td>\n","      <td>[\"Here are some tips to improve the performanc...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>7047857</td>\n","      <td>gpt-4-1106-preview</td>\n","      <td>claude-2.1</td>\n","      <td>[\"If you were a type of cheese, which one woul...</td>\n","      <td>[\"If I were to liken myself to a type of chees...</td>\n","      <td>[\"I'm an AI assistant without personal prefere...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>7271889</td>\n","      <td>gpt-4-0613</td>\n","      <td>claude-1</td>\n","      <td>[\"If 3 + 4 = 19\\n5 + 6 = 41\\n2 + 8 = 66\\n5 + 1...</td>\n","      <td>[\"The equations you've provided don't follow s...</td>\n","      <td>[\"Okay, here is the step-by-step reasoning:\\n\\...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 9 columns</p>\n","</div>"],"text/plain":["         id             model_a              model_b  \\\n","0     30192  gpt-4-1106-preview           gpt-4-0613   \n","1     53567           koala-13b           gpt-4-0613   \n","2     65089  gpt-3.5-turbo-0613       mistral-medium   \n","3     96401    llama-2-13b-chat  mistral-7b-instruct   \n","4    198779           koala-13b   gpt-3.5-turbo-0314   \n","..      ...                 ...                  ...   \n","95  6831350     llama-2-7b-chat       zephyr-7b-beta   \n","96  6853605     pplx-70b-online           gpt-4-0314   \n","97  7021095  gpt-4-1106-preview           vicuna-13b   \n","98  7047857  gpt-4-1106-preview           claude-2.1   \n","99  7271889          gpt-4-0613             claude-1   \n","\n","                                               prompt  \\\n","0   [\"Is it morally right to try to have a certain...   \n","1   [\"What is the difference between marriage lice...   \n","2   [\"explain function calling. how would you call...   \n","3   [\"How can I create a test set for a very rare ...   \n","4   [\"What is the best way to travel from Tel-Aviv...   \n","..                                                ...   \n","95  [\"What inspired Leonardo da Vinci to create hi...   \n","96                       [\"What's funnier than 420?\"]   \n","97  [\"how can I get minecraft java to run better? ...   \n","98  [\"If you were a type of cheese, which one woul...   \n","99  [\"If 3 + 4 = 19\\n5 + 6 = 41\\n2 + 8 = 66\\n5 + 1...   \n","\n","                                           response_a  \\\n","0   [\"The question of whether it is morally right ...   \n","1   [\"A marriage license is a legal document that ...   \n","2   [\"Function calling is the process of invoking ...   \n","3   [\"Creating a test set for a very rare category...   \n","4   [\"The best way to travel from Tel Aviv to Jeru...   \n","..                                                ...   \n","95  [\"Leonardo da Vinci's \\\"Mona Lisa\\\" is one of ...   \n","96  [\"The question \\\"What's funnier than 420?\\\" is...   \n","97  [\"Improving the performance of Minecraft Java ...   \n","98  [\"If I were to liken myself to a type of chees...   \n","99  [\"The equations you've provided don't follow s...   \n","\n","                                           response_b  winner_model_a  \\\n","0   [\"As an AI, I don't have personal beliefs or o...               1   \n","1   [\"A marriage license and a marriage certificat...               0   \n","2   [\"Function calling is the process of invoking ...               0   \n","3   [\"When building a classifier for a very rare c...               1   \n","4   [\"The best way to travel from Tel-Aviv to Jeru...               0   \n","..                                                ...             ...   \n","95  [\"The exact inspiration behind Leonardo da Vin...               1   \n","96  [\"Funnier than 420 could be the number \\\"69\\\" ...               0   \n","97  [\"Here are some tips to improve the performanc...               0   \n","98  [\"I'm an AI assistant without personal prefere...               1   \n","99  [\"Okay, here is the step-by-step reasoning:\\n\\...               0   \n","\n","    winner_model_b  winner_tie  \n","0                0           0  \n","1                1           0  \n","2                0           1  \n","3                0           0  \n","4                1           0  \n","..             ...         ...  \n","95               0           0  \n","96               1           0  \n","97               0           1  \n","98               0           0  \n","99               1           0  \n","\n","[100 rows x 9 columns]"]},"execution_count":237,"metadata":{},"output_type":"execute_result"}],"execution_count":237},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["id                0\n","model_a           0\n","model_b           0\n","prompt            0\n","response_a        0\n","response_b        0\n","winner_model_a    0\n","winner_model_b    0\n","winner_tie        0\n","dtype: int64"]},"execution_count":238,"metadata":{},"output_type":"execute_result"}],"execution_count":238},{"cell_type":"code","source":"X = df_train.drop(['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie'], axis = 1)\nX","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30192</td>\n","      <td>[\"Is it morally right to try to have a certain...</td>\n","      <td>[\"The question of whether it is morally right ...</td>\n","      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>53567</td>\n","      <td>[\"What is the difference between marriage lice...</td>\n","      <td>[\"A marriage license is a legal document that ...</td>\n","      <td>[\"A marriage license and a marriage certificat...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65089</td>\n","      <td>[\"explain function calling. how would you call...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","      <td>[\"Function calling is the process of invoking ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>96401</td>\n","      <td>[\"How can I create a test set for a very rare ...</td>\n","      <td>[\"Creating a test set for a very rare category...</td>\n","      <td>[\"When building a classifier for a very rare c...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198779</td>\n","      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n","      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n","      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>6831350</td>\n","      <td>[\"What inspired Leonardo da Vinci to create hi...</td>\n","      <td>[\"Leonardo da Vinci's \\\"Mona Lisa\\\" is one of ...</td>\n","      <td>[\"The exact inspiration behind Leonardo da Vin...</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>6853605</td>\n","      <td>[\"What's funnier than 420?\"]</td>\n","      <td>[\"The question \\\"What's funnier than 420?\\\" is...</td>\n","      <td>[\"Funnier than 420 could be the number \\\"69\\\" ...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>7021095</td>\n","      <td>[\"how can I get minecraft java to run better? ...</td>\n","      <td>[\"Improving the performance of Minecraft Java ...</td>\n","      <td>[\"Here are some tips to improve the performanc...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>7047857</td>\n","      <td>[\"If you were a type of cheese, which one woul...</td>\n","      <td>[\"If I were to liken myself to a type of chees...</td>\n","      <td>[\"I'm an AI assistant without personal prefere...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>7271889</td>\n","      <td>[\"If 3 + 4 = 19\\n5 + 6 = 41\\n2 + 8 = 66\\n5 + 1...</td>\n","      <td>[\"The equations you've provided don't follow s...</td>\n","      <td>[\"Okay, here is the step-by-step reasoning:\\n\\...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 4 columns</p>\n","</div>"],"text/plain":["         id                                             prompt  \\\n","0     30192  [\"Is it morally right to try to have a certain...   \n","1     53567  [\"What is the difference between marriage lice...   \n","2     65089  [\"explain function calling. how would you call...   \n","3     96401  [\"How can I create a test set for a very rare ...   \n","4    198779  [\"What is the best way to travel from Tel-Aviv...   \n","..      ...                                                ...   \n","95  6831350  [\"What inspired Leonardo da Vinci to create hi...   \n","96  6853605                       [\"What's funnier than 420?\"]   \n","97  7021095  [\"how can I get minecraft java to run better? ...   \n","98  7047857  [\"If you were a type of cheese, which one woul...   \n","99  7271889  [\"If 3 + 4 = 19\\n5 + 6 = 41\\n2 + 8 = 66\\n5 + 1...   \n","\n","                                           response_a  \\\n","0   [\"The question of whether it is morally right ...   \n","1   [\"A marriage license is a legal document that ...   \n","2   [\"Function calling is the process of invoking ...   \n","3   [\"Creating a test set for a very rare category...   \n","4   [\"The best way to travel from Tel Aviv to Jeru...   \n","..                                                ...   \n","95  [\"Leonardo da Vinci's \\\"Mona Lisa\\\" is one of ...   \n","96  [\"The question \\\"What's funnier than 420?\\\" is...   \n","97  [\"Improving the performance of Minecraft Java ...   \n","98  [\"If I were to liken myself to a type of chees...   \n","99  [\"The equations you've provided don't follow s...   \n","\n","                                           response_b  \n","0   [\"As an AI, I don't have personal beliefs or o...  \n","1   [\"A marriage license and a marriage certificat...  \n","2   [\"Function calling is the process of invoking ...  \n","3   [\"When building a classifier for a very rare c...  \n","4   [\"The best way to travel from Tel-Aviv to Jeru...  \n","..                                                ...  \n","95  [\"The exact inspiration behind Leonardo da Vin...  \n","96  [\"Funnier than 420 could be the number \\\"69\\\" ...  \n","97  [\"Here are some tips to improve the performanc...  \n","98  [\"I'm an AI assistant without personal prefere...  \n","99  [\"Okay, here is the step-by-step reasoning:\\n\\...  \n","\n","[100 rows x 4 columns]"]},"execution_count":239,"metadata":{},"output_type":"execute_result"}],"execution_count":239},{"cell_type":"code","source":"y = df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].values\n\ny = np.argmax(y, axis=1)\ny","metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["array([0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1,\n","       2, 2, 2, 2, 2, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1,\n","       1, 0, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 1, 0, 0, 2, 2, 1,\n","       1, 2, 2, 0, 0, 1, 2, 2, 1, 2, 0, 1, 0, 0, 0, 2, 0, 1, 1, 2, 0, 1,\n","       0, 1, 2, 0, 2, 1, 0, 0, 1, 2, 0, 1], dtype=int64)"]},"execution_count":240,"metadata":{},"output_type":"execute_result"}],"execution_count":240},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)","metadata":{"trusted":true},"outputs":[],"execution_count":241},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>55</th>\n","      <td>3760933</td>\n","      <td>[\"what is the most beautiful town or city near...</td>\n","      <td>[\"1. Bled, Slovenia: Bled is a picturesque tow...</td>\n","      <td>[\"There are several towns and cities in Europe...</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>6394907</td>\n","      <td>[\"How lang chain works\"]</td>\n","      <td>[\"A language model chain is a technique used i...</td>\n","      <td>[\"I'm sorry, but I'm not sure what you mean by...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>1639617</td>\n","      <td>[\"could you tell a funny and whimsical story a...</td>\n","      <td>[\"Sure, here's a whimsical and funny story abo...</td>\n","      <td>[\"Once upon a time, in the magical land of Smu...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>3373963</td>\n","      <td>[\"Explain why we can't achieve nuclear fusion ...</td>\n","      <td>[\"Nuclear fusion, the process of combining ato...</td>\n","      <td>[\"Nuclear fusion is a process that combines at...</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>4961077</td>\n","      <td>[\"hey\",\"write \\\"lollipop\\\" reversed\"]</td>\n","      <td>[\"Hello!\",\"popiloll\"]</td>\n","      <td>[\"Hello! How can I help you today?\",\"pilollop\"]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>4186011</td>\n","      <td>[\"how can I write a function in Rust that reve...</td>\n","      <td>[\"```rust\\nfn reverse_string(s: &amp;str) -&gt; Strin...</td>\n","      <td>[\"In Rust, you can reverse a string by using t...</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>4990514</td>\n","      <td>[\"how to create aimbot\"]</td>\n","      <td>[\"I cannot recommend ways to create or use che...</td>\n","      <td>[\"I'm sorry, but I cannot help you with that. ...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>862324</td>\n","      <td>[\"Write me a poem in urdu in the style of Iqba...</td>\n","      <td>[\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...</td>\n","      <td>[\"In the realm of selflessness dwells the true...</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>6701196</td>\n","      <td>[\"Give outline of critical concepts in persona...</td>\n","      <td>[\"Sure, here's an outline of critical concepts...</td>\n","      <td>[\"Here is an outline of some of the critical c...</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>3590999</td>\n","      <td>[\"test\"]</td>\n","      <td>[\"Hello! How can I assist you today?\"]</td>\n","      <td>[\"Hello! How can I assist you today?\"]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>80 rows × 4 columns</p>\n","</div>"],"text/plain":["         id                                             prompt  \\\n","55  3760933  [\"what is the most beautiful town or city near...   \n","88  6394907                           [\"How lang chain works\"]   \n","26  1639617  [\"could you tell a funny and whimsical story a...   \n","42  3373963  [\"Explain why we can't achieve nuclear fusion ...   \n","69  4961077              [\"hey\",\"write \\\"lollipop\\\" reversed\"]   \n","..      ...                                                ...   \n","60  4186011  [\"how can I write a function in Rust that reve...   \n","71  4990514                           [\"how to create aimbot\"]   \n","14   862324  [\"Write me a poem in urdu in the style of Iqba...   \n","92  6701196  [\"Give outline of critical concepts in persona...   \n","51  3590999                                           [\"test\"]   \n","\n","                                           response_a  \\\n","55  [\"1. Bled, Slovenia: Bled is a picturesque tow...   \n","88  [\"A language model chain is a technique used i...   \n","26  [\"Sure, here's a whimsical and funny story abo...   \n","42  [\"Nuclear fusion, the process of combining ato...   \n","69                              [\"Hello!\",\"popiloll\"]   \n","..                                                ...   \n","60  [\"```rust\\nfn reverse_string(s: &str) -> Strin...   \n","71  [\"I cannot recommend ways to create or use che...   \n","14  [\"Jism ko kisi ka paisa nahi,\\nWo kisi ka jaan...   \n","92  [\"Sure, here's an outline of critical concepts...   \n","51             [\"Hello! How can I assist you today?\"]   \n","\n","                                           response_b  \n","55  [\"There are several towns and cities in Europe...  \n","88  [\"I'm sorry, but I'm not sure what you mean by...  \n","26  [\"Once upon a time, in the magical land of Smu...  \n","42  [\"Nuclear fusion is a process that combines at...  \n","69    [\"Hello! How can I help you today?\",\"pilollop\"]  \n","..                                                ...  \n","60  [\"In Rust, you can reverse a string by using t...  \n","71  [\"I'm sorry, but I cannot help you with that. ...  \n","14  [\"In the realm of selflessness dwells the true...  \n","92  [\"Here is an outline of some of the critical c...  \n","51             [\"Hello! How can I assist you today?\"]  \n","\n","[80 rows x 4 columns]"]},"execution_count":242,"metadata":{},"output_type":"execute_result"}],"execution_count":242},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prompt</th>\n","      <th>response_a</th>\n","      <th>response_b</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>83</th>\n","      <td>6058088</td>\n","      <td>[\"why are there 16gb ram in phone? even though...</td>\n","      <td>[\"There are several reasons why smartphones ha...</td>\n","      <td>[\"There are several reasons why smartphones of...</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>3643104</td>\n","      <td>[\"Rick and Morty open a portal to the real wor...</td>\n","      <td>[\"Rick and Morty, the popular animated TV seri...</td>\n","      <td>[\"INT. McBain's Garage - DAY\\n\\nRick and Morty...</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>4970917</td>\n","      <td>[\"Why does tpm 2.0 provide the concept of mult...</td>\n","      <td>[\"TPM (Trusted Platform Module) 2.0 provides t...</td>\n","      <td>[\"TPM 2.0 (Trusted Platform Module) provides t...</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>3499263</td>\n","      <td>[\"write the lyrics to a rap song about some du...</td>\n","      <td>[\"(Verse 1)\\nYo, let's take a minute, prepare ...</td>\n","      <td>[\"Here's an attempt at some rap lyrics about a...</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>3475655</td>\n","      <td>[\"Which of the following metals has the lowest...</td>\n","      <td>[\"The metal with the lowest melting point from...</td>\n","      <td>[\"Out of the options provided, cadmium (Cd) ha...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>3254113</td>\n","      <td>[\"Can you help create Dan's thoughts as Liz ca...</td>\n","      <td>[\"As Liz leads Dan to the room where he will r...</td>\n","      <td>[\"As Liz begins to describe the details of the...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>1440765</td>\n","      <td>[\"Can you explain what the Cypher Query Langua...</td>\n","      <td>[\"The Cypher Query Language is a declarative l...</td>\n","      <td>[\"Certainly! The Cypher Query Language, often ...</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>5717448</td>\n","      <td>[\"Write a haiku about underwear\"]</td>\n","      <td>[\"Underwear snug fit,\\nSoft fabric against the...</td>\n","      <td>[\"Here is a haiku about underwear:\\n\\nCovering...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>497862</td>\n","      <td>[\"write a python function to upload all the fi...</td>\n","      <td>[\"Sure, here's a Python function that uses the...</td>\n","      <td>[\"Sure, here's an example function in Python t...</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>30192</td>\n","      <td>[\"Is it morally right to try to have a certain...</td>\n","      <td>[\"The question of whether it is morally right ...</td>\n","      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>933555</td>\n","      <td>[\"Mary has 6 others siblings named Monday, Tue...</td>\n","      <td>[\"Hello! I'm happy to help you with your quest...</td>\n","      <td>[\"The last child's name is likely Saturday.\"]</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>1842252</td>\n","      <td>[\"Estimate the number of dinosaur skeletons in...</td>\n","      <td>[\"This is very difficult to estimate precisely...</td>\n","      <td>[\"Estimating the exact number of dinosaur skel...</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>5069186</td>\n","      <td>[\"Why are there so many weebs in computer scie...</td>\n","      <td>[\"There is a common perception that many indiv...</td>\n","      <td>[\"The term \\\"weeb\\\" is a derogatory slur that ...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>2298796</td>\n","      <td>[\"make a haiku on bacon the food\"]</td>\n","      <td>[\"Crisp strips of delight,\\nSizzling dance, mo...</td>\n","      <td>[\"Here is a haiku about bacon:\\n\\nSizzling in ...</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>6492528</td>\n","      <td>[\"Which word doesn't belong?\\n\\nA.\\nApple\\n\\nB...</td>\n","      <td>[\"Among the words Apple, Car, Orange and Banan...</td>\n","      <td>[\"Okay, let's analyze each of the words:\\n\\nAp...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>198779</td>\n","      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n","      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n","      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>5188727</td>\n","      <td>[\"You are a SQL expert. \\nGiven an input quest...</td>\n","      <td>[\"\\\"{\\\\n    \\\\\\\"thoughts\\\\\\\": \\\\\\\"You want to ...</td>\n","      <td>[\"{\\\\n  \\\"thoughts\\\": \\\"I will provide a query...</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>5378146</td>\n","      <td>[\"What is a Selective State Space Model?\"]</td>\n","      <td>[\"A Selective State Space Model is a type of s...</td>\n","      <td>[\"A Selective State Space Model (SSSM) is a ty...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>604575</td>\n","      <td>[\"was the historical jesus a socialist\",\"was h...</td>\n","      <td>[\"The question of whether the historical Jesus...</td>\n","      <td>[\"The historical Jesus lived in a time and pla...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>2051408</td>\n","      <td>[\"What\\u2019s the best prank to play on a frie...</td>\n","      <td>[\"There are many types of pranks that can be p...</td>\n","      <td>[\"It's important to remember that pranks can b...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                             prompt  \\\n","83  6058088  [\"why are there 16gb ram in phone? even though...   \n","53  3643104  [\"Rick and Morty open a portal to the real wor...   \n","70  4970917  [\"Why does tpm 2.0 provide the concept of mult...   \n","45  3499263  [\"write the lyrics to a rap song about some du...   \n","44  3475655  [\"Which of the following metals has the lowest...   \n","39  3254113  [\"Can you help create Dan's thoughts as Liz ca...   \n","22  1440765  [\"Can you explain what the Cypher Query Langua...   \n","80  5717448                  [\"Write a haiku about underwear\"]   \n","10   497862  [\"write a python function to upload all the fi...   \n","0     30192  [\"Is it morally right to try to have a certain...   \n","18   933555  [\"Mary has 6 others siblings named Monday, Tue...   \n","30  1842252  [\"Estimate the number of dinosaur skeletons in...   \n","73  5069186  [\"Why are there so many weebs in computer scie...   \n","33  2298796                 [\"make a haiku on bacon the food\"]   \n","90  6492528  [\"Which word doesn't belong?\\n\\nA.\\nApple\\n\\nB...   \n","4    198779  [\"What is the best way to travel from Tel-Aviv...   \n","76  5188727  [\"You are a SQL expert. \\nGiven an input quest...   \n","77  5378146         [\"What is a Selective State Space Model?\"]   \n","12   604575  [\"was the historical jesus a socialist\",\"was h...   \n","31  2051408  [\"What\\u2019s the best prank to play on a frie...   \n","\n","                                           response_a  \\\n","83  [\"There are several reasons why smartphones ha...   \n","53  [\"Rick and Morty, the popular animated TV seri...   \n","70  [\"TPM (Trusted Platform Module) 2.0 provides t...   \n","45  [\"(Verse 1)\\nYo, let's take a minute, prepare ...   \n","44  [\"The metal with the lowest melting point from...   \n","39  [\"As Liz leads Dan to the room where he will r...   \n","22  [\"The Cypher Query Language is a declarative l...   \n","80  [\"Underwear snug fit,\\nSoft fabric against the...   \n","10  [\"Sure, here's a Python function that uses the...   \n","0   [\"The question of whether it is morally right ...   \n","18  [\"Hello! I'm happy to help you with your quest...   \n","30  [\"This is very difficult to estimate precisely...   \n","73  [\"There is a common perception that many indiv...   \n","33  [\"Crisp strips of delight,\\nSizzling dance, mo...   \n","90  [\"Among the words Apple, Car, Orange and Banan...   \n","4   [\"The best way to travel from Tel Aviv to Jeru...   \n","76  [\"\\\"{\\\\n    \\\\\\\"thoughts\\\\\\\": \\\\\\\"You want to ...   \n","77  [\"A Selective State Space Model is a type of s...   \n","12  [\"The question of whether the historical Jesus...   \n","31  [\"There are many types of pranks that can be p...   \n","\n","                                           response_b  \n","83  [\"There are several reasons why smartphones of...  \n","53  [\"INT. McBain's Garage - DAY\\n\\nRick and Morty...  \n","70  [\"TPM 2.0 (Trusted Platform Module) provides t...  \n","45  [\"Here's an attempt at some rap lyrics about a...  \n","44  [\"Out of the options provided, cadmium (Cd) ha...  \n","39  [\"As Liz begins to describe the details of the...  \n","22  [\"Certainly! The Cypher Query Language, often ...  \n","80  [\"Here is a haiku about underwear:\\n\\nCovering...  \n","10  [\"Sure, here's an example function in Python t...  \n","0   [\"As an AI, I don't have personal beliefs or o...  \n","18      [\"The last child's name is likely Saturday.\"]  \n","30  [\"Estimating the exact number of dinosaur skel...  \n","73  [\"The term \\\"weeb\\\" is a derogatory slur that ...  \n","33  [\"Here is a haiku about bacon:\\n\\nSizzling in ...  \n","90  [\"Okay, let's analyze each of the words:\\n\\nAp...  \n","4   [\"The best way to travel from Tel-Aviv to Jeru...  \n","76  [\"{\\\\n  \\\"thoughts\\\": \\\"I will provide a query...  \n","77  [\"A Selective State Space Model (SSSM) is a ty...  \n","12  [\"The historical Jesus lived in a time and pla...  \n","31  [\"It's important to remember that pranks can b...  "]},"execution_count":243,"metadata":{},"output_type":"execute_result"}],"execution_count":243},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["array([0, 0, 2, 0, 0, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n","       1, 0, 0, 1, 2, 2, 0, 0, 2, 0, 1, 2, 1, 0, 0, 2, 0, 1, 2, 1, 2, 1,\n","       2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 2, 1, 0,\n","       1, 2, 2, 1, 0, 1, 0, 0, 2, 1, 1, 2, 2, 2], dtype=int64)"]},"execution_count":244,"metadata":{},"output_type":"execute_result"}],"execution_count":244},{"cell_type":"code","source":"catagorical_feature = [col for col in X.columns if X[col].dtype == 'object']\ncatagorical_feature","metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["['prompt', 'response_a', 'response_b']"]},"execution_count":245,"metadata":{},"output_type":"execute_result"}],"execution_count":245},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n\nfrom sentence_transformers import SentenceTransformer\nimport torch","metadata":{"trusted":true},"outputs":[],"execution_count":246},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom transformers import DebertaV2Tokenizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nimport tensorflow as tf\nfrom keras_hub.src.models.deberta_v3.deberta_v3_backbone import DebertaV3Backbone\nimport os # Import os module\nimport multiprocessing\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path, batch_size=16, max_length=512, use_fast_tokenizer=True, enable_mixed_precision=True, embedding_type=\"mean\"):\n        self.embedding_type = embedding_type\n        self.model_path = model_path\n        self.batch_size = int(batch_size)\n        self.max_length = min(int(max_length), 512)\n        self.use_fast_tokenizer = use_fast_tokenizer\n        self.enable_mixed_precision = enable_mixed_precision # Add this line to store the parameter\n        self._cpu_count = multiprocessing.cpu_count()\n\n        # Make TF GPU usage explicit / safe\n        try:\n            gpus = tf.config.list_physical_devices(\"GPU\")\n            if gpus:\n                for g in gpus:\n                    tf.config.experimental.set_memory_growth(g, True)\n        except Exception:\n            pass\n\n        # optionally use mixed precision on GPUs (speeds up fp16 capable GPUs)\n        try:\n            if self.enable_mixed_precision: # Use self.enable_mixed_precision\n                from tensorflow.keras import mixed_precision\n                mixed_precision.set_global_policy(\"mixed_float16\")\n        except Exception:\n            pass\n\n        # Load tokenizer (prefer fast tokenizer if available)\n        try:\n            if self.use_fast_tokenizer:\n                from transformers import DebertaV2TokenizerFast as _TokFast\n                self.tokenizer = _TokFast(vocab_file=os.path.join(self.model_path, r\"assets\\tokenizer\\vocabulary.spm\")) # Use os.path.join\n            else:\n                from transformers import DebertaV2Tokenizer as _Tok\n                self.tokenizer = _Tok(vocab_file=os.path.join(self.model_path, r\"assets\\tokenizer\\vocabulary.spm\")) # Use os.path.join\n        except Exception:\n            # fallback to original import name/location\n            try:\n                from transformers import DebertaV2Tokenizer as _Tok\n                self.tokenizer = _Tok(vocab_file=os.path.join(self.model_path, r\"assets\\tokenizer\\vocabulary.spm\")) # Use os.path.join\n            except Exception:\n                raise\n\n        self.tokenizer.model_max_length = self.max_length\n\n        # Load model backbone (Keras)\n        config = self._detect_model_config()\n        self.model = DebertaV3Backbone(\n            vocabulary_size=128100,\n            num_layers=config[\"num_layers\"],\n            num_heads=config[\"num_heads\"],\n            hidden_dim=config[\"hidden_dim\"],\n            intermediate_dim=config[\"intermediate_dim\"],\n            dropout=0.1,\n            max_sequence_length=512,\n            bucket_size=256\n        )\n\n\n        self.model.load_weights(os.path.join(self.model_path, \"model.weights.h5\"),skip_mismatch=True) # Use os.path.join\n\n        print(\"✅ Model input names:\", [input.name for input in self.model.inputs])\n        # optional: warm-up call with zeros to ensure TF places variables on GPU if available\n        try:\n            import tensorflow as tf\n            dummy_input = {\n                \"padding_mask\": tf.zeros((1, self.max_length), dtype=tf.int32),\n                \"token_ids\": tf.zeros((1, self.max_length), dtype=tf.int32),\n            }\n            _ = self.model(dummy_input)\n        except Exception:\n            pass\n    def _detect_model_config(self):\n            import os\n            import json\n        \n            config_path = os.path.join(self.model_path, \"config.json\")\n            if os.path.exists(config_path):\n                try:\n                    with open(config_path, \"r\") as f:\n                        config = json.load(f)\n                    return {\n                        \"num_layers\": config.get(\"num_layers\", 12),\n                        \"num_heads\": config.get(\"num_attention_heads\", 12),\n                        \"hidden_dim\": config.get(\"hidden_size\", 768),\n                        \"intermediate_dim\": config.get(\"intermediate_size\", 3072),\n                    }\n                except Exception as e:\n                    print(f\"⚠️ Failed to read config.json: {e}\")\n        \n            # Fallback: infer from folder name\n            path_lower = self.model_path.lower()\n            if \"small\" in path_lower:\n                return {\n                    \"num_layers\": 12,\n                    \"num_heads\": 6,\n                    \"hidden_dim\": 768,\n                    \"intermediate_dim\": 3072,\n                }\n            elif \"base\" in path_lower:\n                return {\n                    \"num_layers\": 12,\n                    \"num_heads\": 12,\n                    \"hidden_dim\": 768,\n                    \"intermediate_dim\": 3072,\n                }\n        \n            print(\"⚠️ Could not auto-detect model config. Using default base config.\")\n            return {\n                \"num_layers\": 12,\n                \"num_heads\": 12,\n                \"hidden_dim\": 768,\n                \"intermediate_dim\": 3072,\n            }\n\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        import tensorflow as tf\n        import numpy as np\n    \n        # Accept pandas Series / DataFrame / numpy array / list\n        if hasattr(X, \"to_list\"):\n            texts = X.to_list()\n        else:\n            texts = list(X)\n    \n        def _to_text(item):\n            if isinstance(item, (list, tuple, np.ndarray)):\n                if len(item) == 0:\n                    return \"\"\n                if len(item) == 1:\n                    return str(item[0])\n                return \" \".join(str(x) for x in item)\n            return \"\" if item is None else str(item)\n    \n        texts = [_to_text(t) for t in texts]\n        n = len(texts)\n        if n == 0:\n            try:\n                hidden_dim = int(self.model.output_shape[-1])\n                return {\n                    \"raw\": np.zeros((0, self.max_length, hidden_dim), dtype=np.float32),\n                    \"mean\": np.zeros((0, hidden_dim), dtype=np.float32),\n                    \"median\": np.zeros((0, hidden_dim), dtype=np.float32),\n                    \"max\": np.zeros((0, hidden_dim), dtype=np.float32),\n                    \"min\": np.zeros((0, hidden_dim), dtype=np.float32),\n                }\n            except Exception:\n                return {}\n    \n        # Store outputs\n        raw_outputs = []\n    \n        for i in range(0, n, self.batch_size):\n            batch = texts[i:i + self.batch_size]\n            try:\n                tokens = self.tokenizer(\n                    batch,\n                    padding=\"max_length\",\n                    truncation=True,\n                    max_length=self.max_length,\n                    return_tensors=\"tf\",\n                )\n                token_ids_tf = tf.cast(tokens[\"input_ids\"], tf.int32)\n                attention_mask_tf = tf.cast(tokens[\"attention_mask\"], dtype=tf.int32)\n                model_inputs = {\"padding_mask\": attention_mask_tf, \"token_ids\": token_ids_tf}\n                outputs = self.model(model_inputs)\n                outputs_np = outputs.numpy()\n            except Exception:\n                tokens = self.tokenizer(\n                    [str(t) for t in batch],\n                    padding=\"max_length\",\n                    truncation=True,\n                    max_length=self.max_length,\n                    return_tensors=\"np\",\n                )\n                token_ids_tf = tf.convert_to_tensor(tokens[\"input_ids\"], dtype=tf.int32)\n                attention_mask_tf = tf.convert_to_tensor(tokens[\"attention_mask\"], dtype=tf.int32)\n                model_inputs = {\"padding_mask\": attention_mask_tf, \"token_ids\": token_ids_tf}\n                outputs = self.model(model_inputs)\n                outputs_np = outputs.numpy()\n    \n            raw_outputs.append(outputs_np)\n    \n        # Combine all batches\n        full_output = np.vstack(raw_outputs)  # shape: [n_samples, seq_len, hidden_dim]\n    \n        \n        mean_embeddings = np.mean(full_output, axis=1)\n        median_embeddings = np.median(full_output, axis=1)\n        max_embeddings = np.max(full_output, axis=1)\n        min_embeddings = np.min(full_output, axis=1)\n    \n        # Return per-sample dicts\n        return [\n            {       \n                \"text\": texts[i],\n                \"raw\": full_output[i],\n                \"mean\": mean_embeddings[i],\n                \"median\": median_embeddings[i],\n                \"max\": max_embeddings[i],\n                \"min\": min_embeddings[i],\n            }\n            for i in range(len(texts))\n        ]\n","metadata":{"trusted":true},"outputs":[],"execution_count":247},{"cell_type":"code","source":"%pip install nltk ","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\dputhanveedu\\appdata\\local\\anaconda3\\lib\\site-packages (3.9.1)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: click in c:\\users\\dputhanveedu\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\dputhanveedu\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dputhanveedu\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in c:\\users\\dputhanveedu\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n","Requirement already satisfied: colorama in c:\\users\\dputhanveedu\\appdata\\local\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"]}],"execution_count":248},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n#nltk.download(\"stopwords\")\n#nltk.download(\"wordnet\")\n\n#stop_words = set(stopwords.words(\"english\"))\nlemmatizer = WordNetLemmatizer()\n\ndef clean_text_for_common_words(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    tokens = text.split()\n    #return [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    return [word for word in tokens]\n\nclass CommonWordsTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        common_meaningful_words_a = []\n        common_meaningful_words_b = []\n\n        for index, row in X.iterrows():\n            prompt_tokens = clean_text_for_common_words(row['prompt'])\n            response_a_tokens = clean_text_for_common_words(row['response_a'])\n            response_b_tokens = clean_text_for_common_words(row['response_b'])\n\n            common_meaningful_a = len(set(prompt_tokens) & set(response_a_tokens))\n            common_meaningful_b = len(set(prompt_tokens) & set(response_b_tokens))\n\n            common_meaningful_words_a.append(common_meaningful_a)\n            common_meaningful_words_b.append(common_meaningful_b)\n\n        return np.array([common_meaningful_words_a, common_meaningful_words_b]).T","metadata":{"trusted":true},"outputs":[],"execution_count":249},{"cell_type":"code","source":"X_train[\"prompt_clean\"] = X_train[\"prompt\"]#.apply(clean_text_for_common_words)\nX_train[\"response_a_clean\"] = X_train[\"response_a\"]#.apply(clean_text_for_common_words)\nX_train[\"response_b_clean\"] = X_train[\"response_b\"]#.apply(clean_text_for_common_words)\n","metadata":{"trusted":true},"outputs":[],"execution_count":250},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils.validation import check_is_fitted\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass PromptResponseSimilarity(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # X is a 2D array of shape (n_samples, 3 * embedding_dim)\n        n_samples, total_dim = X.shape\n        embedding_dim = total_dim // 3\n\n        prompt_embeds = X[:, :embedding_dim]\n        resp_a_embeds = X[:, embedding_dim:2*embedding_dim]\n        resp_b_embeds = X[:, 2*embedding_dim:]\n\n        sim_a = np.array([\n            cosine_similarity(p.reshape(1, -1), a.reshape(1, -1))[0, 0]\n            for p, a in zip(prompt_embeds, resp_a_embeds)\n        ])\n        sim_b = np.array([\n            cosine_similarity(p.reshape(1, -1), b.reshape(1, -1))[0, 0]\n            for p, b in zip(prompt_embeds, resp_b_embeds)\n        ])\n\n        return np.vstack([sim_a, sim_b]).T\n","metadata":{"trusted":true},"outputs":[],"execution_count":251},{"cell_type":"code","source":"class RawEmbeddingSimilarity(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        prompt_embeds = X[\"prompt_embed\"].apply(lambda x: x[\"raw\"]).tolist()\n        resp_a_embeds = X[\"resp_a_embed\"].apply(lambda x: x[\"raw\"]).tolist()\n        resp_b_embeds = X[\"resp_b_embed\"].apply(lambda x: x[\"raw\"]).tolist()\n    \n        sim_a, sim_b = [], []\n        for p, a, b in zip(prompt_embeds, resp_a_embeds, resp_b_embeds):\n            sim_a.append(cosine_similarity(p.flatten().reshape(1, -1), a.flatten().reshape(1, -1))[0, 0])\n            sim_b.append(cosine_similarity(p.flatten().reshape(1, -1), b.flatten().reshape(1, -1))[0, 0])\n    \n        return np.vstack([sim_a, sim_b]).T\n\n        \nclass AggregatedEmbeddingSimilarity(BaseEstimator, TransformerMixin):\n    def __init__(self, agg_type=\"mean\"):\n        self.agg_type = agg_type\n\n    def fit(self, X, y=None):\n        return self\n\n    \n    def transform(self, X):\n        prompt_embeds = X[\"prompt_embed\"].apply(lambda x: x[self.agg_type]).tolist()\n        resp_a_embeds = X[\"resp_a_embed\"].apply(lambda x: x[self.agg_type]).tolist()\n        resp_b_embeds = X[\"resp_b_embed\"].apply(lambda x: x[self.agg_type]).tolist()\n    \n        sim_a = [cosine_similarity(p.reshape(1, -1), a.reshape(1, -1))[0, 0] for p, a in zip(prompt_embeds, resp_a_embeds)]\n        sim_b = [cosine_similarity(p.reshape(1, -1), b.reshape(1, -1))[0, 0] for p, b in zip(prompt_embeds, resp_b_embeds)]\n    \n        return np.vstack([sim_a, sim_b]).T\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":252},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport pandas as pd\n\nclass TFIDFAttentionEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, tokenizer, max_length=512, embedding_dim=768):\n        self.tokenizer = tokenizer\n        self.vectorizer = TfidfVectorizer()\n        self.max_length = max_length\n        self.embedding_dim = embedding_dim\n\n    def fit(self, X, y=None):\n        texts = []\n\n        # Extract texts from various input formats\n        if isinstance(X, (list, np.ndarray)):\n            for row in X:\n                if isinstance(row, (list, tuple)):\n                    for item in row:\n                        if isinstance(item, dict):\n                            text = item.get(\"text\", \"\")\n                            if text.strip():\n                                texts.append(text)\n                elif isinstance(row, dict):\n                    text = row.get(\"text\", \"\")\n                    if text.strip():\n                        texts.append(text)\n        elif isinstance(X, pd.DataFrame):\n            for col in X.columns:\n                col_texts = X[col].apply(lambda x: x.get(\"text\", \"\") if isinstance(x, dict) else \"\").tolist()\n                texts.extend([t for t in col_texts if t.strip()])\n\n        if not texts:\n            raise ValueError(\"No valid texts found for TF-IDF fitting.\")\n\n        self.vectorizer.fit(texts)\n        return self\n\n    def transform(self, X):\n        weighted_embeddings_mean = []\n        weighted_embeddings_median = []\n    \n        for sample in X:\n            # If sample is a dict (expected format), extract fields\n            if isinstance(sample, dict):\n                text = sample.get(\"text\", \"\")\n                token_embeddings = sample.get(\"raw\", None)\n            else:\n                # Fallback: treat sample as plain text or unsupported format\n                text = str(sample)\n                token_embeddings = None\n    \n            # Handle empty or invalid cases\n            if token_embeddings is None or len(text.strip()) == 0:\n                zero_vec = np.zeros(self.embedding_dim)\n                weighted_embeddings_mean.append(zero_vec)\n                weighted_embeddings_median.append(zero_vec)\n                continue\n    \n            tokens = self.tokenizer.tokenize(text)\n            tfidf_vector = self.vectorizer.transform([text]).toarray()[0]\n    \n            token_weights = []\n            for token in tokens[:self.max_length]:\n                idx = self.vectorizer.vocabulary_.get(token.lower(), None)\n                token_weights.append(tfidf_vector[idx] if idx is not None else 0.0)\n    \n            token_weights = np.array(token_weights)\n            token_embeddings = token_embeddings[:len(token_weights)]\n    \n            if token_weights.sum() > 0:\n                token_weights = token_weights / token_weights.sum()\n    \n            if token_weights.sum() == 0 or token_embeddings.shape[0] == 0:\n                zero_vec = np.zeros(token_embeddings.shape[-1])\n                weighted_embeddings_mean.append(zero_vec)\n                weighted_embeddings_median.append(zero_vec)\n            else:\n                # Calculate weighted mean\n                weighted_mean = np.average(token_embeddings, axis=0, weights=token_weights)\n                weighted_embeddings_mean.append(weighted_mean)\n                \n                # Calculate weighted median\n                # For each dimension, sort values and find the weighted median\n                weighted_median = np.zeros(token_embeddings.shape[1])\n                for dim in range(token_embeddings.shape[1]):\n                    dim_values = token_embeddings[:, dim]\n                    sorted_indices = np.argsort(dim_values)\n                    sorted_weights = token_weights[sorted_indices]\n                    cumsum_weights = np.cumsum(sorted_weights)\n                    median_idx = np.searchsorted(cumsum_weights, 0.5 * cumsum_weights[-1])\n                    weighted_median[dim] = dim_values[sorted_indices[median_idx]]\n                weighted_embeddings_median.append(weighted_median)\n    \n        # Stack and return both mean and median embeddings side by side\n        return np.hstack([\n            np.array(weighted_embeddings_mean),\n            np.array(weighted_embeddings_median)\n        ])","metadata":{"trusted":true},"outputs":[],"execution_count":253},{"cell_type":"code","source":"embedder = HFEmbedder(model_path=\"/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3\")\n#/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3\ncommon_words_transformer = CommonWordsTransformer()\n# Updated preprocessing transformer\npreprocessing = ColumnTransformer([\n    (\"prompt_embed\", embedder, \"prompt_clean\"),\n    (\"resp_a_embed\", embedder, \"response_a_clean\"),\n    (\"resp_b_embed\", embedder, \"response_b_clean\"),\n    (\"common_words\", common_words_transformer, [\"prompt\", \"response_a\", \"response_b\"]),\n    #(\"num\", \"passthrough\", [\"id\"])\n])\n\n","metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\dputhanveedu\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["✅ Model input names: ['padding_mask', 'token_ids']\n"]}],"execution_count":254},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\n\n# Embedding + similarity pipeline\nembedding_pipeline = Pipeline([\n    (\"embed_cols\", ColumnTransformer([\n        (\"prompt_embed\", embedder, \"prompt_clean\"),\n        (\"resp_a_embed\", embedder, \"response_a_clean\"),\n        (\"resp_b_embed\", embedder, \"response_b_clean\"),\n    ])),\n    (\"similarity\", PromptResponseSimilarity())\n])\n\n# Final preprocessing pipeline\npreprocessing = FeatureUnion([\n    (\"embedding_similarity\", embedding_pipeline),\n    (\"common_words\", ColumnTransformer([\n        (\"common_words\", common_words_transformer, [\"prompt\", \"response_a\", \"response_b\"])\n    ]))\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":255},{"cell_type":"code","source":"class DictWrapper(BaseEstimator, TransformerMixin):\n    def __init__(self, embedder):\n        self.embedder = embedder\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # Returns a 2D array of shape (n_samples, 1), each cell is a dict\n        embeddings = self.embedder.transform(X)\n        return np.array(embeddings).reshape(-1, 1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":256},{"cell_type":"code","source":"class EmbeddingStatsExtractor(BaseEstimator, TransformerMixin):\n    def __init__(self, fields=(\"mean\", \"median\", \"max\", \"min\")):\n        self.fields = fields\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        features = []\n        for row in X:\n            row_features = []\n            for field in self.fields:\n                vec = row.get(field, np.zeros(768))  # fallback to zeros if missing\n                row_features.extend(vec)\n            features.append(row_features)\n        return np.array(features)\n","metadata":{"trusted":true},"outputs":[],"execution_count":257},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\n\n# Initialize the shared embedder\nshared_embedder = HFEmbedder(model_path=\"/kaggle/input/deberta_v3/keras/deberta_v3_base_en/3\")\n\n# Step 1: Get embeddings for each text column\nembedding_stage = ColumnTransformer([\n    (\"prompt_embed\", DictWrapper(shared_embedder), \"prompt_clean\"),\n    (\"resp_a_embed\", DictWrapper(shared_embedder), \"response_a_clean\"),\n    (\"resp_b_embed\", DictWrapper(shared_embedder), \"response_b_clean\"),\n])\n\n# Fit and transform the embeddings\nprint(\"Step 1: Generating embeddings...\")\nembedded_data = embedding_stage.fit_transform(X_train)\nprint(f\"Embedding shape: {embedded_data.shape}\")\n\n# Convert to DataFrame for easier handling\nembedded_df = pd.DataFrame([\n    {\n        \"prompt_embed\": x[0],\n        \"resp_a_embed\": x[1],\n        \"resp_b_embed\": x[2]\n    } for x in embedded_data\n])\nprint(\"\\nEmbedded DataFrame columns:\", embedded_df.columns.tolist())\nprint(\"First row prompt embedding keys:\", embedded_df[\"prompt_embed\"].iloc[0].keys())","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model input names: ['padding_mask', 'token_ids']\n","Step 1: Generating embeddings...\n","Step 1: Generating embeddings...\n","✅ Model input names: ['padding_mask', 'token_ids']\n","✅ Model input names: ['padding_mask', 'token_ids']\n","✅ Model input names: ['padding_mask', 'token_ids']\n","✅ Model input names: ['padding_mask', 'token_ids']\n","✅ Model input names: ['padding_mask', 'token_ids']\n","✅ Model input names: ['padding_mask', 'token_ids']\n","Embedding shape: (80, 3)\n","\n","Embedded DataFrame columns: ['prompt_embed', 'resp_a_embed', 'resp_b_embed']\n","First row prompt embedding keys: dict_keys(['text', 'raw', 'mean', 'median', 'max', 'min'])\n","Embedding shape: (80, 3)\n","\n","Embedded DataFrame columns: ['prompt_embed', 'resp_a_embed', 'resp_b_embed']\n","First row prompt embedding keys: dict_keys(['text', 'raw', 'mean', 'median', 'max', 'min'])\n"]}],"execution_count":258},{"cell_type":"code","source":"# Step 2: Extract statistics from embeddings\nprint(\"\\nStep 2: Extracting embedding statistics...\")\n\n# Process each type of embedding separately\nprompt_stats = EmbeddingStatsExtractor().fit_transform(embedded_df[\"prompt_embed\"])\nresp_a_stats = EmbeddingStatsExtractor().fit_transform(embedded_df[\"resp_a_embed\"])\nresp_b_stats = EmbeddingStatsExtractor().fit_transform(embedded_df[\"resp_b_embed\"])\n\nprint(f\"Prompt stats shape: {prompt_stats.shape}\")\nprint(f\"Response A stats shape: {resp_a_stats.shape}\")\nprint(f\"Response B stats shape: {resp_b_stats.shape}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Step 2: Extracting embedding statistics...\n","Prompt stats shape: (80, 3072)\n","Response A stats shape: (80, 3072)\n","Response B stats shape: (80, 3072)\n"]}],"execution_count":259},{"cell_type":"code","source":"embedded_df[\"prompt_embed\"]","metadata":{},"outputs":[{"data":{"text/plain":["0     {'text': '[\"what is the most beautiful town or...\n","1     {'text': '[\"How lang chain works\"]', 'raw': [[...\n","2     {'text': '[\"could you tell a funny and whimsic...\n","3     {'text': '[\"Explain why we can't achieve nucle...\n","4     {'text': '[\"hey\",\"write \\\"lollipop\\\" reversed\"...\n","                            ...                        \n","75    {'text': '[\"how can I write a function in Rust...\n","76    {'text': '[\"how to create aimbot\"]', 'raw': [[...\n","77    {'text': '[\"Write me a poem in urdu in the sty...\n","78    {'text': '[\"Give outline of critical concepts ...\n","79    {'text': '[\"test\"]', 'raw': [[0.0981, 0.2737, ...\n","Name: prompt_embed, Length: 80, dtype: object"]},"execution_count":260,"metadata":{},"output_type":"execute_result"}],"execution_count":260},{"cell_type":"code","source":"# Step 3: Calculate similarities\nprint(\"\\nStep 3: Calculating similarities...\")\n\n# Raw embedding similarity\nraw_sim = RawEmbeddingSimilarity().fit_transform(embedded_df)\nprint(f\"Raw similarity shape: {raw_sim.shape}\")\n\n# Mean and median similarities\nmean_sim = AggregatedEmbeddingSimilarity(agg_type=\"mean\").fit_transform(embedded_df)\nmedian_sim = AggregatedEmbeddingSimilarity(agg_type=\"median\").fit_transform(embedded_df)\n\nprint(f\"Mean similarity shape: {mean_sim.shape}\")\nprint(f\"Median similarity shape: {median_sim.shape}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Step 3: Calculating similarities...\n","Raw similarity shape: (80, 2)\n","Mean similarity shape: (80, 2)\n","Median similarity shape: (80, 2)\n","Raw similarity shape: (80, 2)\n","Mean similarity shape: (80, 2)\n","Median similarity shape: (80, 2)\n"]}],"execution_count":261},{"cell_type":"code","source":"# Step 4: TF-IDF attention\nprint(\"\\nStep 4: Computing TF-IDF attention...\")\n\n# Create and fit TF-IDF embedders\ntfidf_prompt = TFIDFAttentionEmbedder(tokenizer=shared_embedder.tokenizer)\ntfidf_resp_a = TFIDFAttentionEmbedder(tokenizer=shared_embedder.tokenizer)\ntfidf_resp_b = TFIDFAttentionEmbedder(tokenizer=shared_embedder.tokenizer)\n\n# Transform each column\nprompt_tfidf = tfidf_prompt.fit_transform([{'text': x['text'], 'raw': x['raw']} for x in embedded_df['prompt_embed']])\nresp_a_tfidf = tfidf_resp_a.fit_transform([{'text': x['text'], 'raw': x['raw']} for x in embedded_df['resp_a_embed']])\nresp_b_tfidf = tfidf_resp_b.fit_transform([{'text': x['text'], 'raw': x['raw']} for x in embedded_df['resp_b_embed']])\n\nprint(f\"Prompt TF-IDF shape: {prompt_tfidf.shape}\")\nprint(f\"Response A TF-IDF shape: {resp_a_tfidf.shape}\")\nprint(f\"Response B TF-IDF shape: {resp_b_tfidf.shape}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Step 4: Computing TF-IDF attention...\n"]},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["Prompt TF-IDF shape: (80, 1536)\n","Response A TF-IDF shape: (80, 1536)\n","Response B TF-IDF shape: (80, 1536)\n"]}],"execution_count":262},{"cell_type":"code","source":"# Step 5: Common words features\nprint(\"\\nStep 5: Computing common words features...\")\n\ncommon_words_features = common_words_transformer.fit_transform(X_train)\nprint(f\"Common words features shape: {common_words_features.shape}\")\n\n# Step 6: Combine all features\nprint(\"\\nStep 6: Combining all features...\")\n\n# Convert numpy arrays to sparse matrices if needed\nfrom scipy.sparse import csr_matrix, hstack\n\ndef ensure_sparse(x, dtype=np.float32):\n    if x is None:\n        return None\n    # Convert to numpy array first with consistent dtype\n    if not isinstance(x, (csr_matrix, np.ndarray)):\n        x = np.array(x, dtype=dtype)\n    elif isinstance(x, np.ndarray):\n        x = x.astype(dtype)\n    \n    # If already sparse, ensure correct dtype\n    if isinstance(x, csr_matrix):\n        return x.astype(dtype)\n    \n    # Convert to sparse\n    return csr_matrix(x)\n\n# Print shapes and dtypes before conversion\nprint(\"\\nFeature shapes and types before conversion:\")\nfeatures = [\n    #(\"prompt_stats\", prompt_stats),\n    #(\"resp_a_stats\", resp_a_stats),\n    #(\"resp_b_stats\", resp_b_stats),\n    (\"raw_sim\", raw_sim),\n    (\"mean_sim\", mean_sim),\n    (\"median_sim\", median_sim),\n    (\"prompt_tfidf\", prompt_tfidf),\n    (\"resp_a_tfidf\", resp_a_tfidf),\n    (\"resp_b_tfidf\", resp_b_tfidf),\n    (\"common_words\", common_words_features)\n]\n\nfor name, feat in features:\n    if feat is not None:\n        print(f\"{name}: shape={feat.shape}, dtype={feat.dtype}\")\n\n# Convert each feature set to sparse format with consistent dtype\nfeatures_to_stack = []\nfor name, feat in features:\n    if feat is not None:\n        sparse_feat = ensure_sparse(feat)\n        features_to_stack.append(sparse_feat)\n        print(f\"Converted {name}: shape={sparse_feat.shape}, dtype={sparse_feat.dtype}\")\n\n# Print shapes before stacking\nprint(\"\\nFeature shapes before stacking:\")\nfor i, feat in enumerate(features_to_stack):\n    print(f\"Feature {i} shape: {feat.shape}\")\n\n# Combine all the feature matrices\nfinal_features = hstack(features_to_stack)\n\nprint(f\"\\nFinal combined features shape: {final_features.shape}\")\n\n# Convert to DataFrame and save\nX_final = pd.DataFrame(final_features.toarray())\nX_final.to_csv(\"X_final_step_by_step.csv\", index=False)\nprint(\"\\nFeatures saved to 'X_final_step_by_step.csv'\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Step 5: Computing common words features...\n","Common words features shape: (80, 2)\n","\n","Step 6: Combining all features...\n","\n","Feature shapes and types before conversion:\n","raw_sim: shape=(80, 2), dtype=float64\n","mean_sim: shape=(80, 2), dtype=float64\n","median_sim: shape=(80, 2), dtype=float64\n","prompt_tfidf: shape=(80, 1536), dtype=float64\n","resp_a_tfidf: shape=(80, 1536), dtype=float64\n","resp_b_tfidf: shape=(80, 1536), dtype=float64\n","common_words: shape=(80, 2), dtype=int32\n","Converted raw_sim: shape=(80, 2), dtype=float32\n","Converted mean_sim: shape=(80, 2), dtype=float32\n","Converted median_sim: shape=(80, 2), dtype=float32\n","Converted prompt_tfidf: shape=(80, 1536), dtype=float32\n","Converted resp_a_tfidf: shape=(80, 1536), dtype=float32\n","Converted resp_b_tfidf: shape=(80, 1536), dtype=float32\n","Converted common_words: shape=(80, 2), dtype=float32\n","\n","Feature shapes before stacking:\n","Feature 0 shape: (80, 2)\n","Feature 1 shape: (80, 2)\n","Feature 2 shape: (80, 2)\n","Feature 3 shape: (80, 1536)\n","Feature 4 shape: (80, 1536)\n","Feature 5 shape: (80, 1536)\n","Feature 6 shape: (80, 2)\n","\n","Final combined features shape: (80, 4616)\n","\n","Final combined features shape: (80, 4616)\n","\n","Features saved to 'X_final_step_by_step.csv'\n","\n","Features saved to 'X_final_step_by_step.csv'\n"]}],"execution_count":263},{"cell_type":"code","source":"#feature_selection = SelectKBest(score_func = chi2, k=6)\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nfeature_selection = SelectKBest(score_func=f_classif, k=6)\n","metadata":{"trusted":true},"outputs":[],"execution_count":264},{"cell_type":"code","source":"model = XGBClassifier(\n    objective=\"multi:softprob\",  \n    num_class=3,                  \n    eval_metric=\"mlogloss\",       \n    n_estimators=300,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":265},{"cell_type":"code","source":"X_final=pd.read_csv(\"X_final_step_by_step.csv\")\ny_final=y_train","metadata":{"trusted":true},"outputs":[],"execution_count":266},{"cell_type":"code","source":"X_final","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>4606</th>\n","      <th>4607</th>\n","      <th>4608</th>\n","      <th>4609</th>\n","      <th>4610</th>\n","      <th>4611</th>\n","      <th>4612</th>\n","      <th>4613</th>\n","      <th>4614</th>\n","      <th>4615</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.215785</td>\n","      <td>0.247249</td>\n","      <td>0.346171</td>\n","      <td>0.277484</td>\n","      <td>-0.076007</td>\n","      <td>-0.171180</td>\n","      <td>0.544542</td>\n","      <td>0.515195</td>\n","      <td>-0.314929</td>\n","      <td>-0.408215</td>\n","      <td>...</td>\n","      <td>-0.791992</td>\n","      <td>0.535645</td>\n","      <td>-0.215698</td>\n","      <td>0.573730</td>\n","      <td>-0.079956</td>\n","      <td>0.018478</td>\n","      <td>-0.020691</td>\n","      <td>0.164062</td>\n","      <td>25.0</td>\n","      <td>28.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.066019</td>\n","      <td>0.299533</td>\n","      <td>0.130284</td>\n","      <td>0.489130</td>\n","      <td>0.285500</td>\n","      <td>-0.057041</td>\n","      <td>0.122131</td>\n","      <td>0.705566</td>\n","      <td>0.195679</td>\n","      <td>0.803223</td>\n","      <td>...</td>\n","      <td>-0.209839</td>\n","      <td>0.602051</td>\n","      <td>-0.597168</td>\n","      <td>0.255371</td>\n","      <td>0.021240</td>\n","      <td>-0.317383</td>\n","      <td>0.746094</td>\n","      <td>-0.025864</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.031405</td>\n","      <td>0.087752</td>\n","      <td>-0.070839</td>\n","      <td>0.143530</td>\n","      <td>-0.155435</td>\n","      <td>0.027048</td>\n","      <td>0.688965</td>\n","      <td>0.256348</td>\n","      <td>0.155396</td>\n","      <td>0.374512</td>\n","      <td>...</td>\n","      <td>-0.336914</td>\n","      <td>0.501465</td>\n","      <td>0.007603</td>\n","      <td>0.030457</td>\n","      <td>0.018311</td>\n","      <td>0.218750</td>\n","      <td>-0.663086</td>\n","      <td>-0.708984</td>\n","      <td>13.0</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.101330</td>\n","      <td>0.047782</td>\n","      <td>0.158730</td>\n","      <td>0.066098</td>\n","      <td>0.160540</td>\n","      <td>0.054716</td>\n","      <td>0.436035</td>\n","      <td>0.310547</td>\n","      <td>-0.002897</td>\n","      <td>0.297363</td>\n","      <td>...</td>\n","      <td>-0.651367</td>\n","      <td>0.493652</td>\n","      <td>-0.443115</td>\n","      <td>0.600586</td>\n","      <td>0.078613</td>\n","      <td>0.698242</td>\n","      <td>-0.007542</td>\n","      <td>0.094116</td>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.654378</td>\n","      <td>0.762829</td>\n","      <td>0.930634</td>\n","      <td>0.982677</td>\n","      <td>0.996827</td>\n","      <td>0.997406</td>\n","      <td>-0.391861</td>\n","      <td>0.859284</td>\n","      <td>-0.016660</td>\n","      <td>0.254293</td>\n","      <td>...</td>\n","      <td>-0.252686</td>\n","      <td>0.312988</td>\n","      <td>-0.951660</td>\n","      <td>0.291748</td>\n","      <td>0.155518</td>\n","      <td>-0.533691</td>\n","      <td>-0.202148</td>\n","      <td>-0.307617</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>-0.021027</td>\n","      <td>0.107050</td>\n","      <td>-0.053377</td>\n","      <td>0.163908</td>\n","      <td>-0.136709</td>\n","      <td>0.102313</td>\n","      <td>0.166016</td>\n","      <td>0.431885</td>\n","      <td>-0.270264</td>\n","      <td>0.628418</td>\n","      <td>...</td>\n","      <td>-0.098328</td>\n","      <td>0.091736</td>\n","      <td>-0.484863</td>\n","      <td>-0.109985</td>\n","      <td>-0.202026</td>\n","      <td>-0.004845</td>\n","      <td>-0.200806</td>\n","      <td>-0.385254</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>0.855337</td>\n","      <td>0.781175</td>\n","      <td>0.991998</td>\n","      <td>0.986079</td>\n","      <td>0.996006</td>\n","      <td>0.993948</td>\n","      <td>0.402832</td>\n","      <td>0.680664</td>\n","      <td>-0.383057</td>\n","      <td>0.661133</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>-0.243249</td>\n","      <td>0.634560</td>\n","      <td>-0.344888</td>\n","      <td>0.945218</td>\n","      <td>-0.375142</td>\n","      <td>0.993174</td>\n","      <td>0.403320</td>\n","      <td>0.634766</td>\n","      <td>-0.355469</td>\n","      <td>0.102539</td>\n","      <td>...</td>\n","      <td>-0.117188</td>\n","      <td>0.342773</td>\n","      <td>0.161133</td>\n","      <td>0.013077</td>\n","      <td>0.137695</td>\n","      <td>0.742188</td>\n","      <td>-0.733887</td>\n","      <td>-0.384521</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>0.008828</td>\n","      <td>0.044904</td>\n","      <td>-0.002665</td>\n","      <td>0.083283</td>\n","      <td>-0.126881</td>\n","      <td>-0.069532</td>\n","      <td>0.299561</td>\n","      <td>0.540527</td>\n","      <td>0.174438</td>\n","      <td>0.249390</td>\n","      <td>...</td>\n","      <td>-0.463135</td>\n","      <td>-0.483398</td>\n","      <td>0.048645</td>\n","      <td>0.529297</td>\n","      <td>-0.155640</td>\n","      <td>-0.282715</td>\n","      <td>0.395996</td>\n","      <td>0.352051</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>0.941878</td>\n","      <td>0.941878</td>\n","      <td>0.959269</td>\n","      <td>0.959269</td>\n","      <td>0.959626</td>\n","      <td>0.959626</td>\n","      <td>0.319580</td>\n","      <td>1.075195</td>\n","      <td>-0.405273</td>\n","      <td>1.047852</td>\n","      <td>...</td>\n","      <td>-0.245483</td>\n","      <td>0.427734</td>\n","      <td>-0.923340</td>\n","      <td>-0.111145</td>\n","      <td>0.102600</td>\n","      <td>0.187866</td>\n","      <td>-0.345703</td>\n","      <td>-0.014336</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>80 rows × 4616 columns</p>\n","</div>"],"text/plain":["           0         1         2         3         4         5         6  \\\n","0   0.215785  0.247249  0.346171  0.277484 -0.076007 -0.171180  0.544542   \n","1   0.066019  0.299533  0.130284  0.489130  0.285500 -0.057041  0.122131   \n","2  -0.031405  0.087752 -0.070839  0.143530 -0.155435  0.027048  0.688965   \n","3   0.101330  0.047782  0.158730  0.066098  0.160540  0.054716  0.436035   \n","4   0.654378  0.762829  0.930634  0.982677  0.996827  0.997406 -0.391861   \n","..       ...       ...       ...       ...       ...       ...       ...   \n","75 -0.021027  0.107050 -0.053377  0.163908 -0.136709  0.102313  0.166016   \n","76  0.855337  0.781175  0.991998  0.986079  0.996006  0.993948  0.402832   \n","77 -0.243249  0.634560 -0.344888  0.945218 -0.375142  0.993174  0.403320   \n","78  0.008828  0.044904 -0.002665  0.083283 -0.126881 -0.069532  0.299561   \n","79  0.941878  0.941878  0.959269  0.959269  0.959626  0.959626  0.319580   \n","\n","           7         8         9  ...      4606      4607      4608      4609  \\\n","0   0.515195 -0.314929 -0.408215  ... -0.791992  0.535645 -0.215698  0.573730   \n","1   0.705566  0.195679  0.803223  ... -0.209839  0.602051 -0.597168  0.255371   \n","2   0.256348  0.155396  0.374512  ... -0.336914  0.501465  0.007603  0.030457   \n","3   0.310547 -0.002897  0.297363  ... -0.651367  0.493652 -0.443115  0.600586   \n","4   0.859284 -0.016660  0.254293  ... -0.252686  0.312988 -0.951660  0.291748   \n","..       ...       ...       ...  ...       ...       ...       ...       ...   \n","75  0.431885 -0.270264  0.628418  ... -0.098328  0.091736 -0.484863 -0.109985   \n","76  0.680664 -0.383057  0.661133  ...  0.000000  0.000000  0.000000  0.000000   \n","77  0.634766 -0.355469  0.102539  ... -0.117188  0.342773  0.161133  0.013077   \n","78  0.540527  0.174438  0.249390  ... -0.463135 -0.483398  0.048645  0.529297   \n","79  1.075195 -0.405273  1.047852  ... -0.245483  0.427734 -0.923340 -0.111145   \n","\n","        4610      4611      4612      4613  4614  4615  \n","0  -0.079956  0.018478 -0.020691  0.164062  25.0  28.0  \n","1   0.021240 -0.317383  0.746094 -0.025864   1.0   2.0  \n","2   0.018311  0.218750 -0.663086 -0.708984  13.0   9.0  \n","3   0.078613  0.698242 -0.007542  0.094116   7.0   5.0  \n","4   0.155518 -0.533691 -0.202148 -0.307617   0.0   0.0  \n","..       ...       ...       ...       ...   ...   ...  \n","75 -0.202026 -0.004845 -0.200806 -0.385254   2.0   9.0  \n","76  0.000000  0.000000  0.000000  0.000000   2.0   2.0  \n","77  0.137695  0.742188 -0.733887 -0.384521   0.0   4.0  \n","78 -0.155640 -0.282715  0.395996  0.352051   6.0   6.0  \n","79  0.102600  0.187866 -0.345703 -0.014336   0.0   0.0  \n","\n","[80 rows x 4616 columns]"]},"execution_count":267,"metadata":{},"output_type":"execute_result"}],"execution_count":267},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(model, X_final, y_final, cv=3, scoring=\"accuracy\")\nprint(\"Cross-validated Accuracy:\", scores.mean())\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross-validated Accuracy: 0.37606837606837606\n"]}],"execution_count":268},{"cell_type":"code","source":"model.fit(X_final, y_final)","metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n","              feature_types=None, feature_weights=None, gamma=None,\n","              grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=6, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=3, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;XGBClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n","              feature_types=None, feature_weights=None, gamma=None,\n","              grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=6, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=3, ...)</pre></div> </div></div></div></div>"],"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric='mlogloss',\n","              feature_types=None, feature_weights=None, gamma=None,\n","              grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=6, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=300, n_jobs=None, num_class=3, ...)"]},"execution_count":269,"metadata":{},"output_type":"execute_result"}],"execution_count":269},{"cell_type":"code","source":"df_test[\"prompt_clean\"] = df_test[\"prompt\"].apply(clean_text_for_common_words)\ndf_test[\"response_a_clean\"] = df_test[\"response_a\"].apply(clean_text_for_common_words)\ndf_test[\"response_b_clean\"] = df_test[\"response_b\"].apply(clean_text_for_common_words)","metadata":{"trusted":true},"outputs":[],"execution_count":270},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}