{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhaneshkp/NLP/blob/main/Tapas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f2fff661",
      "metadata": {
        "id": "f2fff661",
        "outputId": "01482264-1979-426f-9594-96e832d3bc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
            "0       1  CA-2018-152156   11/8/2018  11/11/2018    Second Class    CG-12520   \n",
            "1       2  CA-2018-152156   11/8/2018  11/11/2018    Second Class    CG-12520   \n",
            "2       3  CA-2018-138688   6/12/2018   6/16/2018    Second Class    DV-13045   \n",
            "3       4  US-2017-108966  10/11/2017  10/18/2017  Standard Class    SO-20335   \n",
            "4       5  US-2017-108966  10/11/2017  10/18/2017  Standard Class    SO-20335   \n",
            "\n",
            "     Customer Name    Segment Country/Region             City  ...  \\\n",
            "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
            "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
            "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
            "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
            "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
            "\n",
            "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
            "0     42420.0   South  FUR-BO-10001798        Furniture    Bookcases   \n",
            "1     42420.0   South  FUR-CH-10000454        Furniture       Chairs   \n",
            "2     90036.0    West  OFF-LA-10000240  Office Supplies       Labels   \n",
            "3     33311.0   South  FUR-TA-10000577        Furniture       Tables   \n",
            "4     33311.0   South  OFF-ST-10000760  Office Supplies      Storage   \n",
            "\n",
            "                                        Product Name     Sales  Quantity  \\\n",
            "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
            "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
            "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
            "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
            "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
            "\n",
            "   Discount    Profit  \n",
            "0      0.00   41.9136  \n",
            "1      0.00  219.5820  \n",
            "2      0.00    6.8714  \n",
            "3      0.45 -383.0310  \n",
            "4      0.20    2.5164  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "import chardet\n",
        "import pandas as pd\n",
        "# Detect the encoding of the file\n",
        "with open(\"orders.csv\", \"rb\") as f:\n",
        "    result = chardet.detect(f.read())\n",
        "\n",
        "# Read the CSV file with the detected encoding\n",
        "order_data = pd.read_csv(\"orders.csv\", encoding=result['encoding'])\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(order_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c2bbbc07",
      "metadata": {
        "id": "c2bbbc07"
      },
      "outputs": [],
      "source": [
        "order_data=order_data[['Segment','Category','Sub-Category','Sales']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48339e60",
      "metadata": {
        "id": "48339e60",
        "outputId": "9e754d18-0226-416a-aaa0-12d29e18856f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342,
          "referenced_widgets": [
            "40ecf83b28084ceb895f8679f8f34abe",
            "fc72839d9a5e4d36b9af6561a038193c",
            "96a40c8f988e4d0f9ebcf7a85c4aef92",
            "75bf8ac27da34b6e8cfb74bf1ad17071",
            "6909fbbb256641dab1d70f68b50667e0",
            "e741ef44e06f4df1b8433144c0a7be6d",
            "ee27fd07bd1f4a1b8af95fe4571558de",
            "bc27fd3c0e2b4f61a4138ea647f9ebb3",
            "88abcbf3f8d9405eb54b5771d6a83ef5",
            "65126c182c07471ab1b91f0492166169",
            "142617ec469f4610b75c00a95e2908bd",
            "a61621fc965d44779f32ef52354ee101",
            "345844e1308646338b72a1fda6bfd974",
            "b9fe7608097f4d58ba16f501b1376b06",
            "07be5084215543128dcfdcdfb34e0279",
            "ee1596adef1049d9b3a4ec2a5b566bdd",
            "0efd430997224c8cbaf423d7055750a3",
            "cfa2f9d7b7d34644b435d84e15a3010f",
            "6767ead1fb0942b9bfd90e6e22d79e2f",
            "dfde21d17f194590ab98003d0c79efd3",
            "cd59cc6439a74aeea1941da1839d179b",
            "ff1a9c597bef437289200bf362e5ce32",
            "71c39acb88b14efaaf417dfda8eade7b",
            "1a7aaa14e8b54eee9b8d89aa85cc2518",
            "7eae7f2c4e5b41b58b8d0af23ee31362",
            "19e7f5248b46442aaf549419ddeb3abd",
            "e48fd973111949b1897576c4370008b2",
            "6a04c39e4a4c4d27af311c00e444e884",
            "04484a3aab8a4e148e774329e7220935",
            "f36bec8ad5ba403b949ab649ade63679",
            "75f72954bf6d4494925eda7fc59ce83d",
            "7a299e3981a84420a4795e8799b3d440",
            "1ecdeb4e288d4b31ac27f4d0081611b5",
            "38b647f1d05944389c112afcbccebac3",
            "69af82cc523346238a4abbc204a1d964",
            "90f5f9fa23eb471d824c72538a0cc883",
            "261a5645a9004898a39352f38f782639",
            "7f93389431214e1e8870761fc7578f9b",
            "5b9591e64a464c948ca5176b7ecee81d",
            "917538746d5d4bd19549040ab1e29bfc",
            "fcb28ca58f5349db8d9ef13c7f0205de",
            "2c62b289371e422a8db584e5b3985130",
            "cd206bef399f488e8f6300968935970c",
            "244acfa3302c40acb6cb20067dce5d7f",
            "ec2a1ccf4363446fbfd29e67014f75ac",
            "59919bf2764a4573afbe7ac9ef402ed9",
            "ce869999c2c448628ad7b2b4b5819673",
            "7ca64e686a814d5981c09d2ed6268187",
            "81f55e7742614c92b31861458995b68c",
            "128472001384441b8153133b578ef15f",
            "8223b416402440b09eb5a7742855e08e",
            "9db1ec83c1b140d5aaf3ed7dfeb36160",
            "f693fbe363964bd1b3f1502f3d738706",
            "855494948157429dbba4758e89cd5a48",
            "3a20b3c3a6884668ab2c8d46e42b6b92"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/490 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40ecf83b28084ceb895f8679f8f34abe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/262k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a61621fc965d44779f32ef52354ee101"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71c39acb88b14efaaf417dfda8eade7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38b647f1d05944389c112afcbccebac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec2a1ccf4363446fbfd29e67014f75ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['column_output_bias', 'column_output_weights', 'output_bias', 'output_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
        "\n",
        "# Load the model and tokenizer from the Hugging Face Model Hub\n",
        "model_name = \"google/tapas-base\"\n",
        "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
        "model = TapasForQuestionAnswering.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "455346c9",
      "metadata": {
        "id": "455346c9"
      },
      "outputs": [],
      "source": [
        "# Ask Questions\n",
        "order_data = order_data.fillna('').astype(str)\n",
        "inputs = tokenizer(\n",
        "    table=order_data,\n",
        "    queries=[\"What segment has the highest sales?\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        "    unk_token='<unk>'\n",
        ")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Process the outputs to get the answer\n",
        "logits = outputs.logits\n",
        "predicted_answer = tokenizer.decode(torch.argmax(logits, dim=-1).squeeze(), skip_special_tokens=True)\n",
        "print(f\"Predicted answer: {predicted_answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f63600",
      "metadata": {
        "id": "59f63600",
        "outputId": "0ef10a51-dffb-4b2d-eabf-b16f32e18233"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.ipynb_checkpoints',\n",
              " 'BERT',\n",
              " 'BERT.ipynb',\n",
              " 'fine-tuned-tapas',\n",
              " 'fine_tuned_tabert',\n",
              " 'fraudTest.csv',\n",
              " 'fraudTrain.csv',\n",
              " 'Fraudulent transactions-Bkp02Sept2024.ipynb',\n",
              " 'Fraudulent transactions-Copy1.ipynb',\n",
              " 'Fraudulent transactions.ipynb',\n",
              " 'fraud_detection_nn.pth',\n",
              " 'fraud_detection_nn_es.pth',\n",
              " 'LIME_implementation',\n",
              " 'LIME_implementation.zip',\n",
              " 'logs',\n",
              " 'orders.csv',\n",
              " 'orders_updated.csv',\n",
              " 'proj2',\n",
              " 'results',\n",
              " 'Tapas',\n",
              " 'Tapas.ipynb',\n",
              " 'tokenized_data.pt',\n",
              " 'train_df.csv',\n",
              " 'train_df_new.csv',\n",
              " 'Untitled.ipynb']"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7ec0dd82",
      "metadata": {
        "id": "7ec0dd82",
        "outputId": "eb363ae6-2232-4ebe-d331-7065d8754b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            " Row ID             0\n",
            "Order ID           0\n",
            "Order Date         0\n",
            "Ship Date          0\n",
            "Ship Mode          0\n",
            "Customer ID        0\n",
            "Customer Name      0\n",
            "Segment            0\n",
            "Country/Region     0\n",
            "City               0\n",
            "State              0\n",
            "Postal Code       11\n",
            "Region             0\n",
            "Product ID         0\n",
            "Category           0\n",
            "Sub-Category       0\n",
            "Product Name       0\n",
            "Sales              0\n",
            "Quantity           0\n",
            "Discount           0\n",
            "Profit             0\n",
            "dtype: int64\n",
            "Number of duplicate rows: 0\n",
            "Data types of each column:\n",
            " Row ID              int64\n",
            "Order ID           object\n",
            "Order Date         object\n",
            "Ship Date          object\n",
            "Ship Mode          object\n",
            "Customer ID        object\n",
            "Customer Name      object\n",
            "Segment            object\n",
            "Country/Region     object\n",
            "City               object\n",
            "State              object\n",
            "Postal Code       float64\n",
            "Region             object\n",
            "Product ID         object\n",
            "Category           object\n",
            "Sub-Category       object\n",
            "Product Name       object\n",
            "Sales             float64\n",
            "Quantity            int64\n",
            "Discount          float64\n",
            "Profit            float64\n",
            "dtype: object\n",
            "Basic statistics of the dataset:\n",
            "             Row ID   Postal Code         Sales     Quantity     Discount  \\\n",
            "count  9994.000000   9983.000000   9994.000000  9994.000000  9994.000000   \n",
            "mean   4997.500000  55245.233297    229.858001     3.789574     0.156203   \n",
            "std    2885.163629  32038.715955    623.245101     2.225110     0.206452   \n",
            "min       1.000000   1040.000000      0.444000     1.000000     0.000000   \n",
            "25%    2499.250000  23223.000000     17.280000     2.000000     0.000000   \n",
            "50%    4997.500000  57103.000000     54.490000     3.000000     0.200000   \n",
            "75%    7495.750000  90008.000000    209.940000     5.000000     0.200000   \n",
            "max    9994.000000  99301.000000  22638.480000    14.000000     0.800000   \n",
            "\n",
            "            Profit  \n",
            "count  9994.000000  \n",
            "mean     28.656896  \n",
            "std     234.260108  \n",
            "min   -6599.978000  \n",
            "25%       1.728750  \n",
            "50%       8.666500  \n",
            "75%      29.364000  \n",
            "max    8399.976000  \n",
            "Current length of the dataset: 9994\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = order_data.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_values)\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicate_rows = order_data.duplicated().sum()\n",
        "print(\"Number of duplicate rows:\", duplicate_rows)\n",
        "\n",
        "# Optionally, remove duplicate rows\n",
        "order_data = order_data.drop_duplicates()\n",
        "\n",
        "# Check data types\n",
        "data_types = order_data.dtypes\n",
        "print(\"Data types of each column:\\n\", data_types)\n",
        "\n",
        "# Generate basic statistics\n",
        "statistics = order_data.describe()\n",
        "print(\"Basic statistics of the dataset:\\n\", statistics)\n",
        "\n",
        "current_length = len(order_data)\n",
        "print(f\"Current length of the dataset: {current_length}\")\n",
        "\n",
        "order_data=order_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d7f79a34",
      "metadata": {
        "id": "d7f79a34",
        "outputId": "3f33a07e-2d8a-4501-c230-6e6591b88e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current length of the dataset: 9983\n"
          ]
        }
      ],
      "source": [
        "current_length = len(order_data)\n",
        "print(f\"Current length of the dataset: {current_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2354bf3a",
      "metadata": {
        "id": "2354bf3a"
      },
      "outputs": [],
      "source": [
        "order_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e9bf32",
      "metadata": {
        "id": "02e9bf32",
        "outputId": "aad90010-7058-4e2b-e359-784de66a4749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  2054,  6903,  2038,  1996,  3284,  4341,  1029,   102,  6903,\n",
            "          4341,  7325,  6694,  5971, 10347,  2188,  2436,  3156,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]]), 'labels': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'numeric_values': tensor([[  nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan, 1000.,   nan, 1500.,   nan,   nan,  500.,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan]]), 'numeric_values_scale': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1.]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import TapasTokenizer\n",
        "\n",
        "# Example table data\n",
        "data = {\n",
        "    'Segment': ['Consumer', 'Corporate', 'Home Office'],\n",
        "    'Sales': ['1000', '1500', '500']\n",
        "}\n",
        "table = pd.DataFrame(data)\n",
        "\n",
        "# Example question and answer\n",
        "questions = [\"What segment has the highest sales?\"]\n",
        "answer_coordinates = [[(1, 1)]]  # Coordinates for the answer cell\n",
        "answer_texts = [\"Corporate\"]\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./Tapas\")\n",
        "\n",
        "# Tokenize the inputs\n",
        "inputs = tokenizer(\n",
        "    table=table,\n",
        "    queries=questions,\n",
        "    answer_coordinates=answer_coordinates,\n",
        "    answer_text=answer_texts,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "print(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c288d3c",
      "metadata": {
        "id": "7c288d3c",
        "outputId": "2cec3d02-c809-47c1-fc58-197ad8b2cabe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  2054,  6903,  2038,  1996,  3284,  4341,  1029,   102,  6903,\n",
            "          4341,  7325,  6694,  5971, 10347,  2188,  2436,  3156,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]]), 'labels': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'numeric_values': tensor([[  nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan, 1000.,   nan, 1500.,   nan,   nan,  500.,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
            "           nan,   nan]]), 'numeric_values_scale': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "         1., 1., 1., 1., 1., 1., 1., 1.]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import TapasTokenizer\n",
        "\n",
        "# Example table data\n",
        "data = {\n",
        "    'Segment': ['Consumer', 'Corporate', 'Home Office'],\n",
        "    'Sales': [\"1000\", \"1500\", \"500\"]\n",
        "}\n",
        "table = pd.DataFrame(data)\n",
        "\n",
        "# Example question and answer\n",
        "questions = [\"What segment has the highest sales?\"]\n",
        "answer_coordinates = [[(1, 1)]]  # Coordinates for the answer cell\n",
        "answer_texts = [\"1500\"]  # The text in the answer cell\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./Tapas\")\n",
        "\n",
        "# Tokenize the inputs\n",
        "try:\n",
        "    inputs = tokenizer(\n",
        "        table=table,\n",
        "        queries=questions,\n",
        "        answer_coordinates=answer_coordinates,\n",
        "        answer_text=answer_texts,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    print(inputs)\n",
        "except ValueError as e:\n",
        "    print(f\"An error occurred during tokenization: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b651e66c",
      "metadata": {
        "id": "b651e66c",
        "outputId": "c5bdfae4-6ca0-4c28-c2d7-3a6a9c94dc05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  text = normalize_for_match(row[col_index].text)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  cell = row[col_index]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#order_data=order_data.head(500)\n",
        "# Tokenize the entire dataset\n",
        "tokenizer = TapasTokenizer.from_pretrained(model_name)\n",
        "questions = [\"What segment has the highest sales?\"] * len(order_data)\n",
        "answer_coordinates = [[(0, 0)]] * len(order_data)  # Adjust coordinates as needed\n",
        "answer_texts = ['Consumer'] * len(order_data)  # Adjust answers as needed\n",
        "\n",
        "inputs = tokenizer(\n",
        "    table=order_data,\n",
        "    queries=questions,\n",
        "    answer_coordinates=answer_coordinates,\n",
        "    answer_text=answer_texts,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Save the tokenized data\n",
        "torch.save(inputs, \"tokenized_data.pt\")\n",
        "\n",
        "# Custom Dataset class to load pre-tokenized data\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenized_data):\n",
        "        self.tokenized_data = tokenized_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tokenized_data['input_ids'].shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.tokenized_data.items()}\n",
        "\n",
        "# Load the tokenized data\n",
        "tokenized_data = torch.load(\"tokenized_data.pt\")\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = CustomDataset(tokenized_data)\n",
        "eval_dataset = CustomDataset(tokenized_data)\n",
        "\n",
        "# Print dataset sizes to verify\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "# Load the model\n",
        "model = TapasForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine-tuned-tapas\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-tapas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f43ca9",
      "metadata": {
        "id": "57f43ca9"
      },
      "outputs": [],
      "source": [
        "tokenizer = TapasTokenizer.from_pretrained(\"./fine-tuned-tapas\")\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"./fine-tuned-tapas\")\n",
        "\n",
        "# Ask Questions\n",
        "inputs = tokenizer(\n",
        "    table=order_data,\n",
        "    queries=[\"What segment has the highest sales?\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Process the outputs to get the answer\n",
        "logits = outputs.logits\n",
        "predicted_answer = tokenizer.decode(torch.argmax(logits, dim=-1).squeeze(), skip_special_tokens=True)\n",
        "print(f\"Predicted answer: {predicted_answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ab26b0",
      "metadata": {
        "id": "57ab26b0",
        "outputId": "03181b7c-274e-459f-aecd-21bab7be7c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer:    start  14   end 6\n"
          ]
        }
      ],
      "source": [
        "# Get the logits directly\n",
        "logits = outputs.logits\n",
        "\n",
        "# Assuming logits is a 2D tensor with shape [batch_size, sequence_length]\n",
        "# Get the predicted token indices for start and end positions\n",
        "start_logits, end_logits = logits.split(256, dim=1)  # Adjust the split size based on your model's output\n",
        "\n",
        "# Squeeze the last dimension\n",
        "start_logits = start_logits.squeeze(-1)\n",
        "end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "# Get the predicted start and end positions\n",
        "start_index = torch.argmax(start_logits, dim=1).item()\n",
        "end_index = torch.argmax(end_logits, dim=1).item()\n",
        "\n",
        "# Decode the answer from the table\n",
        "predicted_answer = tokenizer.convert_tokens_to_string(\n",
        "    tokenizer.convert_ids_to_tokens(inputs['input_ids'][0, start_index:end_index + 1])\n",
        ")\n",
        "print(f\"Predicted answer: {predicted_answer}   start  {start_index}   end {end_index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de97ee81",
      "metadata": {
        "id": "de97ee81",
        "outputId": "c4d10f6a-87a1-49bd-8eeb-da0b591e2c70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  101,  2054,  6903,  2038,  1996,  3284,  4341,  1029,   102,  6903,\n",
              "          4696,  4942,  1011,  4696,  7325,  7390,  2338, 18382,  2015,  7325,\n",
              "          7390,  8397,  5971,  2436,  6067, 10873,  7325,  7390,  7251,  7325,\n",
              "          2436,  6067,  5527,  7325,  7390, 23127,  7325,  2436,  6067,  2396,\n",
              "          7325,  2974, 11640,  7325,  2436,  6067, 14187,  2545,  7325,  2436,\n",
              "          6067, 22449,  7325,  7390,  7251,  7325,  2974, 11640,  7325,  2436,\n",
              "          6067,  3259,  7325,  2436,  6067, 14187,  2545,  2188,  2436,  2436,\n",
              "          6067, 22449,  2188,  2436,  2436,  6067, 14187,  2545,  7325,  2436,\n",
              "          6067,  5527,  7325,  2436,  6067,  5527,  7325,  2436,  6067,  2396,\n",
              "          7325,  2974, 11640,  7325,  2436,  6067, 14187,  2545,  5971,  2436,\n",
              "          6067,  2396,  5971,  2436,  6067, 22449,  7325,  7390,  8397,  7325,\n",
              "          7390,  7251,  7325,  2436,  6067, 14187,  2545,  7325,  2974, 16611,\n",
              "          7325,  7390,  2338, 18382,  2015,  7325,  2436,  6067, 14187,  2545,\n",
              "          7325,  7390, 23127,  7325,  2436,  6067, 11255,  2015,  7325,  2436,\n",
              "          6067,  2396,  7325,  2436,  6067, 14187,  2545,  7325,  2436,  6067,\n",
              "          2396,  2188,  2436,  2436,  6067,  3259,  5971,  2974, 11640,  5971,\n",
              "          7390, 23127,  2188,  2436,  2436,  6067, 11255,  2015,  2188,  2436,\n",
              "          7390,  2338, 18382,  2015,  2188,  2436,  7390,  8397,  2188,  2436,\n",
              "          2974, 11640,  5971,  2974, 11640,  5971,  2436,  6067,  5527,  5971,\n",
              "          2436,  6067,  5527,  5971,  2974, 16611,  5971,  2436,  6067, 14187,\n",
              "          2545,  7325,  2436,  6067,  5527,  7325,  2974, 16611,  7325,  2974,\n",
              "         11640,  7325,  2436,  6067, 14187,  2545,  7325,  2436,  6067, 10873,\n",
              "          7325,  7390, 23127,  7325,  7390,  8397,  5971,  2436,  6067,  3435,\n",
              "         24454,  2015,  5971,  2974, 11640,  7325,  2436,  6067,  5527,  7325,\n",
              "          2436,  6067,  3259,  7325,  7390,  8397,  7325,  2436,  6067,  3259,\n",
              "          7325,  2974, 16611,  7325,  2436,  6067, 14187,  2545,  7325,  2436,\n",
              "          6067,  2396,  7325,  2974, 16611,  7325,  2436,  6067, 14187,  2545,\n",
              "          7325,  2436,  6067,  3259,  7325,  7390, 23127,  2188,  2436,  7390,\n",
              "          8397,  5971,  2436,  6067,  2396,  5971,  2974, 11640,  7325,  2436,\n",
              "          6067,  3259,  7325,  2436,  6067, 14187,  2545,  7325,  2436,  6067,\n",
              "          3259,  7325,  7390,  8397,  7325,  7390, 23127,  7325,  2436,  6067,\n",
              "          5527,  5971,  2436,  6067, 14187,  2545,  5971,  7390, 23127,  5971,\n",
              "          2436,  6067,  5527,  7325,  7390, 23127,  5971,  2436,  6067, 22449,\n",
              "          5971,  2436,  6067, 14187,  2545,  7325,  2436,  6067,  2396,  7325,\n",
              "          2436,  6067,  5527,  5971,  2436,  6067, 11255,  2015,  2188,  2436,\n",
              "          2436,  6067,  5527,  7325,  7390,  8397,  7325,  2974, 16611,  7325,\n",
              "          2436,  6067, 10873,  2188,  2436,  2436,  6067,  5527,  5971,  2436,\n",
              "          6067,  2396,  5971,  2974, 11640,  5971,  2436,  6067,  3259,  7325,\n",
              "          2436,  6067,  3259,  7325,  7390, 23127,  7325,  2436,  6067, 14187,\n",
              "          2545,  2188,  2436,  2436,  6067, 14187,  2545,  2188,  2436,  7390,\n",
              "         23127,  7325,  2436,  6067, 14187,  2545,  5971,  2436,  6067, 22449,\n",
              "          2188,  2436,  2436,  6067,  3259,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]])"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d47896",
      "metadata": {
        "id": "87d47896",
        "outputId": "7cd8b99f-dde5-4de1-d1ee-57528d545ea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n"
          ]
        }
      ],
      "source": [
        "print(logits.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573c4019",
      "metadata": {
        "id": "573c4019",
        "outputId": "ce7cc301-7bbf-422c-f5fe-96ccb9f0464b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset size: 0\n",
            "Evaluation dataset size: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at ./Tapas and are newly initialized: ['output_bias', 'column_output_bias', 'output_weights', 'column_output_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[166], line 101\u001b[0m\n\u001b[0;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     94\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     95\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     96\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m     97\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m    104\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine-tuned-tapas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1551\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[1;32m-> 1553\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_train_dataloader()\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;66;03m# Setting up training control variables:\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;66;03m# number of training epochs: num_train_epochs\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# number of training steps per epoch: num_update_steps_per_epoch\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# total number of training steps to execute: max_steps\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m total_train_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mworld_size\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\trainer.py:850\u001b[0m, in \u001b[0;36mTrainer.get_train_dataloader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    842\u001b[0m dataloader_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size,\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollate_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_collator,\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpin_memory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_pin_memory,\n\u001b[0;32m    847\u001b[0m }\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_dataset, torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterableDataset):\n\u001b[1;32m--> 850\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampler\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_sampler()\n\u001b[0;32m    851\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_drop_last\n\u001b[0;32m    852\u001b[0m     dataloader_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_init_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed_worker\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\trainer.py:821\u001b[0m, in \u001b[0;36mTrainer._get_train_sampler\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LengthGroupedSampler(\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps,\n\u001b[0;32m    815\u001b[0m         dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset,\n\u001b[0;32m    816\u001b[0m         lengths\u001b[38;5;241m=\u001b[39mlengths,\n\u001b[0;32m    817\u001b[0m         model_input_name\u001b[38;5;241m=\u001b[39mmodel_input_name,\n\u001b[0;32m    818\u001b[0m     )\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RandomSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:143\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import TapasTokenizer, TapasForQuestionAnswering, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure order_data is defined and loaded\n",
        "order_data = pd.DataFrame({\n",
        "    'Segment': ['Consumer', 'Corporate', 'Home Office'],\n",
        "    'Sales': [1000, 1500, 500]\n",
        "})\n",
        "\n",
        "current_length = len(order_data)\n",
        "rows_to_drop = current_length % 8\n",
        "if rows_to_drop > 0:\n",
        "    order_data = order_data[:-rows_to_drop]\n",
        "\n",
        "# Reset the index and convert all values to strings\n",
        "order_data.reset_index(drop=True, inplace=True)\n",
        "order_data = order_data.astype(str)\n",
        "\n",
        "# Save the updated dataset to a new CSV file\n",
        "order_data.to_csv(\"orders_updated.csv\", index=False)\n",
        "\n",
        "# Generate questions and answers for each row\n",
        "questions = [\"What segment has the highest sales?\"] * len(order_data)\n",
        "answer_coordinates = [[(0, 0)]] * len(order_data)  # Adjust coordinates as needed\n",
        "answer_texts = [\"Consumer\"] * len(order_data)  # Adjust answers as needed\n",
        "\n",
        "assert len(questions) == len(order_data), \"Questions list length does not match order_data length\"\n",
        "assert len(answer_coordinates) == len(order_data), \"Answer coordinates list length does not match order_data length\"\n",
        "assert len(answer_texts) == len(order_data), \"Answer texts list length does not match order_data length\"\n",
        "\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, questions, answer_coordinates, answer_texts):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.questions = questions\n",
        "        self.answer_coordinates = answer_coordinates\n",
        "        self.answer_texts = answer_texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self.dataframe):\n",
        "            raise IndexError(f\"Index {idx} is out of bounds for dataframe with length {len(self.dataframe)}\")\n",
        "\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        table = pd.DataFrame([row])\n",
        "        print(f\"Processing row {idx}: {row}\")  # Debugging statement\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(\n",
        "                table=table,\n",
        "                queries=[self.questions[idx]],\n",
        "                answer_coordinates=[self.answer_coordinates[idx]],\n",
        "                answer_text=[self.answer_texts[idx]],\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during tokenization at index {idx}: {e}\")\n",
        "            raise e\n",
        "\n",
        "        return inputs\n",
        "\n",
        "# Create instances of the custom dataset\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./Tapas\")\n",
        "train_dataset = CustomDataset(order_data, tokenizer, questions, answer_coordinates, answer_texts)\n",
        "eval_dataset = CustomDataset(order_data, tokenizer, questions, answer_coordinates, answer_texts)\n",
        "\n",
        "# Print dataset sizes to verify\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "# Load the model from the local directory\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"./Tapas\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "# Initialize the Trainer with the custom DataLoader\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine-tuned-tapas\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-tapas\")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./fine-tuned-tapas\")\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"./fine-tuned-tapas\")\n",
        "\n",
        "# Ask Questions\n",
        "inputs = tokenizer(\n",
        "    table=order_data,\n",
        "    queries=[\"What segment has the highest sales?\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Process the outputs to get the answer\n",
        "logits = outputs.logits\n",
        "predicted_answer = tokenizer.decode(torch.argmax(logits, dim=-1).squeeze(), skip_special_tokens=True)\n",
        "print(f\"Predicted answer: {predicted_answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c36e80",
      "metadata": {
        "id": "d1c36e80",
        "outputId": "35893fb4-6c7e-4fa5-b574-ae08d5bd8f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset size: 9976\n",
            "Evaluation dataset size: 9976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at ./Tapas and are newly initialized: ['output_bias', 'column_output_bias', 'output_weights', 'column_output_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "C:\\Anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 7400: Segment                Consumer\n",
            "Category        Office Supplies\n",
            "Sub-Category           Supplies\n",
            "Name: 7400, dtype: object\n",
            "Error during tokenization at index 7400: iloc cannot enlarge its target object\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "iloc cannot enlarge its target object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[173], line 94\u001b[0m\n\u001b[0;32m     86\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     87\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     88\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     89\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m     90\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[0;32m     91\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m     97\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine-tuned-tapas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1541\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m     trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m )\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1787\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1784\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   1788\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rng_to_sync:\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\accelerate\\data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[173], line 58\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during tokenization at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, idx\n",
            "Cell \u001b[1;32mIn[173], line 47\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging statement\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[0;32m     48\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m     49\u001b[0m         queries\u001b[38;5;241m=\u001b[39mquestions,\n\u001b[0;32m     50\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m     51\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_texts,\n\u001b[0;32m     52\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m     )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during tokenization at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:650\u001b[0m, in \u001b[0;36mTapasTokenizer.__call__\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(queries, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m    651\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    652\u001b[0m         queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m    653\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    654\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    655\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    656\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    657\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    658\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    659\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    660\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    661\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    662\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    663\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    664\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    665\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    666\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    667\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    668\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    669\u001b[0m     )\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m    672\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    673\u001b[0m         query\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    690\u001b[0m     )\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:768\u001b[0m, in \u001b[0;36mTapasTokenizer.batch_encode_plus\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    764\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m     )\n\u001b[1;32m--> 768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    769\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    770\u001b[0m     queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m    771\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    772\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    773\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    774\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    775\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    776\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    777\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    778\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    779\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    780\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    781\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    782\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    783\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    784\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    785\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m )\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:835\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_encode_plus\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    832\u001b[0m     queries[idx] \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    833\u001b[0m     queries_tokens\u001b[38;5;241m.\u001b[39mappend(query_tokens)\n\u001b[1;32m--> 835\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_prepare_for_model(\n\u001b[0;32m    836\u001b[0m     table,\n\u001b[0;32m    837\u001b[0m     queries,\n\u001b[0;32m    838\u001b[0m     tokenized_table\u001b[38;5;241m=\u001b[39mtable_tokens,\n\u001b[0;32m    839\u001b[0m     queries_tokens\u001b[38;5;241m=\u001b[39mqueries_tokens,\n\u001b[0;32m    840\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    841\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    842\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    843\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    844\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    845\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    846\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    847\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    848\u001b[0m     prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    849\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    850\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    851\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    852\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    853\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    854\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    855\u001b[0m )\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:890\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_prepare_for_model\u001b[1;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(raw_queries, queries_tokens, answer_coordinates, answer_text)):\n\u001b[0;32m    889\u001b[0m     raw_query, query_tokens, answer_coords, answer_txt \u001b[38;5;241m=\u001b[39m example\n\u001b[1;32m--> 890\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[0;32m    891\u001b[0m         raw_table,\n\u001b[0;32m    892\u001b[0m         raw_query,\n\u001b[0;32m    893\u001b[0m         tokenized_table\u001b[38;5;241m=\u001b[39mtokenized_table,\n\u001b[0;32m    894\u001b[0m         query_tokens\u001b[38;5;241m=\u001b[39mquery_tokens,\n\u001b[0;32m    895\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coords,\n\u001b[0;32m    896\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_txt,\n\u001b[0;32m    897\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    898\u001b[0m         padding\u001b[38;5;241m=\u001b[39mPaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\u001b[38;5;241m.\u001b[39mvalue,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    899\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    900\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    901\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    902\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    903\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    904\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    905\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    906\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# We convert the whole batch to tensors at the end\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    908\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    909\u001b[0m         prev_answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    910\u001b[0m         prev_answer_text\u001b[38;5;241m=\u001b[39manswer_text[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    911\u001b[0m     )\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch_outputs:\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:1229\u001b[0m, in \u001b[0;36mTapasTokenizer.prepare_for_model\u001b[1;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m   1223\u001b[0m     prev_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_answer_ids(\n\u001b[0;32m   1224\u001b[0m         column_ids, row_ids, table_data, prev_answer_text, prev_answer_coordinates\n\u001b[0;32m   1225\u001b[0m     )\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# FIRST: parse both the table and question in terms of numeric values\u001b[39;00m\n\u001b[1;32m-> 1229\u001b[0m raw_table \u001b[38;5;241m=\u001b[39m add_numeric_table_values(raw_table)\n\u001b[0;32m   1230\u001b[0m raw_query \u001b[38;5;241m=\u001b[39m add_numeric_values_to_question(raw_query)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;66;03m# SECOND: add numeric-related features (and not parse them in these functions):\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:2826\u001b[0m, in \u001b[0;36madd_numeric_table_values\u001b[1;34m(table, min_consolidation_fraction, debug_info)\u001b[0m\n\u001b[0;32m   2824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_index, row \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m   2825\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_index, cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row):\n\u001b[1;32m-> 2826\u001b[0m         table\u001b[38;5;241m.\u001b[39miloc[row_index, col_index] \u001b[38;5;241m=\u001b[39m Cell(text\u001b[38;5;241m=\u001b[39mcell)\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;66;03m# Third, add numeric_value attributes to these Cell objects\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_index, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(table\u001b[38;5;241m.\u001b[39mcolumns):\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:846\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    844\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m    845\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_setitem_indexer(key)\n\u001b[1;32m--> 846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m    849\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1550\u001b[0m, in \u001b[0;36m_iLocIndexer._has_valid_setitem_indexer\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(i):\n\u001b[0;32m   1549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ax):\n\u001b[1;32m-> 1550\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import TapasTokenizer, TapasForQuestionAnswering, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "\n",
        "current_length = len(order_data)\n",
        "rows_to_drop = current_length % 8\n",
        "if rows_to_drop > 0:\n",
        "    order_data = order_data[:-rows_to_drop]\n",
        "\n",
        "# Reset the index and convert all values to strings\n",
        "order_data.reset_index(drop=True, inplace=True)\n",
        "order_data = order_data.astype(str)\n",
        "\n",
        "# Save the updated dataset to a new CSV file\n",
        "order_data.to_csv(\"orders_updated.csv\", index=False)\n",
        "\n",
        "# Generate questions and answers for each row\n",
        "questions = [\"What segment has the highest sales?\"]\n",
        "answer_coordinates = [[(0, 0)]]   # Adjust coordinates as needed\n",
        "answer_texts = ['Consumer']  # Adjust answers as needed\n",
        "#assert len(questions) == len(order_data), \"Questions list length does not match order_data length\"\n",
        "#assert len(answer_coordinates) == len(order_data), \"Answer coordinates list length does not match order_data length\"\n",
        "#assert len(answer_texts) == len(order_data), \"Answer texts list length does not match order_data length\"\n",
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, questions, answer_coordinates, answer_texts):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.questions = questions\n",
        "        self.answer_coordinates = answer_coordinates\n",
        "        self.answer_texts = answer_texts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self.dataframe):\n",
        "            raise IndexError(f\"Index {idx} is out of bounds for dataframe with length {len(self.dataframe)}\")\n",
        "\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        table = pd.DataFrame([row])\n",
        "        print(f\"Processing row {idx}: {row}\")  # Debugging statement\n",
        "\n",
        "        try:\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                table=table,\n",
        "                queries=questions,\n",
        "                answer_coordinates=answer_coordinates,\n",
        "                answer_text=answer_texts,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during tokenization at index {idx}: {e}\")\n",
        "            raise e\n",
        "\n",
        "        return inputs, idx\n",
        "\n",
        "# Create instances of the custom dataset\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./Tapas\")\n",
        "train_dataset = CustomDataset(order_data, tokenizer, questions, answer_coordinates, answer_texts)\n",
        "eval_dataset = CustomDataset(order_data, tokenizer, questions, answer_coordinates, answer_texts)\n",
        "\n",
        "# Print dataset sizes to verify\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "# Load the model from the local directory\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"./Tapas\")\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "# Initialize the Trainer with the custom DataLoader\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./fine-tuned-tapas\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-tapas\")\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./fine-tuned-tapas\")\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"./fine-tuned-tapas\")\n",
        "\n",
        "# Ask Questions\n",
        "inputs = tokenizer(table=order_data, queries=[\"What segment has the highest sales?\"], padding=\"max_length\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da35076",
      "metadata": {
        "id": "5da35076",
        "outputId": "d0dd2748-54d8-4a8f-de3a-4eccfccde9c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Consumer'"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_texts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b55d3f",
      "metadata": {
        "id": "b5b55d3f",
        "outputId": "075c5213-d787-40c6-8bfd-ebcd5e9059ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Segment                Consumer\n",
              "Category        Office Supplies\n",
              "Sub-Category           Supplies\n",
              "Name: 7400, dtype: object"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "order_data.iloc[7400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b859f03",
      "metadata": {
        "id": "1b859f03",
        "outputId": "979bf49a-9f13-410c-9ccd-2cd96c36afda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing row 1: Segment          Consumer\n",
            "Category        Furniture\n",
            "Sub-Category       Chairs\n",
            "Name: 1, dtype: object\n",
            "Error during tokenization at index 1: iloc cannot enlarge its target object\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "iloc cannot enlarge its target object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[146], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset[\u001b[38;5;241m1\u001b[39m]\n",
            "Cell \u001b[1;32mIn[144], line 55\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during tokenization at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, idx\n",
            "Cell \u001b[1;32mIn[144], line 44\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging statement\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[0;32m     45\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m     46\u001b[0m         queries\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions[\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m     47\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswer_coordinates[\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m     48\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswer_texts[\u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m     49\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during tokenization at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:650\u001b[0m, in \u001b[0;36mTapasTokenizer.__call__\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(queries, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m    651\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    652\u001b[0m         queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m    653\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    654\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    655\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    656\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    657\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    658\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    659\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    660\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    661\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    662\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    663\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    664\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    665\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    666\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    667\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    668\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    669\u001b[0m     )\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m    672\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    673\u001b[0m         query\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    690\u001b[0m     )\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:768\u001b[0m, in \u001b[0;36mTapasTokenizer.batch_encode_plus\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    764\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m     )\n\u001b[1;32m--> 768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    769\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    770\u001b[0m     queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m    771\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    772\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    773\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    774\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    775\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    776\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    777\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    778\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    779\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    780\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    781\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    782\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    783\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    784\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    785\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    787\u001b[0m )\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:835\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_encode_plus\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    832\u001b[0m     queries[idx] \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    833\u001b[0m     queries_tokens\u001b[38;5;241m.\u001b[39mappend(query_tokens)\n\u001b[1;32m--> 835\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_prepare_for_model(\n\u001b[0;32m    836\u001b[0m     table,\n\u001b[0;32m    837\u001b[0m     queries,\n\u001b[0;32m    838\u001b[0m     tokenized_table\u001b[38;5;241m=\u001b[39mtable_tokens,\n\u001b[0;32m    839\u001b[0m     queries_tokens\u001b[38;5;241m=\u001b[39mqueries_tokens,\n\u001b[0;32m    840\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    841\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    842\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    843\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    844\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    845\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    846\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    847\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    848\u001b[0m     prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    849\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    850\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    851\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    852\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    853\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    854\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    855\u001b[0m )\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:890\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_prepare_for_model\u001b[1;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(raw_queries, queries_tokens, answer_coordinates, answer_text)):\n\u001b[0;32m    889\u001b[0m     raw_query, query_tokens, answer_coords, answer_txt \u001b[38;5;241m=\u001b[39m example\n\u001b[1;32m--> 890\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[0;32m    891\u001b[0m         raw_table,\n\u001b[0;32m    892\u001b[0m         raw_query,\n\u001b[0;32m    893\u001b[0m         tokenized_table\u001b[38;5;241m=\u001b[39mtokenized_table,\n\u001b[0;32m    894\u001b[0m         query_tokens\u001b[38;5;241m=\u001b[39mquery_tokens,\n\u001b[0;32m    895\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coords,\n\u001b[0;32m    896\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_txt,\n\u001b[0;32m    897\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    898\u001b[0m         padding\u001b[38;5;241m=\u001b[39mPaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\u001b[38;5;241m.\u001b[39mvalue,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    899\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    900\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    901\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    902\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    903\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    904\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    905\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    906\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# We convert the whole batch to tensors at the end\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    908\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    909\u001b[0m         prev_answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    910\u001b[0m         prev_answer_text\u001b[38;5;241m=\u001b[39manswer_text[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    911\u001b[0m     )\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch_outputs:\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:1229\u001b[0m, in \u001b[0;36mTapasTokenizer.prepare_for_model\u001b[1;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m   1223\u001b[0m     prev_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_answer_ids(\n\u001b[0;32m   1224\u001b[0m         column_ids, row_ids, table_data, prev_answer_text, prev_answer_coordinates\n\u001b[0;32m   1225\u001b[0m     )\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# FIRST: parse both the table and question in terms of numeric values\u001b[39;00m\n\u001b[1;32m-> 1229\u001b[0m raw_table \u001b[38;5;241m=\u001b[39m add_numeric_table_values(raw_table)\n\u001b[0;32m   1230\u001b[0m raw_query \u001b[38;5;241m=\u001b[39m add_numeric_values_to_question(raw_query)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;66;03m# SECOND: add numeric-related features (and not parse them in these functions):\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:2826\u001b[0m, in \u001b[0;36madd_numeric_table_values\u001b[1;34m(table, min_consolidation_fraction, debug_info)\u001b[0m\n\u001b[0;32m   2824\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_index, row \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m   2825\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_index, cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row):\n\u001b[1;32m-> 2826\u001b[0m         table\u001b[38;5;241m.\u001b[39miloc[row_index, col_index] \u001b[38;5;241m=\u001b[39m Cell(text\u001b[38;5;241m=\u001b[39mcell)\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;66;03m# Third, add numeric_value attributes to these Cell objects\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_index, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(table\u001b[38;5;241m.\u001b[39mcolumns):\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:846\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    844\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m    845\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_setitem_indexer(key)\n\u001b[1;32m--> 846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    848\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m    849\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
            "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1550\u001b[0m, in \u001b[0;36m_iLocIndexer._has_valid_setitem_indexer\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(i):\n\u001b[0;32m   1549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ax):\n\u001b[1;32m-> 1550\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
          ]
        }
      ],
      "source": [
        "train_dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a649dc4",
      "metadata": {
        "id": "3a649dc4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 5: Load the Fine-Tuned Model\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"./fine-tuned-tapas\")\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"./fine-tuned-tapas\")\n",
        "\n",
        "# Step 6: Ask Questions\n",
        "# Example question: Is the premium paid higher for males?\n",
        "inputs = tokenizer(table=table, queries=[\"what segament has highest sales?\"], padding=\"max_length\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_answer_coordinates = tokenizer.convert_logits_to_predictions(inputs, logits)\n",
        "print(predicted_answer_coordinates)\n",
        "\n",
        "# Example question: What is the average premium paid by gender?\n",
        "inputs = tokenizer(table=table, queries=[\"What is the average sales by category?\"], padding=\"max_length\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "predicted_answer_coordinates = tokenizer.convert_logits_to_predictions(inputs, logits)\n",
        "print(predicted_answer_coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0585f56",
      "metadata": {
        "id": "f0585f56",
        "outputId": "42d30496-7d7c-4f71-e3b2-73201d812afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset size: 7995\n",
            "Evaluation dataset size: 1999\n"
          ]
        }
      ],
      "source": [
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Evaluation dataset size: {len(eval_dataset)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523b636c",
      "metadata": {
        "id": "523b636c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40ecf83b28084ceb895f8679f8f34abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc72839d9a5e4d36b9af6561a038193c",
              "IPY_MODEL_96a40c8f988e4d0f9ebcf7a85c4aef92",
              "IPY_MODEL_75bf8ac27da34b6e8cfb74bf1ad17071"
            ],
            "layout": "IPY_MODEL_6909fbbb256641dab1d70f68b50667e0"
          }
        },
        "fc72839d9a5e4d36b9af6561a038193c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e741ef44e06f4df1b8433144c0a7be6d",
            "placeholder": "",
            "style": "IPY_MODEL_ee27fd07bd1f4a1b8af95fe4571558de",
            "value": "tokenizer_config.json:100%"
          }
        },
        "96a40c8f988e4d0f9ebcf7a85c4aef92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc27fd3c0e2b4f61a4138ea647f9ebb3",
            "max": 490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88abcbf3f8d9405eb54b5771d6a83ef5",
            "value": 490
          }
        },
        "75bf8ac27da34b6e8cfb74bf1ad17071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65126c182c07471ab1b91f0492166169",
            "placeholder": "",
            "style": "IPY_MODEL_142617ec469f4610b75c00a95e2908bd",
            "value": "490/490[00:00&lt;00:00,18.1kB/s]"
          }
        },
        "6909fbbb256641dab1d70f68b50667e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e741ef44e06f4df1b8433144c0a7be6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee27fd07bd1f4a1b8af95fe4571558de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc27fd3c0e2b4f61a4138ea647f9ebb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88abcbf3f8d9405eb54b5771d6a83ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65126c182c07471ab1b91f0492166169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142617ec469f4610b75c00a95e2908bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a61621fc965d44779f32ef52354ee101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_345844e1308646338b72a1fda6bfd974",
              "IPY_MODEL_b9fe7608097f4d58ba16f501b1376b06",
              "IPY_MODEL_07be5084215543128dcfdcdfb34e0279"
            ],
            "layout": "IPY_MODEL_ee1596adef1049d9b3a4ec2a5b566bdd"
          }
        },
        "345844e1308646338b72a1fda6bfd974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efd430997224c8cbaf423d7055750a3",
            "placeholder": "",
            "style": "IPY_MODEL_cfa2f9d7b7d34644b435d84e15a3010f",
            "value": "vocab.txt:100%"
          }
        },
        "b9fe7608097f4d58ba16f501b1376b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6767ead1fb0942b9bfd90e6e22d79e2f",
            "max": 262028,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfde21d17f194590ab98003d0c79efd3",
            "value": 262028
          }
        },
        "07be5084215543128dcfdcdfb34e0279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd59cc6439a74aeea1941da1839d179b",
            "placeholder": "",
            "style": "IPY_MODEL_ff1a9c597bef437289200bf362e5ce32",
            "value": "262k/262k[00:00&lt;00:00,1.99MB/s]"
          }
        },
        "ee1596adef1049d9b3a4ec2a5b566bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0efd430997224c8cbaf423d7055750a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa2f9d7b7d34644b435d84e15a3010f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6767ead1fb0942b9bfd90e6e22d79e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfde21d17f194590ab98003d0c79efd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd59cc6439a74aeea1941da1839d179b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1a9c597bef437289200bf362e5ce32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71c39acb88b14efaaf417dfda8eade7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a7aaa14e8b54eee9b8d89aa85cc2518",
              "IPY_MODEL_7eae7f2c4e5b41b58b8d0af23ee31362",
              "IPY_MODEL_19e7f5248b46442aaf549419ddeb3abd"
            ],
            "layout": "IPY_MODEL_e48fd973111949b1897576c4370008b2"
          }
        },
        "1a7aaa14e8b54eee9b8d89aa85cc2518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a04c39e4a4c4d27af311c00e444e884",
            "placeholder": "",
            "style": "IPY_MODEL_04484a3aab8a4e148e774329e7220935",
            "value": "special_tokens_map.json:100%"
          }
        },
        "7eae7f2c4e5b41b58b8d0af23ee31362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36bec8ad5ba403b949ab649ade63679",
            "max": 154,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75f72954bf6d4494925eda7fc59ce83d",
            "value": 154
          }
        },
        "19e7f5248b46442aaf549419ddeb3abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a299e3981a84420a4795e8799b3d440",
            "placeholder": "",
            "style": "IPY_MODEL_1ecdeb4e288d4b31ac27f4d0081611b5",
            "value": "154/154[00:00&lt;00:00,3.13kB/s]"
          }
        },
        "e48fd973111949b1897576c4370008b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a04c39e4a4c4d27af311c00e444e884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04484a3aab8a4e148e774329e7220935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f36bec8ad5ba403b949ab649ade63679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f72954bf6d4494925eda7fc59ce83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a299e3981a84420a4795e8799b3d440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ecdeb4e288d4b31ac27f4d0081611b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38b647f1d05944389c112afcbccebac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69af82cc523346238a4abbc204a1d964",
              "IPY_MODEL_90f5f9fa23eb471d824c72538a0cc883",
              "IPY_MODEL_261a5645a9004898a39352f38f782639"
            ],
            "layout": "IPY_MODEL_7f93389431214e1e8870761fc7578f9b"
          }
        },
        "69af82cc523346238a4abbc204a1d964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b9591e64a464c948ca5176b7ecee81d",
            "placeholder": "",
            "style": "IPY_MODEL_917538746d5d4bd19549040ab1e29bfc",
            "value": "config.json:100%"
          }
        },
        "90f5f9fa23eb471d824c72538a0cc883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcb28ca58f5349db8d9ef13c7f0205de",
            "max": 1522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c62b289371e422a8db584e5b3985130",
            "value": 1522
          }
        },
        "261a5645a9004898a39352f38f782639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd206bef399f488e8f6300968935970c",
            "placeholder": "",
            "style": "IPY_MODEL_244acfa3302c40acb6cb20067dce5d7f",
            "value": "1.52k/1.52k[00:00&lt;00:00,24.0kB/s]"
          }
        },
        "7f93389431214e1e8870761fc7578f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9591e64a464c948ca5176b7ecee81d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917538746d5d4bd19549040ab1e29bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcb28ca58f5349db8d9ef13c7f0205de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c62b289371e422a8db584e5b3985130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd206bef399f488e8f6300968935970c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244acfa3302c40acb6cb20067dce5d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec2a1ccf4363446fbfd29e67014f75ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59919bf2764a4573afbe7ac9ef402ed9",
              "IPY_MODEL_ce869999c2c448628ad7b2b4b5819673",
              "IPY_MODEL_7ca64e686a814d5981c09d2ed6268187"
            ],
            "layout": "IPY_MODEL_81f55e7742614c92b31861458995b68c"
          }
        },
        "59919bf2764a4573afbe7ac9ef402ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_128472001384441b8153133b578ef15f",
            "placeholder": "",
            "style": "IPY_MODEL_8223b416402440b09eb5a7742855e08e",
            "value": "pytorch_model.bin:100%"
          }
        },
        "ce869999c2c448628ad7b2b4b5819673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db1ec83c1b140d5aaf3ed7dfeb36160",
            "max": 442768791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f693fbe363964bd1b3f1502f3d738706",
            "value": 442768791
          }
        },
        "7ca64e686a814d5981c09d2ed6268187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855494948157429dbba4758e89cd5a48",
            "placeholder": "",
            "style": "IPY_MODEL_3a20b3c3a6884668ab2c8d46e42b6b92",
            "value": "443M/443M[00:06&lt;00:00,96.9MB/s]"
          }
        },
        "81f55e7742614c92b31861458995b68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128472001384441b8153133b578ef15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8223b416402440b09eb5a7742855e08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9db1ec83c1b140d5aaf3ed7dfeb36160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f693fbe363964bd1b3f1502f3d738706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "855494948157429dbba4758e89cd5a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a20b3c3a6884668ab2c8d46e42b6b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}