{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceId":86518,"sourceType":"competition"},{"datasetId":8144015,"sourceId":12874069,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Dhaneshkp/NLP/blob/main/llm_classification_v1_open-minilm-l6-v2_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"id":"wBE9x8EVvZl6","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:21.372564Z","iopub.execute_input":"2025-08-30T06:49:21.373251Z","iopub.status.idle":"2025-08-30T06:49:21.382291Z","shell.execute_reply.started":"2025-08-30T06:49:21.373217Z","shell.execute_reply":"2025-08-30T06:49:21.381414Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\n\n#!pip install -q sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer\n\n#model = SentenceTransformer(\"all-mpnet-base-v2\")\n","metadata":{"id":"rwiCDwE6vZl8","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:21.383616Z","iopub.execute_input":"2025-08-30T06:49:21.383930Z","iopub.status.idle":"2025-08-30T06:49:21.394445Z","shell.execute_reply.started":"2025-08-30T06:49:21.383904Z","shell.execute_reply":"2025-08-30T06:49:21.393633Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\n#model.save(\"/kaggle/working/all-mpnet-base-v2\")\n","metadata":{"id":"ZKkJLQVcvZl9","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:21.395158Z","iopub.execute_input":"2025-08-30T06:49:21.395386Z","iopub.status.idle":"2025-08-30T06:49:21.411328Z","shell.execute_reply.started":"2025-08-30T06:49:21.395364Z","shell.execute_reply":"2025-08-30T06:49:21.410480Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\n#tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/qwen-llm\")\n#model = AutoModel.from_pretrained(\"/kaggle/input/qwen-llm\")\n\n","metadata":{"id":"uYvkbBHJvZl-","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:21.413140Z","iopub.execute_input":"2025-08-30T06:49:21.413367Z","iopub.status.idle":"2025-08-30T06:49:21.426454Z","shell.execute_reply.started":"2025-08-30T06:49:21.413345Z","shell.execute_reply":"2025-08-30T06:49:21.425709Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ndf_train","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":805},"id":"yifK71QYvZl-","outputId":"303ae10a-9570-4779-cd3e-9c3ed82305c2","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:21.427331Z","iopub.execute_input":"2025-08-30T06:49:21.427583Z","iopub.status.idle":"2025-08-30T06:49:24.825537Z","shell.execute_reply.started":"2025-08-30T06:49:21.427556Z","shell.execute_reply":"2025-08-30T06:49:24.824737Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"               id             model_a              model_b  \\\n0           30192  gpt-4-1106-preview           gpt-4-0613   \n1           53567           koala-13b           gpt-4-0613   \n2           65089  gpt-3.5-turbo-0613       mistral-medium   \n3           96401    llama-2-13b-chat  mistral-7b-instruct   \n4          198779           koala-13b   gpt-3.5-turbo-0314   \n...           ...                 ...                  ...   \n57472  4294656694          gpt-4-0613             claude-1   \n57473  4294692063          claude-2.0     llama-2-13b-chat   \n57474  4294710549            claude-1           alpaca-13b   \n57475  4294899228              palm-2       tulu-2-dpo-70b   \n57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n\n                                                  prompt  \\\n0      [\"Is it morally right to try to have a certain...   \n1      [\"What is the difference between marriage lice...   \n2      [\"explain function calling. how would you call...   \n3      [\"How can I create a test set for a very rare ...   \n4      [\"What is the best way to travel from Tel-Aviv...   \n...                                                  ...   \n57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n57473  [\"In python, implement a naive Bayes with gaus...   \n57474  [\"is it unethical to work on building weapons?...   \n57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n57476  [\"three kids eat three apples in three days, h...   \n\n                                              response_a  \\\n0      [\"The question of whether it is morally right ...   \n1      [\"A marriage license is a legal document that ...   \n2      [\"Function calling is the process of invoking ...   \n3      [\"Creating a test set for a very rare category...   \n4      [\"The best way to travel from Tel Aviv to Jeru...   \n...                                                  ...   \n57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n57473  [\"Here is an implementation of a naive Bayes c...   \n57474  [\"Working on weapons technology raises some et...   \n57475  [\"Bromadiolone is a rodenticide which is most ...   \n57476                                      [\"27 apples\"]   \n\n                                              response_b  winner_model_a  \\\n0      [\"As an AI, I don't have personal beliefs or o...               1   \n1      [\"A marriage license and a marriage certificat...               0   \n2      [\"Function calling is the process of invoking ...               0   \n3      [\"When building a classifier for a very rare c...               1   \n4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n...                                                  ...             ...   \n57472  [\"Here is how that mnemonic represents the dig...               1   \n57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n57474  [\"It depends on the context. Weapons can be us...               1   \n57475  [\"As an AI language model, I do not promote or...               0   \n57476  [\"If three kids eat three apples in three days...               1   \n\n       winner_model_b  winner_tie  \n0                   0           0  \n1                   1           0  \n2                   0           1  \n3                   0           0  \n4                   1           0  \n...               ...         ...  \n57472               0           0  \n57473               0           0  \n57474               0           0  \n57475               1           0  \n57476               0           0  \n\n[57477 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57472</th>\n      <td>4294656694</td>\n      <td>gpt-4-0613</td>\n      <td>claude-1</td>\n      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n      <td>[\"Here is how that mnemonic represents the dig...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57473</th>\n      <td>4294692063</td>\n      <td>claude-2.0</td>\n      <td>llama-2-13b-chat</td>\n      <td>[\"In python, implement a naive Bayes with gaus...</td>\n      <td>[\"Here is an implementation of a naive Bayes c...</td>\n      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57474</th>\n      <td>4294710549</td>\n      <td>claude-1</td>\n      <td>alpaca-13b</td>\n      <td>[\"is it unethical to work on building weapons?...</td>\n      <td>[\"Working on weapons technology raises some et...</td>\n      <td>[\"It depends on the context. Weapons can be us...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57475</th>\n      <td>4294899228</td>\n      <td>palm-2</td>\n      <td>tulu-2-dpo-70b</td>\n      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n      <td>[\"As an AI language model, I do not promote or...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57476</th>\n      <td>4294947231</td>\n      <td>gemini-pro-dev-api</td>\n      <td>gpt-4-1106-preview</td>\n      <td>[\"three kids eat three apples in three days, h...</td>\n      <td>[\"27 apples\"]</td>\n      <td>[\"If three kids eat three apples in three days...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57477 rows × 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\ndf_test","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"Hdqoqi-SvZl_","outputId":"eaf2e8c5-458d-4404-c566-c0b89a18bb75","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.826344Z","iopub.execute_input":"2025-08-30T06:49:24.826679Z","iopub.status.idle":"2025-08-30T06:49:24.839785Z","shell.execute_reply.started":"2025-08-30T06:49:24.826625Z","shell.execute_reply":"2025-08-30T06:49:24.838944Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>136060</td>\n      <td>[\"I have three oranges today, I ate an orange ...</td>\n      <td>[\"You have two oranges today.\"]</td>\n      <td>[\"You still have three oranges. Eating an oran...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>211333</td>\n      <td>[\"You are a mediator in a heated political deb...</td>\n      <td>[\"Thank you for sharing the details of the sit...</td>\n      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1233961</td>\n      <td>[\"How to initialize the classification head wh...</td>\n      <td>[\"When you want to initialize the classificati...</td>\n      <td>[\"To initialize the classification head when p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"df_train.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7yuwJ4zvZl_","outputId":"20a46c9c-58da-495f-f535-e728c9dedd73","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.840589Z","iopub.execute_input":"2025-08-30T06:49:24.840993Z","iopub.status.idle":"2025-08-30T06:49:24.895521Z","shell.execute_reply.started":"2025-08-30T06:49:24.840967Z","shell.execute_reply":"2025-08-30T06:49:24.894712Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"Mj5YG1M6vZmA","outputId":"3d357014-c0e8-4cd3-db6b-74350b5b6907","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.896299Z","iopub.execute_input":"2025-08-30T06:49:24.896507Z","iopub.status.idle":"2025-08-30T06:49:24.928805Z","shell.execute_reply.started":"2025-08-30T06:49:24.896491Z","shell.execute_reply":"2025-08-30T06:49:24.928043Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"id                0\nmodel_a           0\nmodel_b           0\nprompt            0\nresponse_a        0\nresponse_b        0\nwinner_model_a    0\nwinner_model_b    0\nwinner_tie        0\ndtype: int64"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"X = df_train.drop(['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie'], axis = 1)\nX","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"id":"ugzdGm5TvZmA","outputId":"1715934d-eb74-4a3d-8670-8473e9462a59","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.929618Z","iopub.execute_input":"2025-08-30T06:49:24.929891Z","iopub.status.idle":"2025-08-30T06:49:24.958071Z","shell.execute_reply.started":"2025-08-30T06:49:24.929869Z","shell.execute_reply":"2025-08-30T06:49:24.957304Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"               id                                             prompt  \\\n0           30192  [\"Is it morally right to try to have a certain...   \n1           53567  [\"What is the difference between marriage lice...   \n2           65089  [\"explain function calling. how would you call...   \n3           96401  [\"How can I create a test set for a very rare ...   \n4          198779  [\"What is the best way to travel from Tel-Aviv...   \n...           ...                                                ...   \n57472  4294656694  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n57473  4294692063  [\"In python, implement a naive Bayes with gaus...   \n57474  4294710549  [\"is it unethical to work on building weapons?...   \n57475  4294899228  [\"If a bait contains 0,0025% bromadiolon then ...   \n57476  4294947231  [\"three kids eat three apples in three days, h...   \n\n                                              response_a  \\\n0      [\"The question of whether it is morally right ...   \n1      [\"A marriage license is a legal document that ...   \n2      [\"Function calling is the process of invoking ...   \n3      [\"Creating a test set for a very rare category...   \n4      [\"The best way to travel from Tel Aviv to Jeru...   \n...                                                  ...   \n57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n57473  [\"Here is an implementation of a naive Bayes c...   \n57474  [\"Working on weapons technology raises some et...   \n57475  [\"Bromadiolone is a rodenticide which is most ...   \n57476                                      [\"27 apples\"]   \n\n                                              response_b  \n0      [\"As an AI, I don't have personal beliefs or o...  \n1      [\"A marriage license and a marriage certificat...  \n2      [\"Function calling is the process of invoking ...  \n3      [\"When building a classifier for a very rare c...  \n4      [\"The best way to travel from Tel-Aviv to Jeru...  \n...                                                  ...  \n57472  [\"Here is how that mnemonic represents the dig...  \n57473  [\"Sure! Here's an implementation of a naive Ba...  \n57474  [\"It depends on the context. Weapons can be us...  \n57475  [\"As an AI language model, I do not promote or...  \n57476  [\"If three kids eat three apples in three days...  \n\n[57477 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30192</td>\n      <td>[\"Is it morally right to try to have a certain...</td>\n      <td>[\"The question of whether it is morally right ...</td>\n      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>53567</td>\n      <td>[\"What is the difference between marriage lice...</td>\n      <td>[\"A marriage license is a legal document that ...</td>\n      <td>[\"A marriage license and a marriage certificat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65089</td>\n      <td>[\"explain function calling. how would you call...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n      <td>[\"Function calling is the process of invoking ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>96401</td>\n      <td>[\"How can I create a test set for a very rare ...</td>\n      <td>[\"Creating a test set for a very rare category...</td>\n      <td>[\"When building a classifier for a very rare c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198779</td>\n      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57472</th>\n      <td>4294656694</td>\n      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n      <td>[\"Here is how that mnemonic represents the dig...</td>\n    </tr>\n    <tr>\n      <th>57473</th>\n      <td>4294692063</td>\n      <td>[\"In python, implement a naive Bayes with gaus...</td>\n      <td>[\"Here is an implementation of a naive Bayes c...</td>\n      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n    </tr>\n    <tr>\n      <th>57474</th>\n      <td>4294710549</td>\n      <td>[\"is it unethical to work on building weapons?...</td>\n      <td>[\"Working on weapons technology raises some et...</td>\n      <td>[\"It depends on the context. Weapons can be us...</td>\n    </tr>\n    <tr>\n      <th>57475</th>\n      <td>4294899228</td>\n      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n      <td>[\"As an AI language model, I do not promote or...</td>\n    </tr>\n    <tr>\n      <th>57476</th>\n      <td>4294947231</td>\n      <td>[\"three kids eat three apples in three days, h...</td>\n      <td>[\"27 apples\"]</td>\n      <td>[\"If three kids eat three apples in three days...</td>\n    </tr>\n  </tbody>\n</table>\n<p>57477 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"y = df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].values\n\ny = np.argmax(y, axis=1)\ny","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2phggxcLvZmA","outputId":"163f8ebb-2d82-4123-ecd4-426ac7c10129","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.960739Z","iopub.execute_input":"2025-08-30T06:49:24.960974Z","iopub.status.idle":"2025-08-30T06:49:24.968668Z","shell.execute_reply.started":"2025-08-30T06:49:24.960947Z","shell.execute_reply":"2025-08-30T06:49:24.967995Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 2, ..., 0, 1, 0])"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state = 42)","metadata":{"id":"zclkD6mevZmB","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.969749Z","iopub.execute_input":"2025-08-30T06:49:24.970025Z","iopub.status.idle":"2025-08-30T06:49:24.994401Z","shell.execute_reply.started":"2025-08-30T06:49:24.970002Z","shell.execute_reply":"2025-08-30T06:49:24.993697Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"X_train","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":562},"id":"eXdfG6LpvZmB","outputId":"3dc29d3e-5e11-4204-a11a-5b12770f0413","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:24.995248Z","iopub.execute_input":"2025-08-30T06:49:24.995491Z","iopub.status.idle":"2025-08-30T06:49:25.005953Z","shell.execute_reply.started":"2025-08-30T06:49:24.995470Z","shell.execute_reply":"2025-08-30T06:49:25.004890Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"               id                                             prompt  \\\n30205  2245506736  [\"can you give me some escape room themes with...   \n8763    656268525  [\"Why did digital electronics switch from 5 vo...   \n30501  2266396135  [\"as an acclaimed and visionary author punishe...   \n33619  2497468695  [\"\\n\\nWrite a micro editor plugin that shows t...   \n22573  1679992057  [\"1. 19 year old Emese who is thin (165cm 48kg...   \n...           ...                                                ...   \n54343  4061186081         [\"mega-sena brazilian lottery statistics\"]   \n38158  2840606458                     [\"Draw a dog using ASCII art\"]   \n860      62750940                          [\"How to wear a bikini?\"]   \n15795  1180878567  [\"Can you tell me what was going on with all t...   \n56422  4218036675                          [\"SHOW ME WHAT YOU GOT!\"]   \n\n                                              response_a  \\\n30205  [\"Certainly! Here are several escape room them...   \n8763   [\"There are a few key reasons why digital elec...   \n30501  [\"As an acclaimed and visionary author, Elieze...   \n33619  [\"Here is Python code for a basic micro editor...   \n22573  [\"Certainly, let's address each of your points...   \n...                                                  ...   \n54343  [\"I do not have access to real-time mega-sena ...   \n38158                        [\"\\/_\\/\\\\  \\n( o.o )\\n> ^\"]   \n860    [\"Wearing a bikini can be a fun and comfortabl...   \n15795  [\"The direwolves, which are also known as dire...   \n56422  [\"Of course! As an AI, I can assist with a var...   \n\n                                              response_b  \n30205  [\"Here are some fun and immersive escape room ...  \n8763   [\"The shift from 5 volt logic to 3 volt logic ...  \n30501  [\"Eliezer Yudkowsky is often referred to as th...  \n33619  [\"Micro is a modern and intuitive terminal-bas...  \n22573  [\"1. From the description you provided, it see...  \n...                                                  ...  \n54343  [\"Mega-Sena is a Brazilian lottery game that o...  \n38158  [\"Here is a dog drawn with ASCII art:\\n\\n     ...  \n860    [\"Here are the basic steps to wear a bikini:\\n...  \n15795  [\"Sure! On the night of the Red Wedding, all o...  \n56422  [\"I'm a large language model, so I don't have ...  \n\n[45981 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30205</th>\n      <td>2245506736</td>\n      <td>[\"can you give me some escape room themes with...</td>\n      <td>[\"Certainly! Here are several escape room them...</td>\n      <td>[\"Here are some fun and immersive escape room ...</td>\n    </tr>\n    <tr>\n      <th>8763</th>\n      <td>656268525</td>\n      <td>[\"Why did digital electronics switch from 5 vo...</td>\n      <td>[\"There are a few key reasons why digital elec...</td>\n      <td>[\"The shift from 5 volt logic to 3 volt logic ...</td>\n    </tr>\n    <tr>\n      <th>30501</th>\n      <td>2266396135</td>\n      <td>[\"as an acclaimed and visionary author punishe...</td>\n      <td>[\"As an acclaimed and visionary author, Elieze...</td>\n      <td>[\"Eliezer Yudkowsky is often referred to as th...</td>\n    </tr>\n    <tr>\n      <th>33619</th>\n      <td>2497468695</td>\n      <td>[\"\\n\\nWrite a micro editor plugin that shows t...</td>\n      <td>[\"Here is Python code for a basic micro editor...</td>\n      <td>[\"Micro is a modern and intuitive terminal-bas...</td>\n    </tr>\n    <tr>\n      <th>22573</th>\n      <td>1679992057</td>\n      <td>[\"1. 19 year old Emese who is thin (165cm 48kg...</td>\n      <td>[\"Certainly, let's address each of your points...</td>\n      <td>[\"1. From the description you provided, it see...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54343</th>\n      <td>4061186081</td>\n      <td>[\"mega-sena brazilian lottery statistics\"]</td>\n      <td>[\"I do not have access to real-time mega-sena ...</td>\n      <td>[\"Mega-Sena is a Brazilian lottery game that o...</td>\n    </tr>\n    <tr>\n      <th>38158</th>\n      <td>2840606458</td>\n      <td>[\"Draw a dog using ASCII art\"]</td>\n      <td>[\"\\/_\\/\\\\  \\n( o.o )\\n&gt; ^\"]</td>\n      <td>[\"Here is a dog drawn with ASCII art:\\n\\n     ...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>62750940</td>\n      <td>[\"How to wear a bikini?\"]</td>\n      <td>[\"Wearing a bikini can be a fun and comfortabl...</td>\n      <td>[\"Here are the basic steps to wear a bikini:\\n...</td>\n    </tr>\n    <tr>\n      <th>15795</th>\n      <td>1180878567</td>\n      <td>[\"Can you tell me what was going on with all t...</td>\n      <td>[\"The direwolves, which are also known as dire...</td>\n      <td>[\"Sure! On the night of the Red Wedding, all o...</td>\n    </tr>\n    <tr>\n      <th>56422</th>\n      <td>4218036675</td>\n      <td>[\"SHOW ME WHAT YOU GOT!\"]</td>\n      <td>[\"Of course! As an AI, I can assist with a var...</td>\n      <td>[\"I'm a large language model, so I don't have ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>45981 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nnltk.download(\"stopwords\")\nnltk.download(\"wordnet\")\n\nstop_words = set(stopwords.words(\"english\"))\nlemmatizer = WordNetLemmatizer()\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n    tokens = text.split()\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    return \" \".join(tokens)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tmo2CHamvZmB","outputId":"bc612167-df3a-4817-a4f7-e5744f5636df","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:25.006843Z","iopub.execute_input":"2025-08-30T06:49:25.007253Z","iopub.status.idle":"2025-08-30T06:49:25.474008Z","shell.execute_reply.started":"2025-08-30T06:49:25.007228Z","shell.execute_reply":"2025-08-30T06:49:25.473093Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"X_train[\"response_a_clean\"] = X_train[\"response_a\"].apply(clean_text)\nX_train[\"response_b_clean\"] = X_train[\"response_b\"].apply(clean_text)\n\nX_train[\"prompt_clean\"] = X_train[\"prompt\"].apply(clean_text)\n","metadata":{"id":"sByVxKpnvZmB","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:49:25.474894Z","iopub.execute_input":"2025-08-30T06:49:25.475172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":562},"id":"IC6k_RmQvZmB","outputId":"481d34f1-2648-454a-eada-a540c4ede263","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qbE9ugZ8vZmB","outputId":"fcb8c587-f96d-4769-df37-12af635f1fc5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"catagorical_feature = [col for col in X.columns if X[col].dtype == 'object']\ncatagorical_feature","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pgSYSSnZvZmC","outputId":"5bdbecba-d249-41e8-8d77-0694bbfaeeb6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n\nfrom sentence_transformers import SentenceTransformer\nimport torch","metadata":{"id":"Hw-K-3wVvZmC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n\nfrom sentence_transformers import SentenceTransformer\nimport torch\n\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, model_name=\"all-mpnet-base-v2\"):\n        self.model_name = model_name  \n        self.model = SentenceTransformer(model_name)\n        if torch.cuda.is_available():\n            self.model = self.model.to(\"cuda\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return self.model.encode(X.tolist(), show_progress_bar=False, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Example usage in ColumnTransformer\npreprocessing = ColumnTransformer([\n    (\"prompt_embed\", HFEmbedder(), \"prompt\"),\n    (\"resp_a_embed\", HFEmbedder(), \"response_a\"),\n    (\"resp_b_embed\", HFEmbedder(), \"response_b\"),\n    (\"num\", \"passthrough\", [\"id\"])\n])\n","metadata":{"id":"h3ccceBovZmC"}},{"cell_type":"code","source":"","metadata":{"id":"3EOfzGVovZmD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport torch\n\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path=\"/kaggle/input/open-minilm-l6-v2\",use_auth_token=False , local_files_only=True,batch_size=8, use_cuda=True):\n        self.model_path = model_path\n        self.batch_size = batch_size\n        self.use_cuda = use_cuda and torch.cuda.is_available()\n        self.model = SentenceTransformer(self.model_path)\n        if self.use_cuda:\n            self.model = self.model.to(\"cuda\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        texts = X.tolist()\n        all_embeddings = []\n\n        for i in range(0, len(texts), self.batch_size):\n            batch = texts[i:i + self.batch_size]\n            embeddings = self.model.encode(\n                batch,\n                show_progress_bar=False,\n                device=\"cuda\" if self.use_cuda else \"cpu\"\n            )\n            all_embeddings.append(embeddings)\n\n        return np.vstack(all_embeddings)\n\n","metadata":{"id":"dfas4MWXvZmD"}},{"cell_type":"markdown","source":"from transformers import AutoTokenizer, AutoModel\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nimport keras_nlp\nimport keras\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport numpy as np\nimport keras_nlp\n\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, weights_path=\"/kaggle/input/dbertav3-small/model.weights.h5\", batch_size=8):\n        self.batch_size = batch_size\n        self.backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\"deberta_v3_extra_small_en\")\n        self.backbone.load_weights(weights_path)\n        self.preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\"deberta_v3_extra_small_en\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        texts = X.tolist()\n        all_embeddings = []\n\n        for i in range(0, len(texts), self.batch_size):\n            batch = texts[i:i + self.batch_size]\n            tokenized = self.preprocessor(batch)\n            outputs = self.backbone(tokenized)\n            embeddings = np.mean(outputs[\"sequence_output\"].numpy(), axis=1)\n            all_embeddings.append(embeddings)\n\n        return np.vstack(all_embeddings)\n\n","metadata":{"id":"pgzYGuKdvZmD"}},{"cell_type":"markdown","source":"import shutil\n\nshutil.copy(\"/kaggle/input/dbertav3-small/vocabulary.spm\", \"/kaggle/working/spm.model\")\n","metadata":{"id":"StQcr9NQvZmD"}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=8, use_cuda=True):\n        self.model_path = model_path\n        self.batch_size = batch_size\n        self.use_cuda = use_cuda and torch.cuda.is_available()\n        self.model = SentenceTransformer(self.model_path)\n        if self.use_cuda:\n            self.model = self.model.to(\"cuda\")\n\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        # Ensure input is a list of strings\n        if isinstance(X, (np.ndarray, list)):\n            texts = list(X)\n        elif hasattr(X, \"tolist\"):\n            texts = X.tolist()\n        else:\n            raise ValueError(\"Unsupported input type for HFEmbedder\")\n\n        all_embeddings = self.model.encode(\n            texts,\n            show_progress_bar=False,\n            convert_to_numpy=True,\n            batch_size=self.batch_size,\n            device=\"cuda\" if self.use_cuda else \"cpu\"\n        )\n\n        return all_embeddings","metadata":{"id":"UkUWMyJfvZmE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nclass PromptResponseSimilarity(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=8, use_cuda=True):\n        self.model_path = model_path\n        self.batch_size = batch_size\n        self.use_cuda = use_cuda and torch.cuda.is_available()\n\n        self.model = SentenceTransformer(self.model_path)\n        if self.use_cuda:\n            self.model = self.model.to(\"cuda\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        prompts = X[\"prompt\"].tolist()\n        responses_a = X[\"response_a\"].tolist()\n        responses_b = X[\"response_b\"].tolist()\n\n        def embed(texts):\n             embeddings = self.model.encode(\n                texts,\n                show_progress_bar=False,\n                convert_to_numpy=True,\n                batch_size=self.batch_size,\n                device=\"cuda\" if self.use_cuda else \"cpu\"\n            )\n             return embeddings\n\n\n        prompt_embeds = embed(prompts)\n        a_embeds = embed(responses_a)\n        b_embeds = embed(responses_b)\n\n        sim_a = cosine_similarity(prompt_embeds, a_embeds).diagonal()\n        sim_b = cosine_similarity(prompt_embeds, b_embeds).diagonal()\n\n        return np.vstack([sim_a, sim_b]).T","metadata":{"id":"F03Ds9k7vZmE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"YchtDsTT0Gx2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nembedder = HFEmbedder(model_path=\"Qwen/Qwen3-Embedding-0.6B\")\nX_train_embed = X_train.copy()\nX_train_embed[\"prompt_embed\"] = embedder.transform(X_train[\"prompt\"])\nX_train_embed[\"resp_a_embed\"] = embedder.transform(X_train[\"response_a\"])\nX_train_embed[\"resp_b_embed\"] = embedder.transform(X_train[\"response_b\"])\n\n# Drop original text columns if not needed\nX_train_embed = X_train_embed.drop(columns=[\"prompt\", \"response_a\", \"response_b\"])\n","metadata":{"id":"9HgDHkDVvZmE"}},{"cell_type":"markdown","source":"from transformers import AutoTokenizer, AutoModel\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\n\nclass HFEmbedder(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path=\"/kaggle/input/dbertav3-small\", use_fast=False,batch_size=8, use_cuda=True):\n        self.model_path = model_path\n        self.batch_size = batch_size\n        self.use_cuda = use_cuda and torch.cuda.is_available()\n        #self.tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/dbertav3-small\", use_fast=False)\n\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n        self.model = AutoModel.from_pretrained(self.model_path)\n        if self.use_cuda:\n            self.model = self.model.to(\"cuda\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        texts = X.tolist()\n        all_embeddings = []\n\n        for i in range(0, len(texts), self.batch_size):\n            batch = texts[i:i + self.batch_size]\n            inputs = self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n            if self.use_cuda:\n                inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n            with torch.no_grad():\n                outputs = self.model(**inputs)\n            # Mean pooling over token embeddings\n            embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n            all_embeddings.append(embeddings)\n\n        return np.vstack(all_embeddings)\n","metadata":{"id":"MMuWZdW6vZmE"}},{"cell_type":"markdown","source":"from transformers import AutoTokenizer, AutoModel\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass PromptResponseSimilarity(BaseEstimator, TransformerMixin):\n    def __init__(self, model_path=\"/kaggle/input/open-minilm-l6-v2\", batch_size=8, use_cuda=True):\n        self.model_path = model_path\n        self.batch_size = batch_size\n        self.use_cuda = use_cuda and torch.cuda.is_available()\n\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n        self.model = AutoModel.from_pretrained(self.model_path)\n        if self.use_cuda:\n            self.model = self.model.to(\"cuda\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        prompts = X[\"prompt\"].tolist()\n        responses_a = X[\"response_a\"].tolist()\n        responses_b = X[\"response_b\"].tolist()\n\n\n        def embed(texts):\n            embeddings = []\n            for i in range(0, len(texts), self.batch_size):\n                batch = texts[i:i + self.batch_size]\n                inputs = self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n                if self.use_cuda:\n                    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n                with torch.no_grad():\n                    outputs = self.model(**inputs)\n                batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n                embeddings.append(batch_embeddings)\n            return np.vstack(embeddings)\n\n        prompt_embeds = embed(prompts)\n        a_embeds = embed(responses_a)\n        b_embeds = embed(responses_b)\n\n        sim_a = cosine_similarity(prompt_embeds, a_embeds).diagonal()\n        sim_b = cosine_similarity(prompt_embeds, b_embeds).diagonal()\n\n        return np.vstack([sim_a, sim_b]).T\n","metadata":{"id":"9GK8ToDivZmF"}},{"cell_type":"markdown","source":"print(os.listdir(\"/kaggle/input/open-minilm-l6-v2\"))\n","metadata":{"id":"38HPhRnTvZmF"}},{"cell_type":"markdown","source":"\nfrom sklearn.compose import ColumnTransformer\npreprocessing = ColumnTransformer([\n    (\"prompt_embed\", HFEmbedder(\"/kaggle/input/dbertav3-small\"), \"prompt\"),\n    (\"resp_a_embed\", HFEmbedder(\"/kaggle/input/dbertav3-small\"), \"response_a\"),\n    (\"resp_b_embed\", HFEmbedder(\"/kaggle/input/dbertav3-small\"), \"response_b\"),\n    (\"num\", \"passthrough\", [\"id\"])\n])\n","metadata":{"id":"NjgqbVAnvZmF"}},{"cell_type":"markdown","source":"\nfrom sklearn.compose import ColumnTransformer\n\n# Define the embedder with the desired model path\nembedder = HFEmbedder(model_path=\"sentence-transformers/all-MiniLM-L6-v2\")\npreprocessing = ColumnTransformer([\n    (\"sim_diff_squared\", PromptResponseSimilarity(\"/kaggle/input/open-minilm-l6-v2\"), [\"prompt_clean\", \"response_a_clean\", \"response_b_clean\"]),\n    (\"prompt_embed\", embedder, \"prompt_clean\"),\n    (\"resp_a_embed\", embedder, \"response_a_clean\"),\n    (\"resp_b_embed\", embedder, \"response_b_clean\"),\n])\n\n","metadata":{"id":"BYTlIehJvZmG"}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\ndef clean_text_for_common_words(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    tokens = text.split()\n    return [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n\n\nclass CommonWordsTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        common_meaningful_words_a = []\n        common_meaningful_words_b = []\n\n        for index, row in X.iterrows():\n            prompt_tokens = clean_text_for_common_words(row['prompt_clean'])\n            response_a_tokens = clean_text_for_common_words(row['response_a_clean'])\n            response_b_tokens = clean_text_for_common_words(row['response_b_clean'])\n\n            common_meaningful_a = len(set(prompt_tokens) & set(response_a_tokens))\n            common_meaningful_b = len(set(prompt_tokens) & set(response_b_tokens))\n\n            common_meaningful_words_a.append(common_meaningful_a)\n            common_meaningful_words_b.append(common_meaningful_b)\n\n        return np.array([common_meaningful_words_a, common_meaningful_words_b]).T","metadata":{"id":"d5e04fcf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pandas as pd\nimport numpy as np\nimport torch\n\n# Choose a different SentenceTransformer model\n# You can explore other models at https://www.sbert.net/docs/pretrained_models.html\nalternative_model_path = \"sentence-transformers/all-mpnet-base-v2\" # Using a larger SentenceTransformer model\nalternative_model = SentenceTransformer(alternative_model_path)\n\nif torch.cuda.is_available():\n    alternative_model = alternative_model.to(\"cuda\")\n\n\ndef calculate_alternative_similarity(df, model, batch_size=8, use_cuda=True):\n    prompts = df[\"prompt\"].tolist()\n    responses_a = df[\"response_a\"].tolist()\n    responses_b = df[\"response_b\"].tolist()\n\n    def embed(texts):\n        embeddings = model.encode(\n            texts,\n            show_progress_bar=False,\n            convert_to_numpy=True,\n            batch_size=batch_size,\n            device=\"cuda\" if use_cuda else \"cpu\"\n        )\n        return embeddings\n\n    prompt_embeds = embed(prompts)\n    a_embeds = embed(responses_a)\n    b_embeds = embed(responses_b)\n\n    sim_a = cosine_similarity(prompt_embeds, a_embeds).diagonal()\n    sim_b = cosine_similarity(prompt_embeds, b_embeds).diagonal()\n\n    return pd.DataFrame({'alternative_similarity_a': sim_a, 'alternative_similarity_b': sim_b})\n\n# Calculate alternative similarity scores for training and test data\n#alternative_similarity_train = calculate_alternative_similarity(X_train, alternative_model)\n#alternative_similarity_test = calculate_alternative_similarity(X_test, alternative_model)\n\n# You can now add these new similarity scores to your X_train and X_test dataframes\n#X_train = pd.concat([X_train, alternative_similarity_train], axis=1)\n#X_test = pd.concat([X_test, alternative_similarity_test], axis=1)\n\n#display(X_train.head())\n#display(X_test.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cca0cdb8","outputId":"83005984-3c47-40fb-9f41-bbbf4c011e00","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"preprocessing = ColumnTransformer([\n    (\"similarities\", PromptResponseSimilarity(\"/kaggle/input/open-minilm-l6-v2\"), [\"prompt\", \"response_a\", \"response_b\"]),\n    (\"prompt_embed\", HFEmbedder(\"/kaggle/input/open-minilm-l6-v2\"), \"prompt\"),\n    (\"resp_a_embed\", HFEmbedder(\"/kaggle/input/open-minilm-l6-v2\"), \"response_a\"),\n    (\"resp_b_embed\", HFEmbedder(\"/kaggle/input/open-minilm-l6-v2\"), \"response_b\"),\n    (\"num\", \"passthrough\", [\"id\"])\n])\n","metadata":{"id":"qpnwVe5xvZmG"}},{"cell_type":"markdown","source":"preprocessing","metadata":{"id":"UnLkBOl8vZmG"}},{"cell_type":"code","source":"#feature_selection = SelectKBest(score_func = chi2, k=6)\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nfeature_selection = SelectKBest(score_func=f_classif, k=6)\n","metadata":{"id":"sqroOVfcvZmG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = XGBClassifier(\n    objective=\"multi:softprob\",\n    num_class=3,\n    eval_metric=\"mlogloss\",\n    n_estimators=300,\n    learning_rate=0.1,\n    max_depth=6,\n    random_state=42\n)","metadata":{"id":"r2euUG6hvZmG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport torch\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Use HFEmbedder and CommonWordsTransformer\nembedder = HFEmbedder(model_path=\"sentence-transformers/all-MiniLM-L6-v2\")\ncommon_words_transformer = CommonWordsTransformer()\nsimilarity_transformer = calculate_alternative_similarity(model_path=\"sentence-transformers/all-mpnet-base-v2\")\n\n# Combine transformers using ColumnTransformer\n# Make sure to include the columns needed by each transformer\nfeature_union = ColumnTransformer(\n    transformers=[\n        (\"prompt_embed\", embedder, \"prompt\"),\n        (\"resp_a_embed\", embedder, \"response_a\"),\n        (\"resp_b_embed\", embedder, \"response_b\"),\n        (\"common_words\", common_words_transformer, [\"prompt_clean\", \"response_a_clean\", \"response_b_clean\"]),\n        (\"similarities\", similarity_transformer, [\"prompt\", \"response_a\", \"response_b\"]), # Corrected to use clean columns\n\n    ],\n    remainder='drop' # Drop other columns\n)\n\n# Define the model (assuming XGBClassifier is defined in a previous cell)\n# from your_model import model\n\n# Create the final pipeline\nmy_pipeline = Pipeline([\n    (\"features\", feature_union),\n    # Adjust indexing for common_words_diff based on the new feature_union output\n    # The common_words transformer now outputs the last two columns before the similarities transformer\n    (\"common_words_diff\", FunctionTransformer(lambda X: (X[:, -2] - X[:, -1]).reshape(-1, 1))), # Adjusted index based on the transformers order\n    (\"model\", model)\n])\n\ndisplay(my_pipeline)","metadata":{"id":"ncprUXqbvZmG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Q_Wo65bw01Ft","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores = cross_val_score(my_pipeline, X_train, y_train, cv=2, scoring=\"accuracy\")\nprint(\"Accuracy:\", scores.mean())","metadata":{"id":"LVybFCKQvZmG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"alBDr4PcvZmH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"SJtKiETbvZmL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_pipeline.fit(X_train, y_train)","metadata":{"id":"omrEMi2jvZmL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test[\"response_a_clean\"] = df_test[\"response_a\"].apply(clean_text)\ndf_test[\"response_b_clean\"] = df_test[\"response_b\"].apply(clean_text)\n\ndf_test[\"prompt_clean\"] = df_test[\"prompt\"].apply(clean_text)","metadata":{"id":"LuxNawNdvZmL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test","metadata":{"id":"fLyEMudNvZmM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probs = my_pipeline.predict_proba(df_test)\n\nsubmission = pd.DataFrame({\n    \"id\": df_test[\"id\"],\n    \"winner_model_a\": probs[:,0],\n    \"winner_model_b\": probs[:,1],\n    \"winner_tie\": probs[:,2],\n})\nprint(submission)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"id":"D8ub3AzfvZmM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test","metadata":{"id":"I922gdVjvZmM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train[\"response_a_clean\"] = X_train[\"response_a\"].apply(clean_text)\nX_train[\"response_b_clean\"] = X_train[\"response_b\"].apply(clean_text)\nX_train[\"prompt_clean\"] = X_train[\"prompt\"].apply(clean_text)\n\nX_test[\"response_a_clean\"] = X_test[\"response_a\"].apply(clean_text)\nX_test[\"response_b_clean\"] = X_test[\"response_b\"].apply(clean_text)\nX_test[\"prompt_clean\"] = X_test[\"prompt\"].apply(clean_text)\n\n\ncommon_words_transformer = CommonWordsTransformer()\n\nX_train_common_words = common_words_transformer.transform(X_train)\nX_test_common_words = common_words_transformer.transform(X_test)\n\nX_train['common_meaningful_a'] = X_train_common_words[:, 0]\nX_train['common_meaningful_b'] = X_train_common_words[:, 1]\n\nX_test['common_meaningful_a'] = X_test_common_words[:, 0]\nX_test['common_meaningful_b'] = X_test_common_words[:, 1]\n\ndisplay(X_train.head())\ndisplay(X_test.head())","metadata":{"id":"41881256","trusted":true},"outputs":[],"execution_count":null}]}